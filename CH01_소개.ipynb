{
 "cells": [
  {
   "cell_type": "raw",
   "id": "a72a93c8",
   "metadata": {},
   "source": [
    "## 샘플과 타깃의 인코딩"
   ]
  },
  {
   "cell_type": "raw",
   "id": "abf0dc50",
   "metadata": {},
   "source": [
    "# TF 표현 (해당 단어가 문장(말뭉치)에 등장하는 횟수)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "07083752",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import seaborn as sns\n",
    "\n",
    "corpus = ['Time flies like an arrow.',\n",
    "         'Fruit flies like a banana.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "febc024a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 0 1 0 1 1]\n",
      " [0 0 1 1 1 1 0]]\n"
     ]
    }
   ],
   "source": [
    "one_hot_vectorizer = CountVectorizer(binary = True)  # 원핫인코딩으로 변환\n",
    "one_hot = one_hot_vectorizer.fit_transform(corpus) # 희소행렬 반환\n",
    "one_hot = one_hot.toarray()  # 밀집행렬로 변환\n",
    "print(one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "24da2e6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['an' 'arrow' 'banana' 'flies' 'fruit' 'like' 'time']\n"
     ]
    }
   ],
   "source": [
    "vocab = one_hot_vectorizer.get_feature_names_out() # 입력의 조합\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d2b408bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(one_hot, annot=True, cbar=False, xticklabels=vocab,\n",
    "           yticklabels=['Sentence1', 'Sentence2'])\n",
    "plt.show()\n",
    "\n",
    "# CountVectorizer 클래스는 기본적으로 글자 하나로 이루어진 단어는 무시 (a)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "257fb6af",
   "metadata": {},
   "source": [
    "# TF-IDF 표현(흔한 토큰의 점수를 낮추고 드문 토큰의 점수를 높이는 방식)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7b8e56fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.49922133 0.49922133 0.         0.35520009 0.         0.35520009\n",
      "  0.49922133]\n",
      " [0.         0.         0.57615236 0.40993715 0.57615236 0.40993715\n",
      "  0.        ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf = tfidf_vectorizer.fit_transform(corpus).toarray()\n",
    "print(tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3aef6462",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(tfidf, annot=True, cbar=True, xticklabels=vocab,\n",
    "           yticklabels=['Sentence1', 'Sentence2'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "84a6a58c",
   "metadata": {},
   "source": [
    "## 파이토치 기초"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4e2412b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x14cc7436dd0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "torch.manual_seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "90b9a67f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AVG',\n",
       " 'AggregationType',\n",
       " 'AliasDb',\n",
       " 'Any',\n",
       " 'AnyType',\n",
       " 'Argument',\n",
       " 'ArgumentSpec',\n",
       " 'AwaitType',\n",
       " 'BFloat16Storage',\n",
       " 'BFloat16Tensor',\n",
       " 'BenchmarkConfig',\n",
       " 'BenchmarkExecutionStats',\n",
       " 'Block',\n",
       " 'BoolStorage',\n",
       " 'BoolTensor',\n",
       " 'BoolType',\n",
       " 'BufferDict',\n",
       " 'ByteStorage',\n",
       " 'ByteTensor',\n",
       " 'CallStack',\n",
       " 'Callable',\n",
       " 'Capsule',\n",
       " 'CharStorage',\n",
       " 'CharTensor',\n",
       " 'ClassType',\n",
       " 'Code',\n",
       " 'CompilationUnit',\n",
       " 'CompleteArgumentSpec',\n",
       " 'ComplexDoubleStorage',\n",
       " 'ComplexFloatStorage',\n",
       " 'ComplexType',\n",
       " 'ConcreteModuleType',\n",
       " 'ConcreteModuleTypeBuilder',\n",
       " 'DeepCopyMemoTable',\n",
       " 'DeserializationStorageContext',\n",
       " 'DeviceObjType',\n",
       " 'Dict',\n",
       " 'DictType',\n",
       " 'DisableTorchFunction',\n",
       " 'DisableTorchFunctionSubclass',\n",
       " 'DispatchKey',\n",
       " 'DispatchKeySet',\n",
       " 'DoubleStorage',\n",
       " 'DoubleTensor',\n",
       " 'EnumType',\n",
       " 'ErrorReport',\n",
       " 'ExcludeDispatchKeyGuard',\n",
       " 'ExecutionPlan',\n",
       " 'FatalError',\n",
       " 'FileCheck',\n",
       " 'FloatStorage',\n",
       " 'FloatTensor',\n",
       " 'FloatType',\n",
       " 'FunctionSchema',\n",
       " 'Future',\n",
       " 'FutureType',\n",
       " 'Generator',\n",
       " 'Gradient',\n",
       " 'Graph',\n",
       " 'GraphExecutorState',\n",
       " 'HalfStorage',\n",
       " 'HalfTensor',\n",
       " 'IODescriptor',\n",
       " 'InferredType',\n",
       " 'IntStorage',\n",
       " 'IntTensor',\n",
       " 'IntType',\n",
       " 'InterfaceType',\n",
       " 'JITException',\n",
       " 'ListType',\n",
       " 'LiteScriptModule',\n",
       " 'LockingLogger',\n",
       " 'LoggerBase',\n",
       " 'LongStorage',\n",
       " 'LongTensor',\n",
       " 'ModuleDict',\n",
       " 'Node',\n",
       " 'NoneType',\n",
       " 'NoopLogger',\n",
       " 'NumberType',\n",
       " 'OperatorInfo',\n",
       " 'Optional',\n",
       " 'OptionalType',\n",
       " 'PRIVATE_OPS',\n",
       " 'ParameterDict',\n",
       " 'PyObjectType',\n",
       " 'PyTorchFileReader',\n",
       " 'PyTorchFileWriter',\n",
       " 'QInt32Storage',\n",
       " 'QInt8Storage',\n",
       " 'QUInt2x4Storage',\n",
       " 'QUInt4x2Storage',\n",
       " 'QUInt8Storage',\n",
       " 'RRefType',\n",
       " 'SUM',\n",
       " 'ScriptClass',\n",
       " 'ScriptClassFunction',\n",
       " 'ScriptDict',\n",
       " 'ScriptDictIterator',\n",
       " 'ScriptDictKeyIterator',\n",
       " 'ScriptFunction',\n",
       " 'ScriptList',\n",
       " 'ScriptListIterator',\n",
       " 'ScriptMethod',\n",
       " 'ScriptModule',\n",
       " 'ScriptModuleSerializer',\n",
       " 'ScriptObject',\n",
       " 'ScriptObjectProperty',\n",
       " 'SerializationStorageContext',\n",
       " 'Set',\n",
       " 'ShortStorage',\n",
       " 'ShortTensor',\n",
       " 'Size',\n",
       " 'StaticModule',\n",
       " 'Storage',\n",
       " 'StorageBase',\n",
       " 'Stream',\n",
       " 'StreamObjType',\n",
       " 'StringType',\n",
       " 'SymBool',\n",
       " 'SymFloat',\n",
       " 'SymInt',\n",
       " 'SymIntType',\n",
       " 'TYPE_CHECKING',\n",
       " 'Tag',\n",
       " 'Tensor',\n",
       " 'TensorType',\n",
       " 'ThroughputBenchmark',\n",
       " 'TracingState',\n",
       " 'TupleType',\n",
       " 'Type',\n",
       " 'TypedStorage',\n",
       " 'USE_GLOBAL_DEPS',\n",
       " 'USE_RTLD_GLOBAL_WITH_LIBTORCH',\n",
       " 'Union',\n",
       " 'UnionType',\n",
       " 'UntypedStorage',\n",
       " 'Use',\n",
       " 'Value',\n",
       " '_C',\n",
       " '_GLOBAL_DEVICE_CONTEXT',\n",
       " '_TorchCompileInductorWrapper',\n",
       " '_VF',\n",
       " '__all__',\n",
       " '__annotations__',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__config__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__future__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " '__version__',\n",
       " '_adaptive_avg_pool2d',\n",
       " '_adaptive_avg_pool3d',\n",
       " '_add_batch_dim',\n",
       " '_add_relu',\n",
       " '_add_relu_',\n",
       " '_addmm_activation',\n",
       " '_aminmax',\n",
       " '_amp_foreach_non_finite_check_and_unscale_',\n",
       " '_amp_update_scale_',\n",
       " '_assert',\n",
       " '_assert_async',\n",
       " '_assert_tensor_metadata',\n",
       " '_awaits',\n",
       " '_batch_norm_impl_index',\n",
       " '_cast_Byte',\n",
       " '_cast_Char',\n",
       " '_cast_Double',\n",
       " '_cast_Float',\n",
       " '_cast_Half',\n",
       " '_cast_Int',\n",
       " '_cast_Long',\n",
       " '_cast_Short',\n",
       " '_choose_qparams_per_tensor',\n",
       " '_chunk_grad_outputs_efficient_attention',\n",
       " '_classes',\n",
       " '_coalesce',\n",
       " '_compute_linear_combination',\n",
       " '_conj',\n",
       " '_conj_copy',\n",
       " '_conj_physical',\n",
       " '_convert_indices_from_coo_to_csr',\n",
       " '_convert_indices_from_csr_to_coo',\n",
       " '_convolution',\n",
       " '_convolution_mode',\n",
       " '_copy_from',\n",
       " '_copy_from_and_resize',\n",
       " '_ctc_loss',\n",
       " '_cudnn_ctc_loss',\n",
       " '_cudnn_init_dropout_state',\n",
       " '_cudnn_rnn',\n",
       " '_cudnn_rnn_flatten_weight',\n",
       " '_cufft_clear_plan_cache',\n",
       " '_cufft_get_plan_cache_max_size',\n",
       " '_cufft_get_plan_cache_size',\n",
       " '_cufft_set_plan_cache_max_size',\n",
       " '_cummax_helper',\n",
       " '_cummin_helper',\n",
       " '_debug_has_internal_overlap',\n",
       " '_decomp',\n",
       " '_dim_arange',\n",
       " '_dirichlet_grad',\n",
       " '_disable_functionalization',\n",
       " '_dispatch',\n",
       " '_efficientzerotensor',\n",
       " '_embedding_bag',\n",
       " '_embedding_bag_forward_only',\n",
       " '_empty_affine_quantized',\n",
       " '_empty_per_channel_affine_quantized',\n",
       " '_enable_functionalization',\n",
       " '_euclidean_dist',\n",
       " '_fake_quantize_learnable_per_channel_affine',\n",
       " '_fake_quantize_learnable_per_tensor_affine',\n",
       " '_fake_quantize_per_tensor_affine_cachemask_tensor_qparams',\n",
       " '_fft_c2c',\n",
       " '_fft_c2r',\n",
       " '_fft_r2c',\n",
       " '_foobar',\n",
       " '_foreach_abs',\n",
       " '_foreach_abs_',\n",
       " '_foreach_acos',\n",
       " '_foreach_acos_',\n",
       " '_foreach_add',\n",
       " '_foreach_add_',\n",
       " '_foreach_addcdiv',\n",
       " '_foreach_addcdiv_',\n",
       " '_foreach_addcmul',\n",
       " '_foreach_addcmul_',\n",
       " '_foreach_asin',\n",
       " '_foreach_asin_',\n",
       " '_foreach_atan',\n",
       " '_foreach_atan_',\n",
       " '_foreach_ceil',\n",
       " '_foreach_ceil_',\n",
       " '_foreach_clamp_max',\n",
       " '_foreach_clamp_max_',\n",
       " '_foreach_clamp_min',\n",
       " '_foreach_clamp_min_',\n",
       " '_foreach_cos',\n",
       " '_foreach_cos_',\n",
       " '_foreach_cosh',\n",
       " '_foreach_cosh_',\n",
       " '_foreach_div',\n",
       " '_foreach_div_',\n",
       " '_foreach_erf',\n",
       " '_foreach_erf_',\n",
       " '_foreach_erfc',\n",
       " '_foreach_erfc_',\n",
       " '_foreach_exp',\n",
       " '_foreach_exp_',\n",
       " '_foreach_expm1',\n",
       " '_foreach_expm1_',\n",
       " '_foreach_floor',\n",
       " '_foreach_floor_',\n",
       " '_foreach_frac',\n",
       " '_foreach_frac_',\n",
       " '_foreach_lerp',\n",
       " '_foreach_lerp_',\n",
       " '_foreach_lgamma',\n",
       " '_foreach_lgamma_',\n",
       " '_foreach_log',\n",
       " '_foreach_log10',\n",
       " '_foreach_log10_',\n",
       " '_foreach_log1p',\n",
       " '_foreach_log1p_',\n",
       " '_foreach_log2',\n",
       " '_foreach_log2_',\n",
       " '_foreach_log_',\n",
       " '_foreach_maximum',\n",
       " '_foreach_maximum_',\n",
       " '_foreach_minimum',\n",
       " '_foreach_minimum_',\n",
       " '_foreach_mul',\n",
       " '_foreach_mul_',\n",
       " '_foreach_neg',\n",
       " '_foreach_neg_',\n",
       " '_foreach_norm',\n",
       " '_foreach_reciprocal',\n",
       " '_foreach_reciprocal_',\n",
       " '_foreach_round',\n",
       " '_foreach_round_',\n",
       " '_foreach_sigmoid',\n",
       " '_foreach_sigmoid_',\n",
       " '_foreach_sin',\n",
       " '_foreach_sin_',\n",
       " '_foreach_sinh',\n",
       " '_foreach_sinh_',\n",
       " '_foreach_sqrt',\n",
       " '_foreach_sqrt_',\n",
       " '_foreach_sub',\n",
       " '_foreach_sub_',\n",
       " '_foreach_tan',\n",
       " '_foreach_tan_',\n",
       " '_foreach_tanh',\n",
       " '_foreach_tanh_',\n",
       " '_foreach_trunc',\n",
       " '_foreach_trunc_',\n",
       " '_foreach_zero_',\n",
       " '_freeze_functional_tensor',\n",
       " '_from_functional_tensor',\n",
       " '_functorch',\n",
       " '_fused_adam_',\n",
       " '_fused_adamw_',\n",
       " '_fused_dropout',\n",
       " '_fused_moving_avg_obs_fq_helper',\n",
       " '_fused_sdp_choice',\n",
       " '_fw_primal_copy',\n",
       " '_grid_sampler_2d_cpu_fallback',\n",
       " '_guards',\n",
       " '_has_compatible_shallow_copy_type',\n",
       " '_histogramdd_bin_edges',\n",
       " '_histogramdd_from_bin_cts',\n",
       " '_histogramdd_from_bin_tensors',\n",
       " '_import_dotted_name',\n",
       " '_index_put_impl_',\n",
       " '_indices_copy',\n",
       " '_initExtension',\n",
       " '_is_all_true',\n",
       " '_is_any_true',\n",
       " '_is_functional_tensor',\n",
       " '_is_zerotensor',\n",
       " '_jit_internal',\n",
       " '_linalg_check_errors',\n",
       " '_linalg_det',\n",
       " '_linalg_eigh',\n",
       " '_linalg_slogdet',\n",
       " '_linalg_solve_ex',\n",
       " '_linalg_svd',\n",
       " '_linalg_utils',\n",
       " '_load_global_deps',\n",
       " '_lobpcg',\n",
       " '_log_softmax',\n",
       " '_log_softmax_backward_data',\n",
       " '_logcumsumexp',\n",
       " '_lowrank',\n",
       " '_lstm_mps',\n",
       " '_lu_with_info',\n",
       " '_make_dual',\n",
       " '_make_dual_copy',\n",
       " '_make_per_channel_quantized_tensor',\n",
       " '_make_per_tensor_quantized_tensor',\n",
       " '_masked_scale',\n",
       " '_masked_softmax',\n",
       " '_meta_registrations',\n",
       " '_mkldnn',\n",
       " '_mkldnn_reshape',\n",
       " '_mkldnn_transpose',\n",
       " '_mkldnn_transpose_',\n",
       " '_mps_convolution',\n",
       " '_mps_convolution_transpose',\n",
       " '_namedtensor_internals',\n",
       " '_native_batch_norm_legit',\n",
       " '_native_decoder_only_multi_head_attention',\n",
       " '_native_multi_head_attention',\n",
       " '_neg_view',\n",
       " '_neg_view_copy',\n",
       " '_nested_from_padded',\n",
       " '_nested_from_padded_and_nested_example',\n",
       " '_nested_tensor_from_mask',\n",
       " '_nested_tensor_from_mask_left_aligned',\n",
       " '_nested_tensor_from_tensor_list',\n",
       " '_nested_tensor_softmax_with_shape',\n",
       " '_nnpack_available',\n",
       " '_nnpack_spatial_convolution',\n",
       " '_ops',\n",
       " '_pack_padded_sequence',\n",
       " '_pad_packed_sequence',\n",
       " '_pin_memory',\n",
       " '_preload_cuda_deps',\n",
       " '_prelu_kernel',\n",
       " '_prims',\n",
       " '_prims_common',\n",
       " '_refs',\n",
       " '_register_device_module',\n",
       " '_remove_batch_dim',\n",
       " '_reshape_alias_copy',\n",
       " '_reshape_from_tensor',\n",
       " '_resize_output_',\n",
       " '_rowwise_prune',\n",
       " '_sample_dirichlet',\n",
       " '_saturate_weight_to_fp16',\n",
       " '_scaled_dot_product_attention_math',\n",
       " '_scaled_dot_product_efficient_attention',\n",
       " '_scaled_dot_product_flash_attention',\n",
       " '_segment_reduce',\n",
       " '_shape_as_tensor',\n",
       " '_sobol_engine_draw',\n",
       " '_sobol_engine_ff_',\n",
       " '_sobol_engine_initialize_state_',\n",
       " '_sobol_engine_scramble_',\n",
       " '_softmax',\n",
       " '_softmax_backward_data',\n",
       " '_sources',\n",
       " '_sparse_broadcast_to',\n",
       " '_sparse_broadcast_to_copy',\n",
       " '_sparse_coo_tensor_unsafe',\n",
       " '_sparse_csr_prod',\n",
       " '_sparse_csr_sum',\n",
       " '_sparse_log_softmax_backward_data',\n",
       " '_sparse_softmax_backward_data',\n",
       " '_sparse_sparse_matmul',\n",
       " '_sparse_sum',\n",
       " '_stack',\n",
       " '_standard_gamma',\n",
       " '_standard_gamma_grad',\n",
       " '_storage_classes',\n",
       " '_subclasses',\n",
       " '_sync',\n",
       " '_tensor',\n",
       " '_tensor_classes',\n",
       " '_tensor_str',\n",
       " '_test_autograd_multiple_dispatch',\n",
       " '_test_autograd_multiple_dispatch_view',\n",
       " '_test_autograd_multiple_dispatch_view_copy',\n",
       " '_test_check_tensor',\n",
       " '_test_serialization_subcmul',\n",
       " '_to_cpu',\n",
       " '_to_functional_tensor',\n",
       " '_transform_bias_rescale_qkv',\n",
       " '_transformer_decoder_only_layer_fwd',\n",
       " '_transformer_encoder_layer_fwd',\n",
       " '_trilinear',\n",
       " '_triton_multi_head_attention',\n",
       " '_triton_scaled_dot_attention',\n",
       " '_unique',\n",
       " '_unique2',\n",
       " '_unpack_dual',\n",
       " '_use_cudnn_ctc_loss',\n",
       " '_use_cudnn_rnn_flatten_weight',\n",
       " '_utils',\n",
       " '_utils_internal',\n",
       " '_validate_compressed_sparse_indices',\n",
       " '_validate_sparse_bsc_tensor_args',\n",
       " '_validate_sparse_bsr_tensor_args',\n",
       " '_validate_sparse_compressed_tensor_args',\n",
       " '_validate_sparse_coo_tensor_args',\n",
       " '_validate_sparse_csc_tensor_args',\n",
       " '_validate_sparse_csr_tensor_args',\n",
       " '_values_copy',\n",
       " '_vmap_internals',\n",
       " '_warn_typed_storage_removal',\n",
       " '_weight_norm',\n",
       " '_weight_norm_interface',\n",
       " '_weights_only_unpickler',\n",
       " 'abs',\n",
       " 'abs_',\n",
       " 'absolute',\n",
       " 'acos',\n",
       " 'acos_',\n",
       " 'acosh',\n",
       " 'acosh_',\n",
       " 'adaptive_avg_pool1d',\n",
       " 'adaptive_max_pool1d',\n",
       " 'add',\n",
       " 'addbmm',\n",
       " 'addcdiv',\n",
       " 'addcmul',\n",
       " 'addmm',\n",
       " 'addmv',\n",
       " 'addmv_',\n",
       " 'addr',\n",
       " 'adjoint',\n",
       " 'affine_grid_generator',\n",
       " 'alias_copy',\n",
       " 'align_tensors',\n",
       " 'all',\n",
       " 'allclose',\n",
       " 'alpha_dropout',\n",
       " 'alpha_dropout_',\n",
       " 'amax',\n",
       " 'amin',\n",
       " 'aminmax',\n",
       " 'amp',\n",
       " 'angle',\n",
       " 'any',\n",
       " 'ao',\n",
       " 'arange',\n",
       " 'arccos',\n",
       " 'arccos_',\n",
       " 'arccosh',\n",
       " 'arccosh_',\n",
       " 'arcsin',\n",
       " 'arcsin_',\n",
       " 'arcsinh',\n",
       " 'arcsinh_',\n",
       " 'arctan',\n",
       " 'arctan2',\n",
       " 'arctan_',\n",
       " 'arctanh',\n",
       " 'arctanh_',\n",
       " 'are_deterministic_algorithms_enabled',\n",
       " 'argmax',\n",
       " 'argmin',\n",
       " 'argsort',\n",
       " 'argwhere',\n",
       " 'as_strided',\n",
       " 'as_strided_',\n",
       " 'as_strided_copy',\n",
       " 'as_strided_scatter',\n",
       " 'as_tensor',\n",
       " 'asarray',\n",
       " 'asin',\n",
       " 'asin_',\n",
       " 'asinh',\n",
       " 'asinh_',\n",
       " 'atan',\n",
       " 'atan2',\n",
       " 'atan_',\n",
       " 'atanh',\n",
       " 'atanh_',\n",
       " 'atleast_1d',\n",
       " 'atleast_2d',\n",
       " 'atleast_3d',\n",
       " 'attr',\n",
       " 'autocast',\n",
       " 'autocast_decrement_nesting',\n",
       " 'autocast_increment_nesting',\n",
       " 'autograd',\n",
       " 'avg_pool1d',\n",
       " 'backends',\n",
       " 'baddbmm',\n",
       " 'bartlett_window',\n",
       " 'base_py_dll_path',\n",
       " 'batch_norm',\n",
       " 'batch_norm_backward_elemt',\n",
       " 'batch_norm_backward_reduce',\n",
       " 'batch_norm_elemt',\n",
       " 'batch_norm_gather_stats',\n",
       " 'batch_norm_gather_stats_with_counts',\n",
       " 'batch_norm_stats',\n",
       " 'batch_norm_update_stats',\n",
       " 'bernoulli',\n",
       " 'bfloat16',\n",
       " 'bilinear',\n",
       " 'binary_cross_entropy_with_logits',\n",
       " 'bincount',\n",
       " 'binomial',\n",
       " 'bitwise_and',\n",
       " 'bitwise_left_shift',\n",
       " 'bitwise_not',\n",
       " 'bitwise_or',\n",
       " 'bitwise_right_shift',\n",
       " 'bitwise_xor',\n",
       " 'blackman_window',\n",
       " 'block_diag',\n",
       " 'bmm',\n",
       " 'bool',\n",
       " 'broadcast_shapes',\n",
       " 'broadcast_tensors',\n",
       " 'broadcast_to',\n",
       " 'bucketize',\n",
       " 'builtins',\n",
       " 'can_cast',\n",
       " 'candidate',\n",
       " 'cartesian_prod',\n",
       " 'cat',\n",
       " 'ccol_indices_copy',\n",
       " 'cdist',\n",
       " 'cdouble',\n",
       " 'ceil',\n",
       " 'ceil_',\n",
       " 'celu',\n",
       " 'celu_',\n",
       " 'cfloat',\n",
       " 'chain_matmul',\n",
       " 'chalf',\n",
       " 'channel_shuffle',\n",
       " 'channels_last',\n",
       " 'channels_last_3d',\n",
       " 'cholesky',\n",
       " 'cholesky_inverse',\n",
       " 'cholesky_solve',\n",
       " 'choose_qparams_optimized',\n",
       " 'chunk',\n",
       " 'clamp',\n",
       " 'clamp_',\n",
       " 'clamp_max',\n",
       " 'clamp_max_',\n",
       " 'clamp_min',\n",
       " 'clamp_min_',\n",
       " 'classes',\n",
       " 'classproperty',\n",
       " 'clear_autocast_cache',\n",
       " 'clip',\n",
       " 'clip_',\n",
       " 'clone',\n",
       " 'col_indices_copy',\n",
       " 'column_stack',\n",
       " 'combinations',\n",
       " 'compile',\n",
       " 'compiled_with_cxx11_abi',\n",
       " 'complex',\n",
       " 'complex128',\n",
       " 'complex32',\n",
       " 'complex64',\n",
       " 'concat',\n",
       " 'concatenate',\n",
       " 'conj',\n",
       " 'conj_physical',\n",
       " 'conj_physical_',\n",
       " 'constant_pad_nd',\n",
       " 'contiguous_format',\n",
       " 'conv1d',\n",
       " 'conv2d',\n",
       " 'conv3d',\n",
       " 'conv_tbc',\n",
       " 'conv_transpose1d',\n",
       " 'conv_transpose2d',\n",
       " 'conv_transpose3d',\n",
       " 'convolution',\n",
       " 'copysign',\n",
       " 'corrcoef',\n",
       " 'cos',\n",
       " 'cos_',\n",
       " 'cosh',\n",
       " 'cosh_',\n",
       " 'cosine_embedding_loss',\n",
       " 'cosine_similarity',\n",
       " 'count_nonzero',\n",
       " 'cov',\n",
       " 'cpp',\n",
       " 'cpu',\n",
       " 'cross',\n",
       " 'crow_indices_copy',\n",
       " 'ctc_loss',\n",
       " 'ctypes',\n",
       " 'cuda',\n",
       " 'cuda_path',\n",
       " 'cuda_version',\n",
       " 'cudnn_affine_grid_generator',\n",
       " 'cudnn_batch_norm',\n",
       " 'cudnn_convolution',\n",
       " 'cudnn_convolution_add_relu',\n",
       " 'cudnn_convolution_relu',\n",
       " 'cudnn_convolution_transpose',\n",
       " 'cudnn_grid_sampler',\n",
       " 'cudnn_is_acceptable',\n",
       " 'cummax',\n",
       " 'cummin',\n",
       " 'cumprod',\n",
       " 'cumsum',\n",
       " 'cumulative_trapezoid',\n",
       " 'default_generator',\n",
       " 'deg2rad',\n",
       " 'deg2rad_',\n",
       " 'dequantize',\n",
       " 'det',\n",
       " 'detach',\n",
       " 'detach_',\n",
       " 'detach_copy',\n",
       " 'device',\n",
       " 'diag',\n",
       " 'diag_embed',\n",
       " 'diagflat',\n",
       " 'diagonal',\n",
       " 'diagonal_copy',\n",
       " 'diagonal_scatter',\n",
       " 'diff',\n",
       " 'digamma',\n",
       " 'dist',\n",
       " 'distributed',\n",
       " 'distributions',\n",
       " 'div',\n",
       " 'divide',\n",
       " 'dll',\n",
       " 'dll_path',\n",
       " 'dll_paths',\n",
       " 'dlls',\n",
       " 'dot',\n",
       " 'double',\n",
       " 'dropout',\n",
       " 'dropout_',\n",
       " 'dsmm',\n",
       " 'dsplit',\n",
       " 'dstack',\n",
       " 'dtype',\n",
       " 'e',\n",
       " 'eig',\n",
       " 'einsum',\n",
       " 'embedding',\n",
       " 'embedding_bag',\n",
       " 'embedding_renorm_',\n",
       " 'empty',\n",
       " 'empty_like',\n",
       " 'empty_quantized',\n",
       " 'empty_strided',\n",
       " 'enable_grad',\n",
       " 'eq',\n",
       " 'equal',\n",
       " 'erf',\n",
       " 'erf_',\n",
       " 'erfc',\n",
       " 'erfc_',\n",
       " 'erfinv',\n",
       " 'exp',\n",
       " 'exp2',\n",
       " 'exp2_',\n",
       " 'exp_',\n",
       " 'expand_copy',\n",
       " 'expm1',\n",
       " 'expm1_',\n",
       " 'eye',\n",
       " 'fake_quantize_per_channel_affine',\n",
       " 'fake_quantize_per_tensor_affine',\n",
       " 'fbgemm_linear_fp16_weight',\n",
       " 'fbgemm_linear_fp16_weight_fp32_activation',\n",
       " 'fbgemm_linear_int8_weight',\n",
       " 'fbgemm_linear_int8_weight_fp32_activation',\n",
       " 'fbgemm_linear_quantize_weight',\n",
       " 'fbgemm_pack_gemm_matrix_fp16',\n",
       " 'fbgemm_pack_quantized_matrix',\n",
       " 'feature_alpha_dropout',\n",
       " 'feature_alpha_dropout_',\n",
       " 'feature_dropout',\n",
       " 'feature_dropout_',\n",
       " 'fft',\n",
       " 'fill',\n",
       " 'fill_',\n",
       " 'finfo',\n",
       " 'fix',\n",
       " 'fix_',\n",
       " 'flatten',\n",
       " 'flip',\n",
       " 'fliplr',\n",
       " 'flipud',\n",
       " 'float',\n",
       " 'float16',\n",
       " 'float32',\n",
       " 'float64',\n",
       " 'float_power',\n",
       " 'floor',\n",
       " 'floor_',\n",
       " 'floor_divide',\n",
       " 'fmax',\n",
       " 'fmin',\n",
       " 'fmod',\n",
       " 'fork',\n",
       " 'frac',\n",
       " 'frac_',\n",
       " 'frexp',\n",
       " 'frobenius_norm',\n",
       " 'from_dlpack',\n",
       " 'from_file',\n",
       " 'from_numpy',\n",
       " 'frombuffer',\n",
       " 'full',\n",
       " 'full_like',\n",
       " 'func',\n",
       " 'functional',\n",
       " 'fused_moving_avg_obs_fake_quant',\n",
       " 'futures',\n",
       " 'fx',\n",
       " 'gather',\n",
       " 'gcd',\n",
       " 'gcd_',\n",
       " 'ge',\n",
       " 'geqrf',\n",
       " 'ger',\n",
       " 'get_autocast_cpu_dtype',\n",
       " 'get_autocast_gpu_dtype',\n",
       " 'get_default_dtype',\n",
       " 'get_deterministic_debug_mode',\n",
       " 'get_device',\n",
       " 'get_file_path',\n",
       " 'get_float32_matmul_precision',\n",
       " 'get_num_interop_threads',\n",
       " 'get_num_threads',\n",
       " 'get_rng_state',\n",
       " 'glob',\n",
       " 'gradient',\n",
       " 'greater',\n",
       " 'greater_equal',\n",
       " 'grid_sampler',\n",
       " 'grid_sampler_2d',\n",
       " 'grid_sampler_3d',\n",
       " 'group_norm',\n",
       " 'gru',\n",
       " 'gru_cell',\n",
       " 'gt',\n",
       " 'half',\n",
       " 'hamming_window',\n",
       " 'hann_window',\n",
       " 'hardshrink',\n",
       " 'has_cuda',\n",
       " 'has_cudnn',\n",
       " 'has_lapack',\n",
       " 'has_mkl',\n",
       " 'has_mkldnn',\n",
       " 'has_mps',\n",
       " 'has_openmp',\n",
       " 'has_spectral',\n",
       " 'heaviside',\n",
       " 'hinge_embedding_loss',\n",
       " 'histc',\n",
       " 'histogram',\n",
       " 'histogramdd',\n",
       " 'hsmm',\n",
       " 'hsplit',\n",
       " 'hspmm',\n",
       " 'hstack',\n",
       " 'hub',\n",
       " 'hypot',\n",
       " 'i0',\n",
       " 'i0_',\n",
       " 'igamma',\n",
       " 'igammac',\n",
       " 'iinfo',\n",
       " 'imag',\n",
       " 'import_ir_module',\n",
       " 'import_ir_module_from_buffer',\n",
       " 'index_add',\n",
       " 'index_copy',\n",
       " 'index_fill',\n",
       " 'index_put',\n",
       " 'index_put_',\n",
       " 'index_reduce',\n",
       " 'index_select',\n",
       " 'indices_copy',\n",
       " 'inf',\n",
       " 'inference_mode',\n",
       " 'init_num_threads',\n",
       " 'initial_seed',\n",
       " 'inner',\n",
       " 'inspect',\n",
       " 'instance_norm',\n",
       " 'int',\n",
       " 'int16',\n",
       " 'int32',\n",
       " 'int64',\n",
       " 'int8',\n",
       " 'int_repr',\n",
       " 'inverse',\n",
       " 'is_anomaly_check_nan_enabled',\n",
       " 'is_anomaly_enabled',\n",
       " 'is_autocast_cache_enabled',\n",
       " 'is_autocast_cpu_enabled',\n",
       " 'is_autocast_enabled',\n",
       " 'is_complex',\n",
       " 'is_conj',\n",
       " 'is_deterministic_algorithms_warn_only_enabled',\n",
       " 'is_distributed',\n",
       " 'is_floating_point',\n",
       " 'is_grad_enabled',\n",
       " 'is_inference',\n",
       " 'is_inference_mode_enabled',\n",
       " 'is_loaded',\n",
       " 'is_neg',\n",
       " 'is_nonzero',\n",
       " 'is_same_size',\n",
       " 'is_signed',\n",
       " 'is_storage',\n",
       " 'is_tensor',\n",
       " 'is_vulkan_available',\n",
       " 'is_warn_always_enabled',\n",
       " 'isclose',\n",
       " 'isfinite',\n",
       " 'isin',\n",
       " 'isinf',\n",
       " 'isnan',\n",
       " 'isneginf',\n",
       " 'isposinf',\n",
       " 'isreal',\n",
       " 'istft',\n",
       " 'jit',\n",
       " 'kaiser_window',\n",
       " 'kernel32',\n",
       " 'kl_div',\n",
       " 'kron',\n",
       " 'kthvalue',\n",
       " 'last_error',\n",
       " 'layer_norm',\n",
       " 'layout',\n",
       " 'lcm',\n",
       " 'lcm_',\n",
       " 'ldexp',\n",
       " 'ldexp_',\n",
       " 'le',\n",
       " 'legacy_contiguous_format',\n",
       " 'lerp',\n",
       " 'less',\n",
       " 'less_equal',\n",
       " 'lgamma',\n",
       " 'library',\n",
       " 'linalg',\n",
       " 'linspace',\n",
       " 'load',\n",
       " 'lobpcg',\n",
       " 'log',\n",
       " 'log10',\n",
       " 'log10_',\n",
       " 'log1p',\n",
       " 'log1p_',\n",
       " 'log2',\n",
       " 'log2_',\n",
       " 'log_',\n",
       " 'log_softmax',\n",
       " 'logaddexp',\n",
       " 'logaddexp2',\n",
       " 'logcumsumexp',\n",
       " 'logdet',\n",
       " 'logical_and',\n",
       " 'logical_not',\n",
       " 'logical_or',\n",
       " 'logical_xor',\n",
       " 'logit',\n",
       " 'logit_',\n",
       " 'logspace',\n",
       " 'logsumexp',\n",
       " 'long',\n",
       " 'lstm',\n",
       " 'lstm_cell',\n",
       " 'lstsq',\n",
       " 'lt',\n",
       " 'lu',\n",
       " 'lu_solve',\n",
       " 'lu_unpack',\n",
       " 'manual_seed',\n",
       " 'margin_ranking_loss',\n",
       " 'masked',\n",
       " 'masked_fill',\n",
       " 'masked_scatter',\n",
       " 'masked_select',\n",
       " 'math',\n",
       " 'matmul',\n",
       " 'matrix_exp',\n",
       " 'matrix_power',\n",
       " 'matrix_rank',\n",
       " 'max',\n",
       " 'max_pool1d',\n",
       " 'max_pool1d_with_indices',\n",
       " 'max_pool2d',\n",
       " 'max_pool3d',\n",
       " 'maximum',\n",
       " 'mean',\n",
       " 'median',\n",
       " 'memory_format',\n",
       " 'merge_type_from_type_comment',\n",
       " 'meshgrid',\n",
       " 'min',\n",
       " 'minimum',\n",
       " 'miopen_batch_norm',\n",
       " 'miopen_convolution',\n",
       " 'miopen_convolution_add_relu',\n",
       " 'miopen_convolution_relu',\n",
       " 'miopen_convolution_transpose',\n",
       " 'miopen_depthwise_convolution',\n",
       " 'miopen_rnn',\n",
       " 'mkldnn_adaptive_avg_pool2d',\n",
       " 'mkldnn_convolution',\n",
       " 'mkldnn_linear_backward_weights',\n",
       " 'mkldnn_max_pool2d',\n",
       " 'mkldnn_max_pool3d',\n",
       " 'mkldnn_rnn_layer',\n",
       " 'mm',\n",
       " 'mode',\n",
       " 'moveaxis',\n",
       " 'movedim',\n",
       " 'mps',\n",
       " 'msort',\n",
       " 'mul',\n",
       " 'multinomial',\n",
       " 'multiply',\n",
       " 'multiprocessing',\n",
       " 'mv',\n",
       " 'mvlgamma',\n",
       " 'name',\n",
       " 'nan',\n",
       " 'nan_to_num',\n",
       " 'nan_to_num_',\n",
       " 'nanmean',\n",
       " 'nanmedian',\n",
       " 'nanquantile',\n",
       " 'nansum',\n",
       " 'narrow',\n",
       " 'narrow_copy',\n",
       " 'native_batch_norm',\n",
       " 'native_channel_shuffle',\n",
       " 'native_dropout',\n",
       " 'native_group_norm',\n",
       " 'native_layer_norm',\n",
       " 'native_norm',\n",
       " 'ne',\n",
       " 'neg',\n",
       " 'neg_',\n",
       " 'negative',\n",
       " 'negative_',\n",
       " 'nested',\n",
       " 'nextafter',\n",
       " 'nn',\n",
       " 'no_grad',\n",
       " 'nonzero',\n",
       " 'norm',\n",
       " 'norm_except_dim',\n",
       " 'normal',\n",
       " ...]"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(torch)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c79e2108",
   "metadata": {},
   "source": [
    "# 텐서 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3ac89d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe(x) :\n",
    "    print('타입 : {}'.format(x.type()))\n",
    "    print('크기 :', x.shape)\n",
    "    print('값 : \\n{}'.format(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3ee3efe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "타입 : torch.FloatTensor\n",
      "크기 : torch.Size([2, 3])\n",
      "값 : \n",
      "tensor([[0.0000e+00, 8.4490e-39, 1.8754e+28],\n",
      "        [3.2175e+21, 5.4124e+22, 1.0016e-11]])\n"
     ]
    }
   ],
   "source": [
    "describe(torch.Tensor(2, 3))  # 2행 3열 차원을 지정하여 랜덤하게 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6574f4bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "타입 : torch.FloatTensor\n",
      "크기 : torch.Size([2, 3])\n",
      "값 : \n",
      "tensor([[0.9665, 0.7399, 0.4517],\n",
      "        [0.4757, 0.7842, 0.1525]])\n"
     ]
    }
   ],
   "source": [
    "describe(torch.rand(2, 3)) # 균등분포"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2132f590",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "타입 : torch.FloatTensor\n",
      "크기 : torch.Size([2, 3])\n",
      "값 : \n",
      "tensor([[-0.4175,  0.7618,  0.5356],\n",
      "        [ 1.5739, -0.4864, -0.6622]])\n"
     ]
    }
   ],
   "source": [
    "describe(torch.randn(2, 3)) # 표준정규분포"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "e4fb4b58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "타입 : torch.FloatTensor\n",
      "크기 : torch.Size([2, 3])\n",
      "값 : \n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "# 동일한 스칼라값으로 채운 텐서\n",
    "describe(torch.zeros(2, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5c5ad35e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "타입 : torch.FloatTensor\n",
      "크기 : torch.Size([2, 3])\n",
      "값 : \n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(2, 3)\n",
    "describe(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d931bdff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "타입 : torch.FloatTensor\n",
      "크기 : torch.Size([2, 3])\n",
      "값 : \n",
      "tensor([[5., 5., 5.],\n",
      "        [5., 5., 5.]])\n"
     ]
    }
   ],
   "source": [
    "x.fill_(5)  # _ : 인플레이스 메서드 ; 텐서값을 바꾸는 연산\n",
    "describe(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "40a02517",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5414, 0.6419],\n",
       "        [0.2976, 0.7077],\n",
       "        [0.4189, 0.0655]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.Tensor(3,2).uniform_() # 인-플레이스 메서드 연결해 텐서를 균등분포로 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5a15dc95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "타입 : torch.FloatTensor\n",
      "크기 : torch.Size([2, 3])\n",
      "값 : \n",
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n",
      "\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "# 리스트 전달\n",
    "x = torch.Tensor([[1, 2, 3], [4, 5, 6]])\n",
    "describe(x)\n",
    "print()\n",
    "print(x.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d641605e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "타입 : torch.DoubleTensor\n",
      "크기 : torch.Size([2, 3])\n",
      "값 : \n",
      "tensor([[0.3101, 0.5414, 0.0767],\n",
      "        [0.8072, 0.7283, 0.2604]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# 넘파이 배열 전달\n",
    "npy = np.random.rand(2, 3) # 균등분포\n",
    "describe(torch.from_numpy(npy))\n",
    "\n",
    "# 랜덤한 넘파이 배열의 기본 데이터 타입은 float64 => DoubleTensor"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c78246bc",
   "metadata": {},
   "source": [
    "# 텐서 타입과 크기\n",
    "\n",
    "float32 : FloatTensor\n",
    "float64 : DoubleTensor\n",
    "int32 : IntTensor\n",
    "int64 : LongTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "53a2e4dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "타입 : torch.FloatTensor\n",
      "크기 : torch.Size([2, 3])\n",
      "값 : \n",
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.FloatTensor([[1, 2, 3], [4, 5, 6]])\n",
    "describe(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "07c5a5f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "타입 : torch.LongTensor\n",
      "크기 : torch.Size([2, 3])\n",
      "값 : \n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "torch.int64\n"
     ]
    }
   ],
   "source": [
    "x = x.long()\n",
    "describe(x)\n",
    "print(x.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d9ddbb53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "타입 : torch.LongTensor\n",
      "크기 : torch.Size([2, 3])\n",
      "값 : \n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[1, 2, 3], [4, 5, 6]], dtype=torch.int64)\n",
    "describe(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3f9c0b3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "타입 : torch.FloatTensor\n",
      "크기 : torch.Size([2, 3])\n",
      "값 : \n",
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "x = x.float()\n",
    "describe(x)\n",
    "print(x.dtype)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e0af48e9",
   "metadata": {},
   "source": [
    "# 텐서 연산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "4afa0b76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "타입 : torch.FloatTensor\n",
      "크기 : torch.Size([2, 3])\n",
      "값 : \n",
      "tensor([[ 0.4501,  0.2709, -0.8087],\n",
      "        [-0.0217, -1.0413,  0.0702]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(2, 3) # 표준정규분포\n",
    "describe(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "2f55ee03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "타입 : torch.FloatTensor\n",
      "크기 : torch.Size([2, 3])\n",
      "값 : \n",
      "tensor([[ 0.9002,  0.5418, -1.6174],\n",
      "        [-0.0434, -2.0826,  0.1405]])\n"
     ]
    }
   ],
   "source": [
    "describe(torch.add(x, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "480d5060",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "타입 : torch.FloatTensor\n",
      "크기 : torch.Size([2, 3])\n",
      "값 : \n",
      "tensor([[ 0.9002,  0.5418, -1.6174],\n",
      "        [-0.0434, -2.0826,  0.1405]])\n"
     ]
    }
   ],
   "source": [
    "describe(x.add_(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5a3a2f19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "타입 : torch.FloatTensor\n",
      "크기 : torch.Size([2, 3])\n",
      "값 : \n",
      "tensor([[ 0.3844,  0.1836, -1.7250],\n",
      "        [ 0.3192,  1.6368, -1.5298]])\n"
     ]
    }
   ],
   "source": [
    "describe(x + x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "d9ac463e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "타입 : torch.LongTensor\n",
      "크기 : torch.Size([6])\n",
      "값 : \n",
      "tensor([0, 1, 2, 3, 4, 5])\n"
     ]
    }
   ],
   "source": [
    "# 특정 차원에 연산 적용\n",
    "x = torch.arange(6)\n",
    "describe(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "26d80607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "타입 : torch.LongTensor\n",
      "크기 : torch.Size([2, 3])\n",
      "값 : \n",
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5]])\n"
     ]
    }
   ],
   "source": [
    "y = x.view(2, 3)  # 동일한 데이터 공유하는 새로운 텐서 생성\n",
    "describe(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "7de93917",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2414806271616\n",
      "2414806271616\n"
     ]
    }
   ],
   "source": [
    "print(x.data_ptr())  # 원본 텐서\n",
    "print(y.data_ptr())  # 뷰 텐서 ; 복사본이 아님, 변경 시 원본도 변경\n",
    "\n",
    "# 같은 저장 위치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e272832a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "타입 : torch.LongTensor\n",
      "크기 : torch.Size([3])\n",
      "값 : \n",
      "tensor([3, 5, 7])\n"
     ]
    }
   ],
   "source": [
    "describe(torch.sum(y, dim=0)) # 행은 차원 0 ; 열끼리 합한 값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "af198e92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "타입 : torch.LongTensor\n",
      "크기 : torch.Size([2])\n",
      "값 : \n",
      "tensor([ 3, 12])\n"
     ]
    }
   ],
   "source": [
    "describe(torch.sum(y, dim=1)) # 열은 차원 1 ; 행끼리 합한 값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "db5442cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "타입 : torch.LongTensor\n",
      "크기 : torch.Size([3, 2])\n",
      "값 : \n",
      "tensor([[0, 3],\n",
      "        [1, 4],\n",
      "        [2, 5]])\n"
     ]
    }
   ],
   "source": [
    "describe(torch.transpose(y, 0, 1)) # 두번째(0), 세번째(1) 매개변수 차원 전치 ; 행열 전환"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6c65382c",
   "metadata": {},
   "source": [
    "# 인덱싱, 슬리이싱, 연결"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5427f039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "타입 : torch.LongTensor\n",
      "크기 : torch.Size([2, 3])\n",
      "값 : \n",
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(6).view(2, 3)\n",
    "describe(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "ec8ff7fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "타입 : torch.LongTensor\n",
      "크기 : torch.Size([1, 2])\n",
      "값 : \n",
      "tensor([[0, 1]])\n"
     ]
    }
   ],
   "source": [
    "describe(x[:1, :2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "828c4abc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "타입 : torch.LongTensor\n",
      "크기 : torch.Size([])\n",
      "값 : \n",
      "1\n"
     ]
    }
   ],
   "source": [
    "describe(x[0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "2dd5072e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "타입 : torch.LongTensor\n",
      "크기 : torch.Size([2, 2])\n",
      "값 : \n",
      "tensor([[0, 2],\n",
      "        [3, 5]])\n"
     ]
    }
   ],
   "source": [
    "indices = torch.LongTensor([0, 2])\n",
    "describe(torch.index_select(x, dim=1, index=indices)) # 열을 기준으로 한 인덱스\n",
    "# index : 1차원 텐서(IntTensor 또는 LongTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "227c7c0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "타입 : torch.LongTensor\n",
      "크기 : torch.Size([2, 2])\n",
      "값 : \n",
      "tensor([[2, 0],\n",
      "        [5, 3]])\n",
      "\n",
      "타입 : torch.LongTensor\n",
      "크기 : torch.Size([2, 5])\n",
      "값 : \n",
      "tensor([[0, 2, 1, 1, 1],\n",
      "        [3, 5, 4, 4, 4]])\n"
     ]
    }
   ],
   "source": [
    "indices = torch.LongTensor([2, 0])\n",
    "describe(torch.index_select(x, dim=1, index=indices))\n",
    "\n",
    "print()\n",
    "\n",
    "indices = torch.LongTensor([0, 2, 1, 1, 1])\n",
    "describe(torch.index_select(x, dim=1, index=indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "69835486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "타입 : torch.LongTensor\n",
      "크기 : torch.Size([2, 3])\n",
      "값 : \n",
      "tensor([[0, 1, 2],\n",
      "        [0, 1, 2]])\n"
     ]
    }
   ],
   "source": [
    "indices = torch.LongTensor([0, 0])\n",
    "describe(torch.index_select(x, dim=0, index = indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "7720de0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "타입 : torch.LongTensor\n",
      "크기 : torch.Size([2, 3])\n",
      "값 : \n",
      "tensor([[3, 4, 5],\n",
      "        [0, 1, 2]])\n",
      "\n",
      "타입 : torch.LongTensor\n",
      "크기 : torch.Size([4, 3])\n",
      "값 : \n",
      "tensor([[0, 1, 2],\n",
      "        [0, 1, 2],\n",
      "        [3, 4, 5],\n",
      "        [3, 4, 5]])\n"
     ]
    }
   ],
   "source": [
    "indices = torch.LongTensor([1, 0])\n",
    "describe(torch.index_select(x, dim=0, index = indices))\n",
    "\n",
    "print()\n",
    "\n",
    "indices = torch.LongTensor([0, 0, 1, 1])\n",
    "describe(torch.index_select(x, dim=0, index = indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "ff3a9571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "타입 : torch.LongTensor\n",
      "크기 : torch.Size([2])\n",
      "값 : \n",
      "tensor([0, 4])\n"
     ]
    }
   ],
   "source": [
    "row_indices = torch.arange(2).long() # [0, 1]\n",
    "col_indices = torch.LongTensor([0, 1])\n",
    "describe(x[row_indices, col_indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "4103a5b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "타입 : torch.LongTensor\n",
      "크기 : torch.Size([4, 3])\n",
      "값 : \n",
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5],\n",
      "        [0, 1, 2],\n",
      "        [3, 4, 5]])\n",
      "---\n",
      "타입 : torch.LongTensor\n",
      "크기 : torch.Size([2, 6])\n",
      "값 : \n",
      "tensor([[0, 1, 2, 0, 1, 2],\n",
      "        [3, 4, 5, 3, 4, 5]])\n"
     ]
    }
   ],
   "source": [
    "# 텐서 연결\n",
    "describe(torch.cat([x, x], dim=0))\n",
    "print('---')\n",
    "describe(torch.cat([x, x], dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "759ac1c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "타입 : torch.LongTensor\n",
      "크기 : torch.Size([2, 2, 3])\n",
      "값 : \n",
      "tensor([[[0, 1, 2],\n",
      "         [3, 4, 5]],\n",
      "\n",
      "        [[0, 1, 2],\n",
      "         [3, 4, 5]]])\n"
     ]
    }
   ],
   "source": [
    "describe(torch.stack([x, x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "9e461ce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "타입 : torch.FloatTensor\n",
      "크기 : torch.Size([2, 3])\n",
      "값 : \n",
      "tensor([[0., 1., 2.],\n",
      "        [3., 4., 5.]])\n"
     ]
    }
   ],
   "source": [
    "# 선형 대수 계산 : 행렬 곱셈\n",
    "x1 = torch.arange(6).view(2, 3).float()\n",
    "describe(x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "8f269e0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "타입 : torch.FloatTensor\n",
      "크기 : torch.Size([3, 2])\n",
      "값 : \n",
      "tensor([[1., 2.],\n",
      "        [1., 2.],\n",
      "        [1., 2.]])\n"
     ]
    }
   ],
   "source": [
    "x2 = torch.ones(3, 2)\n",
    "x2[:, 1] += 1\n",
    "describe(x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "1bec29d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "타입 : torch.FloatTensor\n",
      "크기 : torch.Size([2, 2])\n",
      "값 : \n",
      "tensor([[ 3.,  6.],\n",
      "        [12., 24.]])\n"
     ]
    }
   ],
   "source": [
    "describe(torch.mm(x1, x2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d4612313",
   "metadata": {},
   "outputs": [
    {
     "ename": "_LinAlgError",
     "evalue": "linalg.inv: The diagonal element 3 is zero, the inversion could not be completed because the input matrix is singular.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_LinAlgError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m y \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m10\u001b[39m)\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m3\u001b[39m)\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m----> 2\u001b[0m describe(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minv\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;66;03m# inverse 도 안돼 왜 ??????????\u001b[39;00m\n\u001b[0;32m      3\u001b[0m describe(y)\n",
      "\u001b[1;31m_LinAlgError\u001b[0m: linalg.inv: The diagonal element 3 is zero, the inversion could not be completed because the input matrix is singular."
     ]
    }
   ],
   "source": [
    "y = torch.arange(1,10).view(3, 3).float()\n",
    "describe(torch.linalg.inv(y)) # inverse 도 안돼 왜 ?????????? -> det가 0이어서 => 유사역행렬 사용\n",
    "describe(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "feb7447b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "타입 : torch.FloatTensor\n",
      "크기 : torch.Size([2, 2])\n",
      "값 : \n",
      "tensor([[1., 2.],\n",
      "        [2., 4.]])\n",
      "타입 : torch.FloatTensor\n",
      "크기 : torch.Size([2, 2])\n",
      "값 : \n",
      "tensor([[12096699.0000, -6048350.0000],\n",
      "        [-6048350.5000,  3024175.7500]])\n"
     ]
    }
   ],
   "source": [
    "y1 = torch.tensor([[1,2],[2,4]]).float()\n",
    "describe(y1)\n",
    "describe(torch.pinverse(y1)) # 유사역행렬\n",
    "#describe(torch.linalg.inv(y1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f765475a",
   "metadata": {},
   "outputs": [
    {
     "ename": "_LinAlgError",
     "evalue": "linalg.inv: The diagonal element 3 is zero, the inversion could not be completed because the input matrix is singular.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_LinAlgError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m y \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m9\u001b[39m)\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m3\u001b[39m)\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m----> 2\u001b[0m describe(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minverse\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m      3\u001b[0m describe(torch\u001b[38;5;241m.\u001b[39mpinverse(y))\n",
      "\u001b[1;31m_LinAlgError\u001b[0m: linalg.inv: The diagonal element 3 is zero, the inversion could not be completed because the input matrix is singular."
     ]
    }
   ],
   "source": [
    "y = torch.arange(9).view(3, 3).float()\n",
    "#describe(torch.inverse(y))\n",
    "describe(torch.pinverse(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9bc1f5b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "타입 : torch.FloatTensor\n",
      "크기 : torch.Size([])\n",
      "값 : \n",
      "12.0\n"
     ]
    }
   ],
   "source": [
    "describe(torch.trace(y))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "21570ab6",
   "metadata": {},
   "source": [
    "텐서와 계산 그래프"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "d3e9df0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "타입 : torch.FloatTensor\n",
      "크기 : torch.Size([2, 2])\n",
      "값 : \n",
      "tensor([[1., 1.],\n",
      "        [1., 1.]], requires_grad=True)\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(2, 2, requires_grad=True) # 그레이디언트 계산의 부가 정보 관리\n",
    "describe(x)\n",
    "print(x.grad is None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "a7202cc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "타입 : torch.FloatTensor\n",
      "크기 : torch.Size([2, 2])\n",
      "값 : \n",
      "tensor([[21., 21.],\n",
      "        [21., 21.]], grad_fn=<AddBackward0>)\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "y = (x + 2) * (x + 5) + 3\n",
    "describe(y)\n",
    "print(x.grad is None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "f397e3dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "타입 : torch.FloatTensor\n",
      "크기 : torch.Size([])\n",
      "값 : \n",
      "21.0\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "z = y.mean()\n",
    "describe(z)\n",
    "z.backward()  # 역방향 계산(손실 함수의 평가 결과), 스칼라여야함(아니면 오류)\n",
    "print(x.grad is None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "24c83391",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 조건 그레이디언트\n",
    "def f(x):\n",
    "    if (x.data > 0).all():\n",
    "        return torch.sin(x)\n",
    "    else:\n",
    "        return torch.cos(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "d90ab36e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5403, 0.8776])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1.0, 0.5], requires_grad=True)\n",
    "y = f(x)\n",
    "y.sum().backward()  # 스칼라로 변환, 하지만 sin, cos 계산 수행 X\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "01ff00a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 마스킹 방법\n",
    "def f2(x):\n",
    "    mask = torch.gt(x, 0).float()  # torch.gt는 크면 True, 작거나 같으면 False\n",
    "    return mask * torch.sin(x) + (1 - mask) * torch.cos(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "60ec3fb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5403, 0.8415])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1.0, -1], requires_grad=True)\n",
    "y = f2(x)\n",
    "y.sum().backward()\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "dc590fd3",
   "metadata": {},
   "source": [
    "# CUDA 텐서"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "19027f72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "763bddff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow-gpu==2.3.0\n",
      "  Downloading tensorflow_gpu-2.3.0-cp38-cp38-win_amd64.whl (344.2 MB)\n",
      "     ---------------------------------------- 0.0/344.2 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.4/344.2 MB 7.4 MB/s eta 0:00:47\n",
      "     ---------------------------------------- 0.8/344.2 MB 8.6 MB/s eta 0:00:40\n",
      "     ---------------------------------------- 1.3/344.2 MB 9.3 MB/s eta 0:00:37\n",
      "     ---------------------------------------- 1.8/344.2 MB 9.7 MB/s eta 0:00:36\n",
      "     --------------------------------------- 2.3/344.2 MB 10.7 MB/s eta 0:00:33\n",
      "     --------------------------------------- 3.0/344.2 MB 10.6 MB/s eta 0:00:33\n",
      "     --------------------------------------- 3.5/344.2 MB 10.5 MB/s eta 0:00:33\n",
      "     ---------------------------------------- 4.0/344.2 MB 9.7 MB/s eta 0:00:35\n",
      "     ---------------------------------------- 4.2/344.2 MB 9.7 MB/s eta 0:00:36\n",
      "     ---------------------------------------- 4.3/344.2 MB 8.6 MB/s eta 0:00:40\n",
      "      --------------------------------------- 4.3/344.2 MB 7.9 MB/s eta 0:00:43\n",
      "      --------------------------------------- 4.8/344.2 MB 8.1 MB/s eta 0:00:43\n",
      "      --------------------------------------- 5.4/344.2 MB 8.3 MB/s eta 0:00:41\n",
      "      --------------------------------------- 5.7/344.2 MB 8.5 MB/s eta 0:00:40\n",
      "      --------------------------------------- 6.1/344.2 MB 8.2 MB/s eta 0:00:42\n",
      "      --------------------------------------- 6.6/344.2 MB 8.6 MB/s eta 0:00:40\n",
      "      --------------------------------------- 7.1/344.2 MB 8.8 MB/s eta 0:00:39\n",
      "      --------------------------------------- 7.9/344.2 MB 9.0 MB/s eta 0:00:38\n",
      "      --------------------------------------- 8.6/344.2 MB 9.1 MB/s eta 0:00:37\n",
      "     - -------------------------------------- 9.2/344.2 MB 9.2 MB/s eta 0:00:37\n",
      "     - -------------------------------------- 9.8/344.2 MB 9.3 MB/s eta 0:00:36\n",
      "     - ------------------------------------- 10.3/344.2 MB 9.5 MB/s eta 0:00:36\n",
      "     - ------------------------------------- 10.8/344.2 MB 9.6 MB/s eta 0:00:35\n",
      "     - ------------------------------------- 11.4/344.2 MB 9.6 MB/s eta 0:00:35\n",
      "     - ------------------------------------- 11.9/344.2 MB 9.6 MB/s eta 0:00:35\n",
      "     - ------------------------------------- 12.5/344.2 MB 9.6 MB/s eta 0:00:35\n",
      "     - ------------------------------------- 13.0/344.2 MB 9.6 MB/s eta 0:00:35\n",
      "     - ------------------------------------- 13.6/344.2 MB 9.8 MB/s eta 0:00:34\n",
      "     - ------------------------------------ 14.2/344.2 MB 10.1 MB/s eta 0:00:33\n",
      "     - ------------------------------------ 14.8/344.2 MB 11.3 MB/s eta 0:00:30\n",
      "     - ------------------------------------ 15.3/344.2 MB 11.3 MB/s eta 0:00:30\n",
      "     - ------------------------------------ 15.9/344.2 MB 11.5 MB/s eta 0:00:29\n",
      "     - ------------------------------------ 16.4/344.2 MB 11.7 MB/s eta 0:00:29\n",
      "     - ------------------------------------ 16.9/344.2 MB 11.7 MB/s eta 0:00:28\n",
      "     - ------------------------------------ 17.5/344.2 MB 11.7 MB/s eta 0:00:28\n",
      "     - ------------------------------------ 18.0/344.2 MB 11.7 MB/s eta 0:00:28\n",
      "     -- ----------------------------------- 18.4/344.2 MB 11.7 MB/s eta 0:00:28\n",
      "     -- ----------------------------------- 19.1/344.2 MB 11.7 MB/s eta 0:00:28\n",
      "     -- ----------------------------------- 19.6/344.2 MB 11.7 MB/s eta 0:00:28\n",
      "     -- ----------------------------------- 20.2/344.2 MB 11.9 MB/s eta 0:00:28\n",
      "     -- ----------------------------------- 20.9/344.2 MB 11.9 MB/s eta 0:00:28\n",
      "     -- ----------------------------------- 21.6/344.2 MB 11.9 MB/s eta 0:00:28\n",
      "     -- ----------------------------------- 22.1/344.2 MB 11.7 MB/s eta 0:00:28\n",
      "     -- ----------------------------------- 22.7/344.2 MB 11.7 MB/s eta 0:00:28\n",
      "     -- ----------------------------------- 23.2/344.2 MB 11.7 MB/s eta 0:00:28\n",
      "     -- ----------------------------------- 23.7/344.2 MB 11.7 MB/s eta 0:00:28\n",
      "     -- ----------------------------------- 24.3/344.2 MB 11.7 MB/s eta 0:00:28\n",
      "     -- ----------------------------------- 24.8/344.2 MB 11.7 MB/s eta 0:00:28\n",
      "     -- ----------------------------------- 25.5/344.2 MB 11.9 MB/s eta 0:00:27\n",
      "     -- ----------------------------------- 26.2/344.2 MB 11.9 MB/s eta 0:00:27\n",
      "     -- ----------------------------------- 26.8/344.2 MB 11.9 MB/s eta 0:00:27\n",
      "     --- ---------------------------------- 27.3/344.2 MB 11.9 MB/s eta 0:00:27\n",
      "     --- ---------------------------------- 27.9/344.2 MB 11.9 MB/s eta 0:00:27\n",
      "     --- ---------------------------------- 28.4/344.2 MB 11.9 MB/s eta 0:00:27\n",
      "     --- ---------------------------------- 28.9/344.2 MB 11.9 MB/s eta 0:00:27\n",
      "     --- ---------------------------------- 29.5/344.2 MB 11.7 MB/s eta 0:00:27\n",
      "     --- ---------------------------------- 30.0/344.2 MB 11.7 MB/s eta 0:00:27\n",
      "     --- ---------------------------------- 30.5/344.2 MB 11.7 MB/s eta 0:00:27\n",
      "     --- ---------------------------------- 31.1/344.2 MB 11.7 MB/s eta 0:00:27\n",
      "     --- ---------------------------------- 31.8/344.2 MB 11.9 MB/s eta 0:00:27\n",
      "     --- ---------------------------------- 32.5/344.2 MB 11.9 MB/s eta 0:00:27\n",
      "     --- ---------------------------------- 33.3/344.2 MB 11.9 MB/s eta 0:00:27\n",
      "     --- ---------------------------------- 33.8/344.2 MB 11.9 MB/s eta 0:00:27\n",
      "     --- ---------------------------------- 34.3/344.2 MB 11.9 MB/s eta 0:00:27\n",
      "     --- ---------------------------------- 34.9/344.2 MB 11.9 MB/s eta 0:00:26\n",
      "     --- ---------------------------------- 35.4/344.2 MB 11.9 MB/s eta 0:00:26\n",
      "     --- ---------------------------------- 36.0/344.2 MB 11.9 MB/s eta 0:00:26\n",
      "     ---- --------------------------------- 36.5/344.2 MB 11.7 MB/s eta 0:00:27\n",
      "     ---- --------------------------------- 37.0/344.2 MB 11.7 MB/s eta 0:00:27\n",
      "     ---- --------------------------------- 37.6/344.2 MB 11.9 MB/s eta 0:00:26\n",
      "     ---- --------------------------------- 38.3/344.2 MB 11.9 MB/s eta 0:00:26\n",
      "     ---- --------------------------------- 39.0/344.2 MB 11.9 MB/s eta 0:00:26\n",
      "     ---- --------------------------------- 39.5/344.2 MB 11.9 MB/s eta 0:00:26\n",
      "     ---- --------------------------------- 40.1/344.2 MB 11.9 MB/s eta 0:00:26\n",
      "     ---- --------------------------------- 40.6/344.2 MB 11.9 MB/s eta 0:00:26\n",
      "     ---- --------------------------------- 40.9/344.2 MB 11.9 MB/s eta 0:00:26\n",
      "     ---- --------------------------------- 40.9/344.2 MB 11.9 MB/s eta 0:00:26\n",
      "     ---- --------------------------------- 40.9/344.2 MB 11.9 MB/s eta 0:00:26\n",
      "     ---- --------------------------------- 41.3/344.2 MB 10.2 MB/s eta 0:00:30\n",
      "     ---- --------------------------------- 41.8/344.2 MB 10.2 MB/s eta 0:00:30\n",
      "     ---- --------------------------------- 42.4/344.2 MB 10.2 MB/s eta 0:00:30\n",
      "     ---- --------------------------------- 42.9/344.2 MB 10.4 MB/s eta 0:00:29\n",
      "     ---- --------------------------------- 43.0/344.2 MB 10.4 MB/s eta 0:00:29\n",
      "     ---- --------------------------------- 43.0/344.2 MB 10.4 MB/s eta 0:00:29\n",
      "     ---- ---------------------------------- 43.2/344.2 MB 9.1 MB/s eta 0:00:34\n",
      "     ---- ---------------------------------- 43.9/344.2 MB 9.1 MB/s eta 0:00:34\n",
      "     ----- --------------------------------- 44.7/344.2 MB 9.1 MB/s eta 0:00:33\n",
      "     ----- --------------------------------- 45.1/344.2 MB 9.1 MB/s eta 0:00:33\n",
      "     ----- --------------------------------- 45.1/344.2 MB 9.1 MB/s eta 0:00:33\n",
      "     ----- --------------------------------- 45.1/344.2 MB 9.1 MB/s eta 0:00:33\n",
      "     ----- --------------------------------- 45.3/344.2 MB 8.0 MB/s eta 0:00:38\n",
      "     ----- --------------------------------- 45.8/344.2 MB 8.0 MB/s eta 0:00:38\n",
      "     ----- --------------------------------- 46.4/344.2 MB 8.0 MB/s eta 0:00:38\n",
      "     ----- --------------------------------- 47.1/344.2 MB 8.1 MB/s eta 0:00:37\n",
      "     ----- --------------------------------- 47.8/344.2 MB 8.1 MB/s eta 0:00:37\n",
      "     ----- --------------------------------- 48.2/344.2 MB 8.1 MB/s eta 0:00:37\n",
      "     ----- --------------------------------- 48.2/344.2 MB 8.1 MB/s eta 0:00:37\n",
      "     ----- --------------------------------- 48.2/344.2 MB 8.1 MB/s eta 0:00:37\n",
      "     ----- --------------------------------- 48.6/344.2 MB 7.4 MB/s eta 0:00:41\n",
      "     ----- --------------------------------- 49.1/344.2 MB 7.4 MB/s eta 0:00:41\n",
      "     ----- --------------------------------- 49.6/344.2 MB 7.3 MB/s eta 0:00:41\n",
      "     ----- --------------------------------- 50.2/344.2 MB 7.3 MB/s eta 0:00:41\n",
      "     ----- --------------------------------- 50.8/344.2 MB 7.3 MB/s eta 0:00:41\n",
      "     ----- --------------------------------- 51.3/344.2 MB 8.1 MB/s eta 0:00:37\n",
      "     ----- --------------------------------- 51.8/344.2 MB 8.2 MB/s eta 0:00:36\n",
      "     ----- --------------------------------- 52.4/344.2 MB 8.1 MB/s eta 0:00:37\n",
      "     ------ -------------------------------- 53.1/344.2 MB 8.1 MB/s eta 0:00:37\n",
      "     ------ -------------------------------- 53.8/344.2 MB 9.1 MB/s eta 0:00:32\n",
      "     ------ -------------------------------- 54.4/344.2 MB 9.1 MB/s eta 0:00:32\n",
      "     ------ -------------------------------- 54.9/344.2 MB 9.1 MB/s eta 0:00:32\n",
      "     ------ ------------------------------- 55.4/344.2 MB 10.4 MB/s eta 0:00:28\n",
      "     ------ ------------------------------- 56.0/344.2 MB 10.4 MB/s eta 0:00:28\n",
      "     ------ ------------------------------- 56.5/344.2 MB 10.4 MB/s eta 0:00:28\n",
      "     ------ ------------------------------- 57.1/344.2 MB 10.4 MB/s eta 0:00:28\n",
      "     ------ ------------------------------- 57.6/344.2 MB 10.4 MB/s eta 0:00:28\n",
      "     ------ ------------------------------- 58.2/344.2 MB 10.4 MB/s eta 0:00:28\n",
      "     ------ ------------------------------- 58.7/344.2 MB 11.7 MB/s eta 0:00:25\n",
      "     ------ ------------------------------- 58.7/344.2 MB 11.7 MB/s eta 0:00:25\n",
      "     ------ ------------------------------- 58.7/344.2 MB 11.7 MB/s eta 0:00:25\n",
      "     ------ ------------------------------- 59.0/344.2 MB 10.6 MB/s eta 0:00:28\n",
      "     ------ ------------------------------- 59.7/344.2 MB 10.6 MB/s eta 0:00:27\n",
      "     ------ ------------------------------- 60.4/344.2 MB 10.6 MB/s eta 0:00:27\n",
      "     ------ ------------------------------- 61.0/344.2 MB 10.6 MB/s eta 0:00:27\n",
      "     ------ ------------------------------- 61.5/344.2 MB 10.6 MB/s eta 0:00:27\n",
      "     ------ ------------------------------- 62.1/344.2 MB 10.4 MB/s eta 0:00:28\n",
      "     ------ ------------------------------- 62.6/344.2 MB 10.6 MB/s eta 0:00:27\n",
      "     ------ ------------------------------- 63.2/344.2 MB 10.4 MB/s eta 0:00:28\n",
      "     ------- ------------------------------ 63.7/344.2 MB 10.4 MB/s eta 0:00:27\n",
      "     ------- ------------------------------ 64.2/344.2 MB 10.4 MB/s eta 0:00:27\n",
      "     ------- ------------------------------ 64.8/344.2 MB 10.4 MB/s eta 0:00:27\n",
      "     ------- ------------------------------ 65.3/344.2 MB 10.4 MB/s eta 0:00:27\n",
      "     ------- ------------------------------ 65.9/344.2 MB 10.4 MB/s eta 0:00:27\n",
      "     ------- ------------------------------ 66.1/344.2 MB 10.4 MB/s eta 0:00:27\n",
      "     ------- ------------------------------ 66.1/344.2 MB 10.4 MB/s eta 0:00:27\n",
      "     ------- ------------------------------- 66.3/344.2 MB 9.4 MB/s eta 0:00:30\n",
      "     ------- ------------------------------- 67.0/344.2 MB 9.4 MB/s eta 0:00:30\n",
      "     ------- ------------------------------- 67.5/344.2 MB 9.4 MB/s eta 0:00:30\n",
      "     ------- ------------------------------- 68.0/344.2 MB 9.4 MB/s eta 0:00:30\n",
      "     ------- ------------------------------- 68.2/344.2 MB 9.2 MB/s eta 0:00:30\n",
      "     ------- ------------------------------- 68.2/344.2 MB 9.2 MB/s eta 0:00:30\n",
      "     ------- ------------------------------- 68.2/344.2 MB 9.2 MB/s eta 0:00:30\n",
      "     ------- ------------------------------- 68.5/344.2 MB 8.2 MB/s eta 0:00:34\n",
      "     ------- ------------------------------- 69.1/344.2 MB 9.1 MB/s eta 0:00:31\n",
      "     ------- ------------------------------- 69.6/344.2 MB 9.1 MB/s eta 0:00:31\n",
      "     ------- ------------------------------- 70.3/344.2 MB 9.2 MB/s eta 0:00:30\n",
      "     -------- ------------------------------ 71.0/344.2 MB 9.1 MB/s eta 0:00:31\n",
      "     -------- ------------------------------ 71.6/344.2 MB 9.1 MB/s eta 0:00:30\n",
      "     -------- ------------------------------ 72.2/344.2 MB 9.1 MB/s eta 0:00:30\n",
      "     -------- ------------------------------ 72.7/344.2 MB 9.1 MB/s eta 0:00:30\n",
      "     -------- ------------------------------ 73.2/344.2 MB 9.1 MB/s eta 0:00:30\n",
      "     -------- ------------------------------ 73.7/344.2 MB 9.1 MB/s eta 0:00:30\n",
      "     -------- ------------------------------ 74.3/344.2 MB 9.1 MB/s eta 0:00:30\n",
      "     -------- ------------------------------ 74.8/344.2 MB 9.1 MB/s eta 0:00:30\n",
      "     -------- ------------------------------ 75.3/344.2 MB 9.2 MB/s eta 0:00:30\n",
      "     -------- ------------------------------ 76.1/344.2 MB 9.1 MB/s eta 0:00:30\n",
      "     -------- ----------------------------- 76.8/344.2 MB 10.2 MB/s eta 0:00:27\n",
      "     -------- ----------------------------- 77.5/344.2 MB 10.2 MB/s eta 0:00:27\n",
      "     -------- ----------------------------- 78.0/344.2 MB 10.2 MB/s eta 0:00:27\n",
      "     -------- ----------------------------- 78.6/344.2 MB 11.9 MB/s eta 0:00:23\n",
      "     -------- ----------------------------- 79.1/344.2 MB 11.9 MB/s eta 0:00:23\n",
      "     -------- ----------------------------- 79.7/344.2 MB 11.9 MB/s eta 0:00:23\n",
      "     -------- ----------------------------- 80.2/344.2 MB 11.7 MB/s eta 0:00:23\n",
      "     -------- ----------------------------- 80.7/344.2 MB 11.7 MB/s eta 0:00:23\n",
      "     -------- ----------------------------- 80.7/344.2 MB 11.7 MB/s eta 0:00:23\n",
      "     -------- ----------------------------- 80.7/344.2 MB 11.7 MB/s eta 0:00:23\n",
      "     -------- ----------------------------- 80.9/344.2 MB 10.2 MB/s eta 0:00:26\n",
      "     --------- ---------------------------- 81.6/344.2 MB 10.4 MB/s eta 0:00:26\n",
      "     --------- ---------------------------- 82.4/344.2 MB 10.4 MB/s eta 0:00:26\n",
      "     --------- ---------------------------- 83.1/344.2 MB 10.4 MB/s eta 0:00:26\n",
      "     --------- ---------------------------- 83.6/344.2 MB 10.4 MB/s eta 0:00:26\n",
      "     --------- ---------------------------- 84.1/344.2 MB 10.4 MB/s eta 0:00:26\n",
      "     --------- ---------------------------- 84.7/344.2 MB 10.2 MB/s eta 0:00:26\n",
      "     --------- ---------------------------- 84.9/344.2 MB 10.4 MB/s eta 0:00:25\n",
      "     --------- ---------------------------- 84.9/344.2 MB 10.4 MB/s eta 0:00:25\n",
      "     --------- ---------------------------- 84.9/344.2 MB 10.4 MB/s eta 0:00:25\n",
      "     --------- ---------------------------- 84.9/344.2 MB 10.4 MB/s eta 0:00:25\n",
      "     --------- ---------------------------- 84.9/344.2 MB 10.4 MB/s eta 0:00:25\n",
      "     --------- ----------------------------- 85.4/344.2 MB 8.4 MB/s eta 0:00:31\n",
      "     --------- ----------------------------- 86.1/344.2 MB 8.4 MB/s eta 0:00:31\n",
      "     --------- ----------------------------- 86.6/344.2 MB 8.4 MB/s eta 0:00:31\n",
      "     --------- ----------------------------- 87.2/344.2 MB 8.4 MB/s eta 0:00:31\n",
      "     --------- ----------------------------- 87.7/344.2 MB 8.4 MB/s eta 0:00:31\n",
      "     ---------- ---------------------------- 88.3/344.2 MB 8.4 MB/s eta 0:00:31\n",
      "     ---------- ---------------------------- 88.8/344.2 MB 8.4 MB/s eta 0:00:31\n",
      "     ---------- ---------------------------- 89.3/344.2 MB 8.4 MB/s eta 0:00:31\n",
      "     ---------- ---------------------------- 89.9/344.2 MB 8.5 MB/s eta 0:00:30\n",
      "     ---------- ---------------------------- 90.6/344.2 MB 8.4 MB/s eta 0:00:31\n",
      "     ---------- ---------------------------- 91.3/344.2 MB 9.4 MB/s eta 0:00:28\n",
      "     ---------- ---------------------------- 91.8/344.2 MB 9.4 MB/s eta 0:00:27\n",
      "     ---------- ---------------------------- 92.4/344.2 MB 9.4 MB/s eta 0:00:27\n",
      "     ---------- ---------------------------- 92.9/344.2 MB 9.4 MB/s eta 0:00:27\n",
      "     ---------- ---------------------------- 93.4/344.2 MB 9.4 MB/s eta 0:00:27\n",
      "     ---------- ---------------------------- 94.0/344.2 MB 9.4 MB/s eta 0:00:27\n",
      "     ---------- ---------------------------- 94.5/344.2 MB 9.5 MB/s eta 0:00:27\n",
      "     ---------- --------------------------- 95.2/344.2 MB 11.9 MB/s eta 0:00:21\n",
      "     ---------- --------------------------- 95.9/344.2 MB 11.9 MB/s eta 0:00:21\n",
      "     ---------- --------------------------- 96.5/344.2 MB 11.9 MB/s eta 0:00:21\n",
      "     ---------- --------------------------- 97.0/344.2 MB 11.9 MB/s eta 0:00:21\n",
      "     ---------- --------------------------- 97.5/344.2 MB 11.9 MB/s eta 0:00:21\n",
      "     ---------- --------------------------- 98.1/344.2 MB 11.9 MB/s eta 0:00:21\n",
      "     ---------- --------------------------- 98.6/344.2 MB 11.7 MB/s eta 0:00:22\n",
      "     ---------- --------------------------- 99.1/344.2 MB 11.7 MB/s eta 0:00:21\n",
      "     ----------- -------------------------- 99.7/344.2 MB 11.9 MB/s eta 0:00:21\n",
      "     ---------- -------------------------- 100.4/344.2 MB 11.9 MB/s eta 0:00:21\n",
      "     ---------- -------------------------- 101.1/344.2 MB 11.9 MB/s eta 0:00:21\n",
      "     ---------- -------------------------- 101.7/344.2 MB 11.9 MB/s eta 0:00:21\n",
      "     ---------- -------------------------- 101.7/344.2 MB 11.9 MB/s eta 0:00:21\n",
      "     ---------- -------------------------- 101.7/344.2 MB 11.9 MB/s eta 0:00:21\n",
      "     ---------- -------------------------- 101.7/344.2 MB 11.9 MB/s eta 0:00:21\n",
      "     ---------- -------------------------- 102.3/344.2 MB 10.1 MB/s eta 0:00:24\n",
      "     ----------- -------------------------- 102.9/344.2 MB 9.9 MB/s eta 0:00:25\n",
      "     ----------- -------------------------- 103.4/344.2 MB 9.9 MB/s eta 0:00:25\n",
      "     ----------- -------------------------- 103.9/344.2 MB 9.9 MB/s eta 0:00:25\n",
      "     ----------- ------------------------- 104.4/344.2 MB 10.1 MB/s eta 0:00:24\n",
      "     ----------- ------------------------- 105.2/344.2 MB 10.1 MB/s eta 0:00:24\n",
      "     ----------- ------------------------- 105.9/344.2 MB 10.1 MB/s eta 0:00:24\n",
      "     ----------- ------------------------- 106.4/344.2 MB 10.1 MB/s eta 0:00:24\n",
      "     ----------- -------------------------- 106.9/344.2 MB 9.9 MB/s eta 0:00:24\n",
      "     ----------- -------------------------- 106.9/344.2 MB 9.9 MB/s eta 0:00:24\n",
      "     ----------- -------------------------- 106.9/344.2 MB 9.9 MB/s eta 0:00:24\n",
      "     ----------- -------------------------- 107.1/344.2 MB 8.8 MB/s eta 0:00:27\n",
      "     ----------- -------------------------- 107.6/344.2 MB 8.8 MB/s eta 0:00:27\n",
      "     ----------- -------------------------- 108.0/344.2 MB 8.8 MB/s eta 0:00:27\n",
      "     ----------- -------------------------- 108.0/344.2 MB 8.8 MB/s eta 0:00:27\n",
      "     ----------- -------------------------- 108.0/344.2 MB 8.8 MB/s eta 0:00:27\n",
      "     ----------- -------------------------- 108.3/344.2 MB 8.1 MB/s eta 0:00:30\n",
      "     ------------ ------------------------- 109.1/344.2 MB 8.1 MB/s eta 0:00:30\n",
      "     ------------ ------------------------- 109.8/344.2 MB 8.1 MB/s eta 0:00:29\n",
      "     ------------ ------------------------- 110.1/344.2 MB 8.1 MB/s eta 0:00:29\n",
      "     ------------ ------------------------- 110.1/344.2 MB 8.1 MB/s eta 0:00:29\n",
      "     ------------ ------------------------- 110.1/344.2 MB 8.1 MB/s eta 0:00:29\n",
      "     ------------ ------------------------- 110.1/344.2 MB 8.1 MB/s eta 0:00:29\n",
      "     ------------ ------------------------- 110.1/344.2 MB 8.1 MB/s eta 0:00:29\n",
      "     ------------ ------------------------- 110.1/344.2 MB 8.1 MB/s eta 0:00:29\n",
      "     ------------ ------------------------- 110.1/344.2 MB 8.1 MB/s eta 0:00:29\n",
      "     ------------ ------------------------- 110.1/344.2 MB 8.1 MB/s eta 0:00:29\n",
      "     ------------ ------------------------- 110.1/344.2 MB 8.1 MB/s eta 0:00:29\n",
      "     ------------ ------------------------- 110.1/344.2 MB 8.1 MB/s eta 0:00:29\n",
      "     ------------ ------------------------- 110.1/344.2 MB 8.1 MB/s eta 0:00:29\n",
      "     ------------ ------------------------- 110.1/344.2 MB 8.1 MB/s eta 0:00:29\n",
      "     ------------ ------------------------- 110.1/344.2 MB 8.1 MB/s eta 0:00:29\n",
      "     ------------ ------------------------- 110.1/344.2 MB 8.1 MB/s eta 0:00:29\n",
      "     ------------ ------------------------- 110.1/344.2 MB 8.1 MB/s eta 0:00:29\n",
      "     ------------ ------------------------- 110.1/344.2 MB 8.1 MB/s eta 0:00:29\n",
      "     ------------ ------------------------- 110.1/344.2 MB 8.1 MB/s eta 0:00:29\n",
      "     ------------ ------------------------- 110.1/344.2 MB 8.1 MB/s eta 0:00:29\n",
      "     ------------ ------------------------- 110.1/344.2 MB 8.1 MB/s eta 0:00:29\n",
      "     ------------ ------------------------- 110.1/344.2 MB 8.1 MB/s eta 0:00:29\n",
      "     ------------ ------------------------- 110.6/344.2 MB 4.4 MB/s eta 0:00:53\n",
      "     ------------ ------------------------- 111.1/344.2 MB 4.4 MB/s eta 0:00:53\n",
      "     ------------ ------------------------- 111.6/344.2 MB 4.4 MB/s eta 0:00:53\n",
      "     ------------ ------------------------- 112.2/344.2 MB 4.7 MB/s eta 0:00:49\n",
      "     ------------ ------------------------- 112.7/344.2 MB 4.7 MB/s eta 0:00:49\n",
      "     ------------ ------------------------- 113.3/344.2 MB 4.8 MB/s eta 0:00:49\n",
      "     ------------ ------------------------- 113.8/344.2 MB 4.8 MB/s eta 0:00:49\n",
      "     ------------ ------------------------- 114.5/344.2 MB 4.8 MB/s eta 0:00:49\n",
      "     ------------ ------------------------- 115.2/344.2 MB 4.8 MB/s eta 0:00:48\n",
      "     ------------ ------------------------- 115.3/344.2 MB 4.7 MB/s eta 0:00:49\n",
      "     ------------ ------------------------- 115.3/344.2 MB 4.7 MB/s eta 0:00:49\n",
      "     ------------ ------------------------- 115.3/344.2 MB 4.7 MB/s eta 0:00:49\n",
      "     ------------ ------------------------- 115.9/344.2 MB 4.5 MB/s eta 0:00:51\n",
      "     ------------ ------------------------- 116.4/344.2 MB 4.5 MB/s eta 0:00:51\n",
      "     ------------ ------------------------- 116.9/344.2 MB 4.5 MB/s eta 0:00:51\n",
      "     ------------ ------------------------- 117.6/344.2 MB 4.8 MB/s eta 0:00:48\n",
      "     ------------- ------------------------ 118.4/344.2 MB 5.0 MB/s eta 0:00:45\n",
      "     ------------- ------------------------ 118.9/344.2 MB 5.0 MB/s eta 0:00:45\n",
      "     ------------- ------------------------ 119.4/344.2 MB 5.0 MB/s eta 0:00:45\n",
      "     ------------- ------------------------ 120.0/344.2 MB 5.0 MB/s eta 0:00:45\n",
      "     ------------ ------------------------ 120.5/344.2 MB 10.2 MB/s eta 0:00:22\n",
      "     ------------- ----------------------- 121.1/344.2 MB 10.4 MB/s eta 0:00:22\n",
      "     ------------- ----------------------- 121.6/344.2 MB 10.2 MB/s eta 0:00:22\n",
      "     ------------- ----------------------- 122.2/344.2 MB 10.2 MB/s eta 0:00:22\n",
      "     ------------- ----------------------- 122.7/344.2 MB 10.2 MB/s eta 0:00:22\n",
      "     ------------- ----------------------- 123.2/344.2 MB 10.2 MB/s eta 0:00:22\n",
      "     ------------- ----------------------- 123.8/344.2 MB 10.4 MB/s eta 0:00:22\n",
      "     ------------- ----------------------- 124.3/344.2 MB 10.4 MB/s eta 0:00:22\n",
      "     ------------- ----------------------- 124.8/344.2 MB 10.2 MB/s eta 0:00:22\n",
      "     ------------- ----------------------- 124.8/344.2 MB 10.2 MB/s eta 0:00:22\n",
      "     ------------- ----------------------- 124.8/344.2 MB 10.2 MB/s eta 0:00:22\n",
      "     ------------- ------------------------ 125.0/344.2 MB 9.1 MB/s eta 0:00:25\n",
      "     ------------- ------------------------ 125.6/344.2 MB 9.1 MB/s eta 0:00:25\n",
      "     ------------- ----------------------- 125.8/344.2 MB 10.2 MB/s eta 0:00:22\n",
      "     ------------- ----------------------- 125.8/344.2 MB 10.2 MB/s eta 0:00:22\n",
      "     ------------- ------------------------ 125.9/344.2 MB 9.2 MB/s eta 0:00:24\n",
      "     ------------- ------------------------ 126.6/344.2 MB 9.2 MB/s eta 0:00:24\n",
      "     -------------- ----------------------- 127.1/344.2 MB 9.1 MB/s eta 0:00:24\n",
      "     -------------- ----------------------- 127.7/344.2 MB 9.1 MB/s eta 0:00:24\n",
      "     -------------- ----------------------- 128.2/344.2 MB 9.2 MB/s eta 0:00:24\n",
      "     -------------- ----------------------- 128.9/344.2 MB 9.2 MB/s eta 0:00:24\n",
      "     -------------- ----------------------- 129.7/344.2 MB 9.2 MB/s eta 0:00:24\n",
      "     -------------- ----------------------- 130.4/344.2 MB 9.2 MB/s eta 0:00:24\n",
      "     -------------- ----------------------- 130.9/344.2 MB 9.2 MB/s eta 0:00:24\n",
      "     -------------- ----------------------- 131.5/344.2 MB 9.2 MB/s eta 0:00:24\n",
      "     -------------- ----------------------- 132.0/344.2 MB 9.2 MB/s eta 0:00:23\n",
      "     -------------- ----------------------- 132.5/344.2 MB 9.2 MB/s eta 0:00:23\n",
      "     -------------- ----------------------- 133.1/344.2 MB 9.2 MB/s eta 0:00:23\n",
      "     -------------- ----------------------- 133.6/344.2 MB 9.2 MB/s eta 0:00:23\n",
      "     -------------- ----------------------- 134.2/344.2 MB 9.1 MB/s eta 0:00:24\n",
      "     -------------- ----------------------- 134.7/344.2 MB 9.1 MB/s eta 0:00:24\n",
      "     -------------- ---------------------- 135.2/344.2 MB 10.6 MB/s eta 0:00:20\n",
      "     -------------- ---------------------- 136.0/344.2 MB 10.6 MB/s eta 0:00:20\n",
      "     -------------- ---------------------- 136.3/344.2 MB 11.9 MB/s eta 0:00:18\n",
      "     -------------- ---------------------- 136.3/344.2 MB 11.9 MB/s eta 0:00:18\n",
      "     -------------- ---------------------- 136.3/344.2 MB 11.9 MB/s eta 0:00:18\n",
      "     -------------- ---------------------- 136.7/344.2 MB 10.2 MB/s eta 0:00:21\n",
      "     -------------- ---------------------- 137.2/344.2 MB 10.2 MB/s eta 0:00:21\n",
      "     -------------- ---------------------- 137.8/344.2 MB 10.2 MB/s eta 0:00:21\n",
      "     -------------- ---------------------- 138.3/344.2 MB 10.2 MB/s eta 0:00:21\n",
      "     -------------- ---------------------- 138.9/344.2 MB 10.2 MB/s eta 0:00:21\n",
      "     -------------- ---------------------- 139.4/344.2 MB 10.2 MB/s eta 0:00:21\n",
      "     --------------- --------------------- 140.1/344.2 MB 10.2 MB/s eta 0:00:20\n",
      "     --------------- --------------------- 140.8/344.2 MB 10.2 MB/s eta 0:00:20\n",
      "     --------------- --------------------- 141.4/344.2 MB 10.2 MB/s eta 0:00:20\n",
      "     --------------- --------------------- 142.1/344.2 MB 10.2 MB/s eta 0:00:20\n",
      "     --------------- --------------------- 142.6/344.2 MB 10.2 MB/s eta 0:00:20\n",
      "     --------------- --------------------- 142.6/344.2 MB 10.2 MB/s eta 0:00:20\n",
      "     --------------- --------------------- 142.6/344.2 MB 10.2 MB/s eta 0:00:20\n",
      "     --------------- ---------------------- 142.8/344.2 MB 9.1 MB/s eta 0:00:23\n",
      "     --------------- ---------------------- 143.3/344.2 MB 9.1 MB/s eta 0:00:23\n",
      "     --------------- ---------------------- 143.9/344.2 MB 9.1 MB/s eta 0:00:23\n",
      "     --------------- ---------------------- 144.4/344.2 MB 9.1 MB/s eta 0:00:22\n",
      "     ---------------- --------------------- 144.9/344.2 MB 9.2 MB/s eta 0:00:22\n",
      "     ---------------- --------------------- 145.7/344.2 MB 9.1 MB/s eta 0:00:22\n",
      "     ---------------- --------------------- 146.4/344.2 MB 9.1 MB/s eta 0:00:22\n",
      "     --------------- --------------------- 147.1/344.2 MB 10.4 MB/s eta 0:00:19\n",
      "     --------------- --------------------- 147.8/344.2 MB 10.4 MB/s eta 0:00:19\n",
      "     --------------- --------------------- 148.3/344.2 MB 10.2 MB/s eta 0:00:20\n",
      "     ---------------- -------------------- 148.8/344.2 MB 10.2 MB/s eta 0:00:20\n",
      "     ---------------- -------------------- 149.4/344.2 MB 10.2 MB/s eta 0:00:20\n",
      "     ---------------- -------------------- 149.9/344.2 MB 10.2 MB/s eta 0:00:19\n",
      "     ---------------- -------------------- 149.9/344.2 MB 10.2 MB/s eta 0:00:19\n",
      "     ---------------- --------------------- 150.0/344.2 MB 9.1 MB/s eta 0:00:22\n",
      "     ---------------- --------------------- 150.7/344.2 MB 9.1 MB/s eta 0:00:22\n",
      "     ---------------- --------------------- 151.3/344.2 MB 9.1 MB/s eta 0:00:22\n",
      "     ---------------- --------------------- 151.8/344.2 MB 9.1 MB/s eta 0:00:22\n",
      "     ---------------- --------------------- 152.3/344.2 MB 9.1 MB/s eta 0:00:22\n",
      "     ---------------- --------------------- 152.8/344.2 MB 9.1 MB/s eta 0:00:22\n",
      "     ---------------- -------------------- 153.4/344.2 MB 10.1 MB/s eta 0:00:19\n",
      "     ---------------- -------------------- 153.8/344.2 MB 10.1 MB/s eta 0:00:19\n",
      "     ---------------- -------------------- 154.5/344.2 MB 10.1 MB/s eta 0:00:19\n",
      "     ---------------- -------------------- 155.2/344.2 MB 10.1 MB/s eta 0:00:19\n",
      "     ---------------- -------------------- 155.2/344.2 MB 10.1 MB/s eta 0:00:19\n",
      "     ---------------- -------------------- 155.2/344.2 MB 10.1 MB/s eta 0:00:19\n",
      "     ----------------- -------------------- 155.4/344.2 MB 8.8 MB/s eta 0:00:22\n",
      "     ----------------- -------------------- 155.9/344.2 MB 8.8 MB/s eta 0:00:22\n",
      "     ----------------- -------------------- 156.4/344.2 MB 8.7 MB/s eta 0:00:22\n",
      "     ----------------- -------------------- 157.0/344.2 MB 8.8 MB/s eta 0:00:22\n",
      "     ----------------- -------------------- 157.6/344.2 MB 8.8 MB/s eta 0:00:22\n",
      "     ----------------- -------------------- 158.1/344.2 MB 8.7 MB/s eta 0:00:22\n",
      "     ----------------- -------------------- 158.7/344.2 MB 8.7 MB/s eta 0:00:22\n",
      "     ----------------- -------------------- 159.2/344.2 MB 8.6 MB/s eta 0:00:22\n",
      "     ----------------- -------------------- 159.6/344.2 MB 8.7 MB/s eta 0:00:22\n",
      "     ----------------- -------------------- 160.1/344.2 MB 8.5 MB/s eta 0:00:22\n",
      "     ----------------- -------------------- 160.6/344.2 MB 9.6 MB/s eta 0:00:20\n",
      "     ----------------- -------------------- 161.3/344.2 MB 9.6 MB/s eta 0:00:19\n",
      "     ----------------- -------------------- 162.0/344.2 MB 9.6 MB/s eta 0:00:19\n",
      "     ----------------- -------------------- 162.8/344.2 MB 9.6 MB/s eta 0:00:19\n",
      "     ------------------ ------------------- 163.3/344.2 MB 9.8 MB/s eta 0:00:19\n",
      "     ------------------ ------------------- 163.9/344.2 MB 9.8 MB/s eta 0:00:19\n",
      "     ------------------ ------------------- 164.4/344.2 MB 9.8 MB/s eta 0:00:19\n",
      "     ------------------ ------------------- 164.9/344.2 MB 9.8 MB/s eta 0:00:19\n",
      "     ----------------- ------------------- 165.5/344.2 MB 11.3 MB/s eta 0:00:16\n",
      "     ----------------- ------------------- 166.0/344.2 MB 11.3 MB/s eta 0:00:16\n",
      "     ----------------- ------------------- 166.5/344.2 MB 11.3 MB/s eta 0:00:16\n",
      "     ----------------- ------------------- 167.1/344.2 MB 11.5 MB/s eta 0:00:16\n",
      "     ------------------ ------------------ 167.8/344.2 MB 11.5 MB/s eta 0:00:16\n",
      "     ------------------ ------------------ 168.5/344.2 MB 11.7 MB/s eta 0:00:16\n",
      "     ------------------ ------------------ 169.0/344.2 MB 11.7 MB/s eta 0:00:15\n",
      "     ------------------ ------------------ 169.8/344.2 MB 11.7 MB/s eta 0:00:15\n",
      "     ------------------ ------------------ 169.9/344.2 MB 11.7 MB/s eta 0:00:15\n",
      "     ------------------ ------------------ 169.9/344.2 MB 11.7 MB/s eta 0:00:15\n",
      "     ------------------ ------------------ 169.9/344.2 MB 11.7 MB/s eta 0:00:15\n",
      "     ------------------ ------------------ 169.9/344.2 MB 11.7 MB/s eta 0:00:15\n",
      "     ------------------ ------------------ 169.9/344.2 MB 11.7 MB/s eta 0:00:15\n",
      "     ------------------ ------------------ 169.9/344.2 MB 11.7 MB/s eta 0:00:15\n",
      "     ------------------ ------------------ 169.9/344.2 MB 11.7 MB/s eta 0:00:15\n",
      "     ------------------ ------------------ 169.9/344.2 MB 11.7 MB/s eta 0:00:15\n",
      "     ------------------ ------------------ 169.9/344.2 MB 11.7 MB/s eta 0:00:15\n",
      "     ------------------ ------------------- 170.2/344.2 MB 7.8 MB/s eta 0:00:23\n",
      "     ------------------ ------------------- 170.7/344.2 MB 7.8 MB/s eta 0:00:23\n",
      "     ------------------ ------------------- 171.2/344.2 MB 7.7 MB/s eta 0:00:23\n",
      "     ------------------ ------------------- 171.7/344.2 MB 7.7 MB/s eta 0:00:23\n",
      "     ------------------- ------------------ 172.2/344.2 MB 7.7 MB/s eta 0:00:23\n",
      "     ------------------- ------------------ 172.8/344.2 MB 7.8 MB/s eta 0:00:22\n",
      "     ------------------- ------------------ 173.5/344.2 MB 7.8 MB/s eta 0:00:22\n",
      "     ------------------- ------------------ 174.2/344.2 MB 7.8 MB/s eta 0:00:22\n",
      "     ------------------- ------------------ 174.7/344.2 MB 7.8 MB/s eta 0:00:22\n",
      "     ------------------- ------------------ 175.3/344.2 MB 7.7 MB/s eta 0:00:22\n",
      "     ------------------- ------------------ 175.8/344.2 MB 7.7 MB/s eta 0:00:22\n",
      "     ------------------- ------------------ 176.3/344.2 MB 7.7 MB/s eta 0:00:22\n",
      "     ------------------- ------------------ 176.8/344.2 MB 7.7 MB/s eta 0:00:22\n",
      "     ------------------- ------------------ 177.3/344.2 MB 7.6 MB/s eta 0:00:22\n",
      "     ------------------- ------------------ 177.8/344.2 MB 7.7 MB/s eta 0:00:22\n",
      "     ------------------- ------------------ 178.3/344.2 MB 7.6 MB/s eta 0:00:22\n",
      "     ------------------- ------------------ 178.9/344.2 MB 7.5 MB/s eta 0:00:22\n",
      "     ------------------- ------------------ 179.4/344.2 MB 7.4 MB/s eta 0:00:23\n",
      "     ------------------- ------------------ 179.9/344.2 MB 7.4 MB/s eta 0:00:23\n",
      "     ------------------- ----------------- 180.4/344.2 MB 10.9 MB/s eta 0:00:16\n",
      "     ------------------- ----------------- 180.8/344.2 MB 10.7 MB/s eta 0:00:16\n",
      "     ------------------- ----------------- 181.3/344.2 MB 10.7 MB/s eta 0:00:16\n",
      "     ------------------- ----------------- 181.8/344.2 MB 10.9 MB/s eta 0:00:15\n",
      "     ------------------- ----------------- 182.3/344.2 MB 10.7 MB/s eta 0:00:16\n",
      "     ------------------- ----------------- 182.4/344.2 MB 10.6 MB/s eta 0:00:16\n",
      "     ------------------- ----------------- 182.4/344.2 MB 10.6 MB/s eta 0:00:16\n",
      "     -------------------- ----------------- 182.5/344.2 MB 9.4 MB/s eta 0:00:18\n",
      "     -------------------- ----------------- 183.0/344.2 MB 9.4 MB/s eta 0:00:18\n",
      "     -------------------- ----------------- 183.6/344.2 MB 9.4 MB/s eta 0:00:18\n",
      "     -------------------- ----------------- 184.1/344.2 MB 9.2 MB/s eta 0:00:18\n",
      "     -------------------- ----------------- 184.5/344.2 MB 9.4 MB/s eta 0:00:18\n",
      "     -------------------- ----------------- 184.5/344.2 MB 9.4 MB/s eta 0:00:18\n",
      "     -------------------- ----------------- 184.5/344.2 MB 9.4 MB/s eta 0:00:18\n",
      "     -------------------- ----------------- 184.5/344.2 MB 9.4 MB/s eta 0:00:18\n",
      "     -------------------- ----------------- 184.9/344.2 MB 8.0 MB/s eta 0:00:20\n",
      "     -------------------- ----------------- 185.4/344.2 MB 8.0 MB/s eta 0:00:20\n",
      "     -------------------- ----------------- 185.9/344.2 MB 7.9 MB/s eta 0:00:21\n",
      "     -------------------- ----------------- 186.4/344.2 MB 8.0 MB/s eta 0:00:20\n",
      "     -------------------- ----------------- 187.1/344.2 MB 8.0 MB/s eta 0:00:20\n",
      "     -------------------- ----------------- 187.8/344.2 MB 8.0 MB/s eta 0:00:20\n",
      "     -------------------- ----------------- 188.3/344.2 MB 8.0 MB/s eta 0:00:20\n",
      "     -------------------- ----------------- 188.8/344.2 MB 8.1 MB/s eta 0:00:20\n",
      "     -------------------- ----------------- 189.3/344.2 MB 8.2 MB/s eta 0:00:19\n",
      "     -------------------- ----------------- 189.8/344.2 MB 8.2 MB/s eta 0:00:19\n",
      "     --------------------- ---------------- 190.4/344.2 MB 8.2 MB/s eta 0:00:19\n",
      "     --------------------- ---------------- 190.9/344.2 MB 8.4 MB/s eta 0:00:19\n",
      "     --------------------- ---------------- 191.6/344.2 MB 8.4 MB/s eta 0:00:19\n",
      "     --------------------- ---------------- 192.2/344.2 MB 8.4 MB/s eta 0:00:19\n",
      "     --------------------- ---------------- 192.9/344.2 MB 9.5 MB/s eta 0:00:16\n",
      "     --------------------- ---------------- 193.4/344.2 MB 9.5 MB/s eta 0:00:16\n",
      "     --------------------- ---------------- 194.0/344.2 MB 9.5 MB/s eta 0:00:16\n",
      "     --------------------- ---------------- 194.5/344.2 MB 9.5 MB/s eta 0:00:16\n",
      "     -------------------- ---------------- 195.0/344.2 MB 11.3 MB/s eta 0:00:14\n",
      "     --------------------- --------------- 195.5/344.2 MB 11.3 MB/s eta 0:00:14\n",
      "     --------------------- --------------- 196.1/344.2 MB 11.3 MB/s eta 0:00:14\n",
      "     --------------------- --------------- 196.8/344.2 MB 11.5 MB/s eta 0:00:13\n",
      "     --------------------- --------------- 197.4/344.2 MB 11.5 MB/s eta 0:00:13\n",
      "     --------------------- --------------- 198.1/344.2 MB 11.5 MB/s eta 0:00:13\n",
      "     --------------------- --------------- 198.6/344.2 MB 11.3 MB/s eta 0:00:13\n",
      "     --------------------- --------------- 199.1/344.2 MB 11.3 MB/s eta 0:00:13\n",
      "     --------------------- --------------- 199.6/344.2 MB 11.3 MB/s eta 0:00:13\n",
      "     --------------------- --------------- 200.1/344.2 MB 11.5 MB/s eta 0:00:13\n",
      "     --------------------- --------------- 200.8/344.2 MB 11.5 MB/s eta 0:00:13\n",
      "     --------------------- --------------- 201.5/344.2 MB 11.5 MB/s eta 0:00:13\n",
      "     --------------------- --------------- 202.0/344.2 MB 11.5 MB/s eta 0:00:13\n",
      "     --------------------- --------------- 202.6/344.2 MB 11.5 MB/s eta 0:00:13\n",
      "     --------------------- --------------- 203.1/344.2 MB 11.5 MB/s eta 0:00:13\n",
      "     --------------------- --------------- 203.4/344.2 MB 11.7 MB/s eta 0:00:13\n",
      "     --------------------- --------------- 203.4/344.2 MB 11.7 MB/s eta 0:00:13\n",
      "     --------------------- --------------- 203.7/344.2 MB 10.7 MB/s eta 0:00:14\n",
      "     --------------------- --------------- 204.4/344.2 MB 10.6 MB/s eta 0:00:14\n",
      "     --------------------- --------------- 204.5/344.2 MB 10.6 MB/s eta 0:00:14\n",
      "     --------------------- --------------- 204.5/344.2 MB 10.6 MB/s eta 0:00:14\n",
      "     --------------------- --------------- 204.5/344.2 MB 10.6 MB/s eta 0:00:14\n",
      "     ---------------------- --------------- 205.0/344.2 MB 9.1 MB/s eta 0:00:16\n",
      "     ---------------------- --------------- 205.5/344.2 MB 9.1 MB/s eta 0:00:16\n",
      "     ---------------------- --------------- 206.0/344.2 MB 9.1 MB/s eta 0:00:16\n",
      "     ---------------------- --------------- 206.5/344.2 MB 9.1 MB/s eta 0:00:16\n",
      "     ---------------------- --------------- 207.1/344.2 MB 9.2 MB/s eta 0:00:15\n",
      "     ---------------------- --------------- 207.8/344.2 MB 9.2 MB/s eta 0:00:15\n",
      "     ----------------------- -------------- 208.4/344.2 MB 9.1 MB/s eta 0:00:15\n",
      "     ----------------------- -------------- 208.9/344.2 MB 9.1 MB/s eta 0:00:15\n",
      "     ----------------------- -------------- 209.4/344.2 MB 9.2 MB/s eta 0:00:15\n",
      "     ----------------------- -------------- 210.0/344.2 MB 9.2 MB/s eta 0:00:15\n",
      "     ----------------------- -------------- 210.5/344.2 MB 9.1 MB/s eta 0:00:15\n",
      "     ----------------------- -------------- 211.0/344.2 MB 9.1 MB/s eta 0:00:15\n",
      "     ----------------------- -------------- 211.6/344.2 MB 9.1 MB/s eta 0:00:15\n",
      "     ----------------------- -------------- 212.1/344.2 MB 9.1 MB/s eta 0:00:15\n",
      "     ----------------------- -------------- 212.6/344.2 MB 9.2 MB/s eta 0:00:15\n",
      "     ----------------------- -------------- 213.4/344.2 MB 9.2 MB/s eta 0:00:15\n",
      "     ----------------------- -------------- 214.1/344.2 MB 9.9 MB/s eta 0:00:14\n",
      "     ----------------------- ------------- 214.8/344.2 MB 11.7 MB/s eta 0:00:12\n",
      "     ----------------------- ------------- 215.0/344.2 MB 11.7 MB/s eta 0:00:12\n",
      "     ----------------------- ------------- 215.3/344.2 MB 10.9 MB/s eta 0:00:12\n",
      "     ----------------------- ------------- 215.8/344.2 MB 10.9 MB/s eta 0:00:12\n",
      "     ----------------------- ------------- 216.4/344.2 MB 11.1 MB/s eta 0:00:12\n",
      "     ----------------------- ------------- 216.9/344.2 MB 10.9 MB/s eta 0:00:12\n",
      "     ----------------------- ------------- 217.5/344.2 MB 10.9 MB/s eta 0:00:12\n",
      "     ----------------------- ------------- 218.0/344.2 MB 11.1 MB/s eta 0:00:12\n",
      "     ----------------------- ------------- 218.5/344.2 MB 11.1 MB/s eta 0:00:12\n",
      "     ----------------------- ------------- 219.1/344.2 MB 11.3 MB/s eta 0:00:12\n",
      "     ----------------------- ------------- 219.1/344.2 MB 11.1 MB/s eta 0:00:12\n",
      "     ----------------------- ------------- 219.1/344.2 MB 11.1 MB/s eta 0:00:12\n",
      "     ------------------------ ------------- 219.5/344.2 MB 9.9 MB/s eta 0:00:13\n",
      "     ------------------------ ------------- 220.2/344.2 MB 9.8 MB/s eta 0:00:13\n",
      "     ------------------------ ------------- 220.8/344.2 MB 9.8 MB/s eta 0:00:13\n",
      "     ------------------------ ------------- 221.3/344.2 MB 9.8 MB/s eta 0:00:13\n",
      "     ------------------------ ------------- 221.9/344.2 MB 9.8 MB/s eta 0:00:13\n",
      "     ------------------------ ------------- 222.4/344.2 MB 9.8 MB/s eta 0:00:13\n",
      "     ------------------------ ------------- 222.9/344.2 MB 9.8 MB/s eta 0:00:13\n",
      "     ------------------------ ------------- 223.3/344.2 MB 9.8 MB/s eta 0:00:13\n",
      "     ------------------------ ------------- 223.7/344.2 MB 9.5 MB/s eta 0:00:13\n",
      "     ------------------------ ------------- 224.4/344.2 MB 9.6 MB/s eta 0:00:13\n",
      "     ------------------------ ------------- 224.4/344.2 MB 9.6 MB/s eta 0:00:13\n",
      "     ------------------------ ------------- 224.4/344.2 MB 9.6 MB/s eta 0:00:13\n",
      "     ------------------------ ------------- 224.4/344.2 MB 9.6 MB/s eta 0:00:13\n",
      "     ------------------------ ------------- 224.4/344.2 MB 9.6 MB/s eta 0:00:13\n",
      "     ------------------------ ------------- 224.4/344.2 MB 9.6 MB/s eta 0:00:13\n",
      "     ------------------------ ------------- 224.4/344.2 MB 9.6 MB/s eta 0:00:13\n",
      "     ------------------------ ------------- 224.4/344.2 MB 9.6 MB/s eta 0:00:13\n",
      "     ------------------------ ------------- 224.6/344.2 MB 7.0 MB/s eta 0:00:18\n",
      "     ------------------------ ------------- 225.1/344.2 MB 7.0 MB/s eta 0:00:18\n",
      "     ------------------------ ------------- 225.7/344.2 MB 7.2 MB/s eta 0:00:17\n",
      "     ------------------------ ------------- 226.2/344.2 MB 7.2 MB/s eta 0:00:17\n",
      "     ------------------------- ------------ 226.8/344.2 MB 7.2 MB/s eta 0:00:17\n",
      "     ------------------------- ------------ 227.3/344.2 MB 7.3 MB/s eta 0:00:17\n",
      "     ------------------------- ------------ 228.0/344.2 MB 7.3 MB/s eta 0:00:16\n",
      "     ------------------------- ------------ 228.8/344.2 MB 7.3 MB/s eta 0:00:16\n",
      "     ------------------------- ------------ 229.5/344.2 MB 8.0 MB/s eta 0:00:15\n",
      "     ------------------------- ------------ 230.2/344.2 MB 8.0 MB/s eta 0:00:15\n",
      "     ------------------------- ------------ 230.7/344.2 MB 8.0 MB/s eta 0:00:15\n",
      "     ------------------------- ------------ 231.3/344.2 MB 7.9 MB/s eta 0:00:15\n",
      "     ------------------------- ------------ 231.8/344.2 MB 7.9 MB/s eta 0:00:15\n",
      "     ------------------------- ------------ 232.3/344.2 MB 7.9 MB/s eta 0:00:15\n",
      "     ------------------------- ------------ 232.9/344.2 MB 7.9 MB/s eta 0:00:15\n",
      "     ------------------------- ------------ 233.4/344.2 MB 7.9 MB/s eta 0:00:15\n",
      "     ------------------------- ------------ 233.9/344.2 MB 8.1 MB/s eta 0:00:14\n",
      "     ------------------------- ----------- 234.7/344.2 MB 11.9 MB/s eta 0:00:10\n",
      "     ------------------------- ----------- 235.4/344.2 MB 11.9 MB/s eta 0:00:10\n",
      "     ------------------------- ----------- 235.9/344.2 MB 11.9 MB/s eta 0:00:10\n",
      "     ------------------------- ----------- 235.9/344.2 MB 11.9 MB/s eta 0:00:10\n",
      "     ------------------------- ----------- 235.9/344.2 MB 11.9 MB/s eta 0:00:10\n",
      "     ------------------------- ----------- 236.3/344.2 MB 10.4 MB/s eta 0:00:11\n",
      "     ------------------------- ----------- 236.9/344.2 MB 10.4 MB/s eta 0:00:11\n",
      "     ------------------------- ----------- 237.4/344.2 MB 10.4 MB/s eta 0:00:11\n",
      "     ------------------------- ----------- 237.9/344.2 MB 10.4 MB/s eta 0:00:11\n",
      "     ------------------------- ----------- 238.5/344.2 MB 10.6 MB/s eta 0:00:11\n",
      "     ------------------------- ----------- 239.0/344.2 MB 10.6 MB/s eta 0:00:10\n",
      "     ------------------------- ----------- 239.8/344.2 MB 10.6 MB/s eta 0:00:10\n",
      "     ------------------------- ----------- 240.5/344.2 MB 10.4 MB/s eta 0:00:10\n",
      "     ------------------------- ----------- 241.2/344.2 MB 10.4 MB/s eta 0:00:10\n",
      "     ------------------------- ----------- 241.7/344.2 MB 10.4 MB/s eta 0:00:10\n",
      "     -------------------------- ---------- 242.3/344.2 MB 10.4 MB/s eta 0:00:10\n",
      "     -------------------------- ---------- 242.8/344.2 MB 10.4 MB/s eta 0:00:10\n",
      "     -------------------------- ---------- 243.3/344.2 MB 10.4 MB/s eta 0:00:10\n",
      "     -------------------------- ---------- 243.9/344.2 MB 10.4 MB/s eta 0:00:10\n",
      "     -------------------------- ---------- 244.4/344.2 MB 10.4 MB/s eta 0:00:10\n",
      "     -------------------------- ---------- 245.0/344.2 MB 10.4 MB/s eta 0:00:10\n",
      "     -------------------------- ---------- 245.5/344.2 MB 10.4 MB/s eta 0:00:10\n",
      "     -------------------------- ---------- 246.2/344.2 MB 11.9 MB/s eta 0:00:09\n",
      "     -------------------------- ---------- 246.9/344.2 MB 11.9 MB/s eta 0:00:09\n",
      "     -------------------------- ---------- 247.5/344.2 MB 11.9 MB/s eta 0:00:09\n",
      "     -------------------------- ---------- 248.0/344.2 MB 11.9 MB/s eta 0:00:09\n",
      "     -------------------------- ---------- 248.6/344.2 MB 11.9 MB/s eta 0:00:09\n",
      "     -------------------------- ---------- 249.1/344.2 MB 11.9 MB/s eta 0:00:08\n",
      "     -------------------------- ---------- 249.7/344.2 MB 11.9 MB/s eta 0:00:08\n",
      "     -------------------------- ---------- 250.2/344.2 MB 11.9 MB/s eta 0:00:08\n",
      "     -------------------------- ---------- 250.7/344.2 MB 11.9 MB/s eta 0:00:08\n",
      "     --------------------------- --------- 251.3/344.2 MB 11.7 MB/s eta 0:00:08\n",
      "     --------------------------- --------- 251.8/344.2 MB 11.7 MB/s eta 0:00:08\n",
      "     --------------------------- --------- 252.5/344.2 MB 11.9 MB/s eta 0:00:08\n",
      "     --------------------------- --------- 253.2/344.2 MB 11.9 MB/s eta 0:00:08\n",
      "     --------------------------- --------- 253.8/344.2 MB 11.9 MB/s eta 0:00:08\n",
      "     --------------------------- --------- 254.3/344.2 MB 11.9 MB/s eta 0:00:08\n",
      "     --------------------------- --------- 254.8/344.2 MB 11.9 MB/s eta 0:00:08\n",
      "     --------------------------- --------- 255.4/344.2 MB 11.7 MB/s eta 0:00:08\n",
      "     --------------------------- --------- 255.9/344.2 MB 11.7 MB/s eta 0:00:08\n",
      "     --------------------------- --------- 256.4/344.2 MB 11.7 MB/s eta 0:00:08\n",
      "     --------------------------- --------- 257.0/344.2 MB 11.9 MB/s eta 0:00:08\n",
      "     --------------------------- --------- 257.7/344.2 MB 11.9 MB/s eta 0:00:08\n",
      "     --------------------------- --------- 258.4/344.2 MB 11.9 MB/s eta 0:00:08\n",
      "     --------------------------- --------- 258.9/344.2 MB 11.9 MB/s eta 0:00:08\n",
      "     --------------------------- --------- 259.5/344.2 MB 11.9 MB/s eta 0:00:08\n",
      "     --------------------------- --------- 260.0/344.2 MB 11.9 MB/s eta 0:00:08\n",
      "     ---------------------------- -------- 260.6/344.2 MB 11.9 MB/s eta 0:00:08\n",
      "     ---------------------------- -------- 261.1/344.2 MB 11.9 MB/s eta 0:00:07\n",
      "     ---------------------------- -------- 261.7/344.2 MB 11.9 MB/s eta 0:00:07\n",
      "     ---------------------------- -------- 262.2/344.2 MB 11.7 MB/s eta 0:00:08\n",
      "     ---------------------------- -------- 262.7/344.2 MB 11.7 MB/s eta 0:00:07\n",
      "     ---------------------------- -------- 263.4/344.2 MB 11.9 MB/s eta 0:00:07\n",
      "     ---------------------------- -------- 264.2/344.2 MB 11.9 MB/s eta 0:00:07\n",
      "     ---------------------------- -------- 264.9/344.2 MB 11.9 MB/s eta 0:00:07\n",
      "     ---------------------------- -------- 265.4/344.2 MB 11.9 MB/s eta 0:00:07\n",
      "     ---------------------------- -------- 266.0/344.2 MB 11.9 MB/s eta 0:00:07\n",
      "     ---------------------------- -------- 266.0/344.2 MB 11.3 MB/s eta 0:00:07\n",
      "     ---------------------------- -------- 266.7/344.2 MB 11.3 MB/s eta 0:00:07\n",
      "     ---------------------------- -------- 267.2/344.2 MB 11.3 MB/s eta 0:00:07\n",
      "     ---------------------------- -------- 267.8/344.2 MB 11.1 MB/s eta 0:00:07\n",
      "     ---------------------------- -------- 268.3/344.2 MB 11.1 MB/s eta 0:00:07\n",
      "     ---------------------------- -------- 268.4/344.2 MB 11.3 MB/s eta 0:00:07\n",
      "     ---------------------------- -------- 268.4/344.2 MB 11.3 MB/s eta 0:00:07\n",
      "     ----------------------------- -------- 268.7/344.2 MB 9.9 MB/s eta 0:00:08\n",
      "     ----------------------------- -------- 269.4/344.2 MB 9.8 MB/s eta 0:00:08\n",
      "     ----------------------------- -------- 269.9/344.2 MB 9.8 MB/s eta 0:00:08\n",
      "     ----------------------------- -------- 270.5/344.2 MB 9.8 MB/s eta 0:00:08\n",
      "     ----------------------------- -------- 270.5/344.2 MB 9.8 MB/s eta 0:00:08\n",
      "     ----------------------------- -------- 270.5/344.2 MB 9.8 MB/s eta 0:00:08\n",
      "     ----------------------------- -------- 270.5/344.2 MB 9.8 MB/s eta 0:00:08\n",
      "     ----------------------------- -------- 271.2/344.2 MB 8.6 MB/s eta 0:00:09\n",
      "     ----------------------------- -------- 271.7/344.2 MB 8.7 MB/s eta 0:00:09\n",
      "     ------------------------------ ------- 272.4/344.2 MB 8.7 MB/s eta 0:00:09\n",
      "     ------------------------------ ------- 273.2/344.2 MB 8.7 MB/s eta 0:00:09\n",
      "     ------------------------------ ------- 273.7/344.2 MB 8.7 MB/s eta 0:00:09\n",
      "     ------------------------------ ------- 274.2/344.2 MB 8.6 MB/s eta 0:00:09\n",
      "     ------------------------------ ------- 274.7/344.2 MB 8.6 MB/s eta 0:00:09\n",
      "     ------------------------------ ------- 275.1/344.2 MB 8.5 MB/s eta 0:00:09\n",
      "     ------------------------------ ------- 275.5/344.2 MB 8.4 MB/s eta 0:00:09\n",
      "     ------------------------------ ------- 275.9/344.2 MB 8.3 MB/s eta 0:00:09\n",
      "     ------------------------------ ------- 276.3/344.2 MB 8.6 MB/s eta 0:00:08\n",
      "     ------------------------------ ------- 276.7/344.2 MB 8.5 MB/s eta 0:00:08\n",
      "     ------------------------------ ------- 276.8/344.2 MB 8.5 MB/s eta 0:00:08\n",
      "     ------------------------------ ------- 276.8/344.2 MB 8.5 MB/s eta 0:00:08\n",
      "     ------------------------------ ------- 277.1/344.2 MB 7.9 MB/s eta 0:00:09\n",
      "     ------------------------------ ------- 277.5/344.2 MB 7.7 MB/s eta 0:00:09\n",
      "     ------------------------------ ------- 278.4/344.2 MB 7.8 MB/s eta 0:00:09\n",
      "     ------------------------------ ------- 278.9/344.2 MB 8.7 MB/s eta 0:00:08\n",
      "     ------------------------------ ------- 279.5/344.2 MB 8.6 MB/s eta 0:00:08\n",
      "     ------------------------------ ------- 280.0/344.2 MB 8.6 MB/s eta 0:00:08\n",
      "     ------------------------------ ------- 280.6/344.2 MB 8.6 MB/s eta 0:00:08\n",
      "     ------------------------------- ------ 281.1/344.2 MB 9.8 MB/s eta 0:00:07\n",
      "     ------------------------------- ------ 281.6/344.2 MB 9.8 MB/s eta 0:00:07\n",
      "     ------------------------------- ------ 282.2/344.2 MB 9.8 MB/s eta 0:00:07\n",
      "     ------------------------------- ------ 282.7/344.2 MB 9.8 MB/s eta 0:00:07\n",
      "     ------------------------------- ------ 283.4/344.2 MB 9.8 MB/s eta 0:00:07\n",
      "     ------------------------------- ------ 284.1/344.2 MB 9.8 MB/s eta 0:00:07\n",
      "     ------------------------------- ------ 284.2/344.2 MB 9.6 MB/s eta 0:00:07\n",
      "     ------------------------------- ------ 284.2/344.2 MB 9.6 MB/s eta 0:00:07\n",
      "     ------------------------------- ------ 284.2/344.2 MB 9.6 MB/s eta 0:00:07\n",
      "     ------------------------------- ------ 284.2/344.2 MB 9.6 MB/s eta 0:00:07\n",
      "     ------------------------------- ------ 284.5/344.2 MB 8.1 MB/s eta 0:00:08\n",
      "     ------------------------------- ------ 285.1/344.2 MB 8.1 MB/s eta 0:00:08\n",
      "     ------------------------------- ------ 285.6/344.2 MB 8.2 MB/s eta 0:00:08\n",
      "     ------------------------------- ------ 286.2/344.2 MB 8.3 MB/s eta 0:00:07\n",
      "     ------------------------------- ------ 286.7/344.2 MB 8.4 MB/s eta 0:00:07\n",
      "     ------------------------------- ------ 287.2/344.2 MB 9.2 MB/s eta 0:00:07\n",
      "     ------------------------------- ------ 287.8/344.2 MB 9.5 MB/s eta 0:00:06\n",
      "     ------------------------------- ------ 288.3/344.2 MB 9.5 MB/s eta 0:00:06\n",
      "     ------------------------------- ------ 289.0/344.2 MB 9.4 MB/s eta 0:00:06\n",
      "     ------------------------------- ------ 289.6/344.2 MB 9.4 MB/s eta 0:00:06\n",
      "     -------------------------------- ----- 290.0/344.2 MB 9.4 MB/s eta 0:00:06\n",
      "     -------------------------------- ----- 290.6/344.2 MB 9.4 MB/s eta 0:00:06\n",
      "     -------------------------------- ----- 291.1/344.2 MB 9.4 MB/s eta 0:00:06\n",
      "     -------------------------------- ----- 291.2/344.2 MB 9.4 MB/s eta 0:00:06\n",
      "     -------------------------------- ----- 291.3/344.2 MB 8.7 MB/s eta 0:00:07\n",
      "     -------------------------------- ----- 291.9/344.2 MB 8.7 MB/s eta 0:00:06\n",
      "     -------------------------------- ----- 292.4/344.2 MB 8.7 MB/s eta 0:00:06\n",
      "     -------------------------------- ----- 293.0/344.2 MB 8.7 MB/s eta 0:00:06\n",
      "     -------------------------------- ----- 293.5/344.2 MB 8.7 MB/s eta 0:00:06\n",
      "     -------------------------------- ----- 294.2/344.2 MB 8.8 MB/s eta 0:00:06\n",
      "     ------------------------------- ----- 294.9/344.2 MB 10.9 MB/s eta 0:00:05\n",
      "     ------------------------------- ----- 295.7/344.2 MB 10.9 MB/s eta 0:00:05\n",
      "     ------------------------------- ----- 296.2/344.2 MB 10.9 MB/s eta 0:00:05\n",
      "     ------------------------------- ----- 296.7/344.2 MB 10.9 MB/s eta 0:00:05\n",
      "     ------------------------------- ----- 297.3/344.2 MB 10.9 MB/s eta 0:00:05\n",
      "     -------------------------------- ---- 297.8/344.2 MB 10.7 MB/s eta 0:00:05\n",
      "     -------------------------------- ---- 297.8/344.2 MB 10.7 MB/s eta 0:00:05\n",
      "     -------------------------------- ---- 297.8/344.2 MB 10.7 MB/s eta 0:00:05\n",
      "     -------------------------------- ----- 298.3/344.2 MB 9.6 MB/s eta 0:00:05\n",
      "     -------------------------------- ----- 298.9/344.2 MB 9.6 MB/s eta 0:00:05\n",
      "     --------------------------------- ---- 299.4/344.2 MB 9.6 MB/s eta 0:00:05\n",
      "     --------------------------------- ---- 299.9/344.2 MB 9.6 MB/s eta 0:00:05\n",
      "     --------------------------------- ---- 300.5/344.2 MB 9.6 MB/s eta 0:00:05\n",
      "     --------------------------------- ---- 301.0/344.2 MB 9.8 MB/s eta 0:00:05\n",
      "     -------------------------------- ---- 301.7/344.2 MB 10.4 MB/s eta 0:00:05\n",
      "     -------------------------------- ---- 302.4/344.2 MB 10.4 MB/s eta 0:00:05\n",
      "     -------------------------------- ---- 302.9/344.2 MB 10.4 MB/s eta 0:00:04\n",
      "     -------------------------------- ---- 303.5/344.2 MB 10.4 MB/s eta 0:00:04\n",
      "     -------------------------------- ---- 303.9/344.2 MB 10.2 MB/s eta 0:00:04\n",
      "     -------------------------------- ---- 304.3/344.2 MB 10.2 MB/s eta 0:00:04\n",
      "     -------------------------------- ---- 304.8/344.2 MB 10.1 MB/s eta 0:00:04\n",
      "     -------------------------------- ---- 305.5/344.2 MB 10.2 MB/s eta 0:00:04\n",
      "     -------------------------------- ---- 306.2/344.2 MB 10.2 MB/s eta 0:00:04\n",
      "     -------------------------------- ---- 306.8/344.2 MB 10.2 MB/s eta 0:00:04\n",
      "     --------------------------------- --- 307.3/344.2 MB 10.2 MB/s eta 0:00:04\n",
      "     --------------------------------- --- 307.8/344.2 MB 10.2 MB/s eta 0:00:04\n",
      "     --------------------------------- --- 308.4/344.2 MB 11.5 MB/s eta 0:00:04\n",
      "     --------------------------------- --- 308.9/344.2 MB 11.5 MB/s eta 0:00:04\n",
      "     --------------------------------- --- 309.3/344.2 MB 11.5 MB/s eta 0:00:04\n",
      "     --------------------------------- --- 309.3/344.2 MB 11.5 MB/s eta 0:00:04\n",
      "     --------------------------------- --- 309.3/344.2 MB 11.5 MB/s eta 0:00:04\n",
      "     ---------------------------------- --- 309.7/344.2 MB 9.9 MB/s eta 0:00:04\n",
      "     ---------------------------------- --- 310.3/344.2 MB 9.9 MB/s eta 0:00:04\n",
      "     --------------------------------- --- 310.4/344.2 MB 10.1 MB/s eta 0:00:04\n",
      "     --------------------------------- --- 310.4/344.2 MB 10.1 MB/s eta 0:00:04\n",
      "     ---------------------------------- --- 310.5/344.2 MB 9.0 MB/s eta 0:00:04\n",
      "     ---------------------------------- --- 311.1/344.2 MB 9.0 MB/s eta 0:00:04\n",
      "     ---------------------------------- --- 311.6/344.2 MB 9.1 MB/s eta 0:00:04\n",
      "     ---------------------------------- --- 312.3/344.2 MB 9.0 MB/s eta 0:00:04\n",
      "     ---------------------------------- --- 313.0/344.2 MB 9.0 MB/s eta 0:00:04\n",
      "     ---------------------------------- --- 313.5/344.2 MB 9.0 MB/s eta 0:00:04\n",
      "     ---------------------------------- --- 313.5/344.2 MB 9.0 MB/s eta 0:00:04\n",
      "     ---------------------------------- --- 313.5/344.2 MB 9.0 MB/s eta 0:00:04\n",
      "     ---------------------------------- --- 313.5/344.2 MB 9.0 MB/s eta 0:00:04\n",
      "     ---------------------------------- --- 314.0/344.2 MB 8.0 MB/s eta 0:00:04\n",
      "     ---------------------------------- --- 314.6/344.2 MB 8.1 MB/s eta 0:00:04\n",
      "     ---------------------------------- --- 315.1/344.2 MB 8.1 MB/s eta 0:00:04\n",
      "     ---------------------------------- --- 315.6/344.2 MB 8.2 MB/s eta 0:00:04\n",
      "     ---------------------------------- --- 316.2/344.2 MB 8.1 MB/s eta 0:00:04\n",
      "     ---------------------------------- --- 316.9/344.2 MB 8.1 MB/s eta 0:00:04\n",
      "     ----------------------------------- -- 317.6/344.2 MB 8.1 MB/s eta 0:00:04\n",
      "     ----------------------------------- -- 318.1/344.2 MB 8.1 MB/s eta 0:00:04\n",
      "     ----------------------------------- -- 318.7/344.2 MB 8.1 MB/s eta 0:00:04\n",
      "     ----------------------------------- -- 319.2/344.2 MB 8.1 MB/s eta 0:00:04\n",
      "     ----------------------------------- -- 319.8/344.2 MB 9.1 MB/s eta 0:00:03\n",
      "     ----------------------------------- -- 320.3/344.2 MB 9.1 MB/s eta 0:00:03\n",
      "     ---------------------------------- -- 320.8/344.2 MB 10.1 MB/s eta 0:00:03\n",
      "     ---------------------------------- -- 321.3/344.2 MB 10.1 MB/s eta 0:00:03\n",
      "     ---------------------------------- -- 321.8/344.2 MB 10.1 MB/s eta 0:00:03\n",
      "     ---------------------------------- -- 322.6/344.2 MB 10.2 MB/s eta 0:00:03\n",
      "     ---------------------------------- -- 323.3/344.2 MB 10.2 MB/s eta 0:00:03\n",
      "     ---------------------------------- -- 324.1/344.2 MB 11.9 MB/s eta 0:00:02\n",
      "     ---------------------------------- -- 324.6/344.2 MB 11.9 MB/s eta 0:00:02\n",
      "     ---------------------------------- -- 325.2/344.2 MB 11.9 MB/s eta 0:00:02\n",
      "     ----------------------------------- - 325.7/344.2 MB 11.9 MB/s eta 0:00:02\n",
      "     ----------------------------------- - 326.3/344.2 MB 11.9 MB/s eta 0:00:02\n",
      "     ----------------------------------- - 326.8/344.2 MB 11.9 MB/s eta 0:00:02\n",
      "     ----------------------------------- - 327.1/344.2 MB 11.9 MB/s eta 0:00:02\n",
      "     ----------------------------------- - 327.1/344.2 MB 11.9 MB/s eta 0:00:02\n",
      "     ----------------------------------- - 327.1/344.2 MB 11.9 MB/s eta 0:00:02\n",
      "     ----------------------------------- - 327.6/344.2 MB 10.4 MB/s eta 0:00:02\n",
      "     ----------------------------------- - 328.1/344.2 MB 10.6 MB/s eta 0:00:02\n",
      "     ----------------------------------- - 328.8/344.2 MB 10.6 MB/s eta 0:00:02\n",
      "     ----------------------------------- - 329.5/344.2 MB 10.4 MB/s eta 0:00:02\n",
      "     ----------------------------------- - 330.3/344.2 MB 10.4 MB/s eta 0:00:02\n",
      "     ----------------------------------- - 330.8/344.2 MB 10.4 MB/s eta 0:00:02\n",
      "     ----------------------------------- - 331.3/344.2 MB 10.4 MB/s eta 0:00:02\n",
      "     ----------------------------------- - 331.9/344.2 MB 10.6 MB/s eta 0:00:02\n",
      "     ----------------------------------- - 332.4/344.2 MB 10.4 MB/s eta 0:00:02\n",
      "     ----------------------------------- - 332.4/344.2 MB 10.4 MB/s eta 0:00:02\n",
      "     ----------------------------------- - 332.4/344.2 MB 10.4 MB/s eta 0:00:02\n",
      "     ------------------------------------ - 332.6/344.2 MB 9.2 MB/s eta 0:00:02\n",
      "     ------------------------------------ - 333.1/344.2 MB 9.2 MB/s eta 0:00:02\n",
      "     ------------------------------------ - 333.7/344.2 MB 9.2 MB/s eta 0:00:02\n",
      "     ------------------------------------ - 334.4/344.2 MB 9.4 MB/s eta 0:00:02\n",
      "     ------------------------------------ - 335.1/344.2 MB 9.4 MB/s eta 0:00:01\n",
      "     -------------------------------------  335.8/344.2 MB 9.2 MB/s eta 0:00:01\n",
      "     -------------------------------------  336.4/344.2 MB 9.2 MB/s eta 0:00:01\n",
      "     -------------------------------------  336.6/344.2 MB 9.4 MB/s eta 0:00:01\n",
      "     -------------------------------------  336.6/344.2 MB 9.4 MB/s eta 0:00:01\n",
      "     -------------------------------------  336.6/344.2 MB 9.4 MB/s eta 0:00:01\n",
      "     -------------------------------------  336.9/344.2 MB 8.3 MB/s eta 0:00:01\n",
      "     -------------------------------------  337.5/344.2 MB 9.1 MB/s eta 0:00:01\n",
      "     -------------------------------------  338.0/344.2 MB 9.0 MB/s eta 0:00:01\n",
      "     -------------------------------------  338.5/344.2 MB 9.0 MB/s eta 0:00:01\n",
      "     -------------------------------------  339.1/344.2 MB 9.0 MB/s eta 0:00:01\n",
      "     -------------------------------------  339.6/344.2 MB 9.0 MB/s eta 0:00:01\n",
      "     -------------------------------------  340.1/344.2 MB 9.1 MB/s eta 0:00:01\n",
      "     -------------------------------------  340.8/344.2 MB 9.1 MB/s eta 0:00:01\n",
      "     -------------------------------------  341.5/344.2 MB 9.1 MB/s eta 0:00:01\n",
      "     -------------------------------------  342.0/344.2 MB 9.1 MB/s eta 0:00:01\n",
      "     -------------------------------------  342.6/344.2 MB 9.0 MB/s eta 0:00:01\n",
      "     ------------------------------------  343.1/344.2 MB 10.1 MB/s eta 0:00:01\n",
      "     ------------------------------------  343.7/344.2 MB 10.1 MB/s eta 0:00:01\n",
      "     ------------------------------------  344.2/344.2 MB 10.2 MB/s eta 0:00:01\n",
      "     ------------------------------------  344.2/344.2 MB 10.2 MB/s eta 0:00:01\n",
      "     ------------------------------------  344.2/344.2 MB 10.2 MB/s eta 0:00:01\n",
      "     ------------------------------------  344.2/344.2 MB 10.2 MB/s eta 0:00:01\n",
      "     ------------------------------------  344.2/344.2 MB 10.2 MB/s eta 0:00:01\n",
      "     ------------------------------------  344.2/344.2 MB 10.2 MB/s eta 0:00:01\n",
      "     ------------------------------------  344.2/344.2 MB 10.2 MB/s eta 0:00:01\n",
      "     ------------------------------------  344.2/344.2 MB 10.2 MB/s eta 0:00:01\n",
      "     ------------------------------------  344.2/344.2 MB 10.2 MB/s eta 0:00:01\n",
      "     ------------------------------------  344.2/344.2 MB 10.2 MB/s eta 0:00:01\n",
      "     ------------------------------------  344.2/344.2 MB 10.2 MB/s eta 0:00:01\n",
      "     ------------------------------------  344.2/344.2 MB 10.2 MB/s eta 0:00:01\n",
      "     ------------------------------------  344.2/344.2 MB 10.2 MB/s eta 0:00:01\n",
      "     ------------------------------------  344.2/344.2 MB 10.2 MB/s eta 0:00:01\n",
      "     ------------------------------------  344.2/344.2 MB 10.2 MB/s eta 0:00:01\n",
      "     ------------------------------------  344.2/344.2 MB 10.2 MB/s eta 0:00:01\n",
      "     ------------------------------------  344.2/344.2 MB 10.2 MB/s eta 0:00:01\n",
      "     ------------------------------------  344.2/344.2 MB 10.2 MB/s eta 0:00:01\n",
      "     ------------------------------------  344.2/344.2 MB 10.2 MB/s eta 0:00:01\n",
      "     ------------------------------------  344.2/344.2 MB 10.2 MB/s eta 0:00:01\n",
      "     ------------------------------------  344.2/344.2 MB 10.2 MB/s eta 0:00:01\n",
      "     ------------------------------------  344.2/344.2 MB 10.2 MB/s eta 0:00:01\n",
      "     -------------------------------------- 344.2/344.2 MB 4.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: absl-py>=0.7.0 in c:\\users\\knuyh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow-gpu==2.3.0) (1.4.0)\n",
      "Requirement already satisfied: astunparse==1.6.3 in c:\\users\\knuyh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow-gpu==2.3.0) (1.6.3)\n",
      "Collecting gast==0.3.3 (from tensorflow-gpu==2.3.0)\n",
      "  Downloading gast-0.3.3-py2.py3-none-any.whl (9.7 kB)\n",
      "Requirement already satisfied: google-pasta>=0.1.8 in c:\\users\\knuyh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow-gpu==2.3.0) (0.2.0)\n",
      "Collecting h5py<2.11.0,>=2.10.0 (from tensorflow-gpu==2.3.0)\n",
      "  Downloading h5py-2.10.0-cp38-cp38-win_amd64.whl (2.5 MB)\n",
      "     ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
      "     ------- -------------------------------- 0.5/2.5 MB 15.2 MB/s eta 0:00:01\n",
      "     ------------------- -------------------- 1.2/2.5 MB 12.6 MB/s eta 0:00:01\n",
      "     ------------------------------ --------- 1.9/2.5 MB 12.2 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 2.4/2.5 MB 12.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 2.5/2.5 MB 11.5 MB/s eta 0:00:00\n",
      "Collecting keras-preprocessing<1.2,>=1.1.1 (from tensorflow-gpu==2.3.0)\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "     ---------------------------------------- 0.0/42.6 kB ? eta -:--:--\n",
      "     ---------------------------------------- 42.6/42.6 kB ? eta 0:00:00\n",
      "Collecting numpy<1.19.0,>=1.16.0 (from tensorflow-gpu==2.3.0)\n",
      "  Downloading numpy-1.18.5-cp38-cp38-win_amd64.whl (12.8 MB)\n",
      "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "     -- ------------------------------------- 0.8/12.8 MB 17.0 MB/s eta 0:00:01\n",
      "     ---- ----------------------------------- 1.5/12.8 MB 13.6 MB/s eta 0:00:01\n",
      "     ------ --------------------------------- 2.2/12.8 MB 12.8 MB/s eta 0:00:01\n",
      "     -------- ------------------------------- 2.8/12.8 MB 12.6 MB/s eta 0:00:01\n",
      "     ---------- ----------------------------- 3.3/12.8 MB 12.4 MB/s eta 0:00:01\n",
      "     ------------ --------------------------- 3.9/12.8 MB 12.3 MB/s eta 0:00:01\n",
      "     ------------- -------------------------- 4.4/12.8 MB 12.1 MB/s eta 0:00:01\n",
      "     --------------- ------------------------ 4.9/12.8 MB 12.1 MB/s eta 0:00:01\n",
      "     ----------------- ---------------------- 5.5/12.8 MB 12.0 MB/s eta 0:00:01\n",
      "     ------------------ --------------------- 6.0/12.8 MB 12.0 MB/s eta 0:00:01\n",
      "     -------------------- ------------------- 6.5/12.8 MB 12.3 MB/s eta 0:00:01\n",
      "     ---------------------- ----------------- 7.3/12.8 MB 12.2 MB/s eta 0:00:01\n",
      "     ------------------------- -------------- 8.0/12.8 MB 12.2 MB/s eta 0:00:01\n",
      "     --------------------------- ------------ 8.7/12.8 MB 12.1 MB/s eta 0:00:01\n",
      "     ----------------------------- ---------- 9.3/12.8 MB 12.1 MB/s eta 0:00:01\n",
      "     ------------------------------ --------- 9.8/12.8 MB 12.0 MB/s eta 0:00:01\n",
      "     ------------------------------- ------- 10.3/12.8 MB 12.1 MB/s eta 0:00:01\n",
      "     --------------------------------- ----- 10.9/12.8 MB 11.7 MB/s eta 0:00:01\n",
      "     ---------------------------------- ---- 11.4/12.8 MB 11.7 MB/s eta 0:00:01\n",
      "     ------------------------------------ -- 11.9/12.8 MB 11.7 MB/s eta 0:00:01\n",
      "     --------------------------------------  12.5/12.8 MB 11.7 MB/s eta 0:00:01\n",
      "     --------------------------------------  12.8/12.8 MB 11.9 MB/s eta 0:00:01\n",
      "     --------------------------------------- 12.8/12.8 MB 11.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\knuyh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow-gpu==2.3.0) (3.3.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\users\\knuyh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow-gpu==2.3.0) (4.23.4)\n",
      "Requirement already satisfied: tensorboard<3,>=2.3.0 in c:\\users\\knuyh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow-gpu==2.3.0) (2.13.0)\n",
      "Collecting tensorflow-gpu-estimator<2.4.0,>=2.3.0 (from tensorflow-gpu==2.3.0)\n",
      "  Downloading tensorflow_gpu_estimator-2.3.0-py2.py3-none-any.whl (474 kB)\n",
      "     ---------------------------------------- 0.0/474.9 kB ? eta -:--:--\n",
      "     -------------------------------------- 474.9/474.9 kB 9.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\knuyh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow-gpu==2.3.0) (2.3.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in c:\\users\\knuyh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow-gpu==2.3.0) (1.15.0)\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\users\\knuyh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow-gpu==2.3.0) (0.40.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\knuyh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow-gpu==2.3.0) (1.16.0)\n",
      "Collecting scipy==1.4.1 (from tensorflow-gpu==2.3.0)\n",
      "  Downloading scipy-1.4.1-cp38-cp38-win_amd64.whl (31.0 MB)\n",
      "     ---------------------------------------- 0.0/31.0 MB ? eta -:--:--\n",
      "      --------------------------------------- 0.5/31.0 MB 11.1 MB/s eta 0:00:03\n",
      "     - -------------------------------------- 1.1/31.0 MB 13.7 MB/s eta 0:00:03\n",
      "     -- ------------------------------------- 1.8/31.0 MB 12.6 MB/s eta 0:00:03\n",
      "     --- ------------------------------------ 2.5/31.0 MB 12.3 MB/s eta 0:00:03\n",
      "     --- ------------------------------------ 3.0/31.0 MB 12.0 MB/s eta 0:00:03\n",
      "     ---- ----------------------------------- 3.6/31.0 MB 12.0 MB/s eta 0:00:03\n",
      "     ----- ---------------------------------- 4.1/31.0 MB 11.9 MB/s eta 0:00:03\n",
      "     ----- ---------------------------------- 4.6/31.0 MB 11.9 MB/s eta 0:00:03\n",
      "     ------ --------------------------------- 5.2/31.0 MB 11.9 MB/s eta 0:00:03\n",
      "     ------- -------------------------------- 5.7/31.0 MB 11.8 MB/s eta 0:00:03\n",
      "     -------- ------------------------------- 6.3/31.0 MB 11.8 MB/s eta 0:00:03\n",
      "     --------- ------------------------------ 7.0/31.0 MB 12.1 MB/s eta 0:00:02\n",
      "     --------- ------------------------------ 7.7/31.0 MB 12.0 MB/s eta 0:00:02\n",
      "     ---------- ----------------------------- 8.4/31.0 MB 12.0 MB/s eta 0:00:02\n",
      "     ----------- ---------------------------- 9.0/31.0 MB 11.9 MB/s eta 0:00:02\n",
      "     ------------ --------------------------- 9.5/31.0 MB 11.9 MB/s eta 0:00:02\n",
      "     ------------ -------------------------- 10.0/31.0 MB 11.9 MB/s eta 0:00:02\n",
      "     ------------- ------------------------- 10.6/31.0 MB 11.9 MB/s eta 0:00:02\n",
      "     ------------- ------------------------- 11.1/31.0 MB 11.7 MB/s eta 0:00:02\n",
      "     -------------- ------------------------ 11.7/31.0 MB 11.7 MB/s eta 0:00:02\n",
      "     --------------- ----------------------- 12.2/31.0 MB 11.7 MB/s eta 0:00:02\n",
      "     ---------------- ---------------------- 12.7/31.0 MB 11.9 MB/s eta 0:00:02\n",
      "     ---------------- ---------------------- 13.5/31.0 MB 11.9 MB/s eta 0:00:02\n",
      "     ----------------- --------------------- 14.2/31.0 MB 11.9 MB/s eta 0:00:02\n",
      "     ------------------ -------------------- 14.9/31.0 MB 11.9 MB/s eta 0:00:02\n",
      "     ------------------- ------------------- 15.4/31.0 MB 11.9 MB/s eta 0:00:02\n",
      "     -------------------- ------------------ 15.9/31.0 MB 11.9 MB/s eta 0:00:02\n",
      "     -------------------- ------------------ 16.5/31.0 MB 11.9 MB/s eta 0:00:02\n",
      "     --------------------- ----------------- 17.0/31.0 MB 11.7 MB/s eta 0:00:02\n",
      "     ---------------------- ---------------- 17.6/31.0 MB 11.7 MB/s eta 0:00:02\n",
      "     ---------------------- ---------------- 18.1/31.0 MB 11.7 MB/s eta 0:00:02\n",
      "     ----------------------- --------------- 18.8/31.0 MB 11.7 MB/s eta 0:00:02\n",
      "     ------------------------ -------------- 19.4/31.0 MB 11.9 MB/s eta 0:00:01\n",
      "     ------------------------- ------------- 20.1/31.0 MB 11.9 MB/s eta 0:00:01\n",
      "     -------------------------- ------------ 20.8/31.0 MB 11.9 MB/s eta 0:00:01\n",
      "     --------------------------- ----------- 21.5/31.0 MB 11.9 MB/s eta 0:00:01\n",
      "     --------------------------- ----------- 22.1/31.0 MB 11.9 MB/s eta 0:00:01\n",
      "     ---------------------------- ---------- 22.6/31.0 MB 11.9 MB/s eta 0:00:01\n",
      "     ----------------------------- --------- 23.2/31.0 MB 11.9 MB/s eta 0:00:01\n",
      "     ----------------------------- --------- 23.7/31.0 MB 11.9 MB/s eta 0:00:01\n",
      "     ------------------------------ -------- 24.2/31.0 MB 11.7 MB/s eta 0:00:01\n",
      "     ------------------------------- ------- 24.8/31.0 MB 11.7 MB/s eta 0:00:01\n",
      "     ------------------------------- ------- 25.3/31.0 MB 11.7 MB/s eta 0:00:01\n",
      "     -------------------------------- ------ 25.8/31.0 MB 11.9 MB/s eta 0:00:01\n",
      "     --------------------------------- ----- 26.6/31.0 MB 11.9 MB/s eta 0:00:01\n",
      "     ---------------------------------- ---- 27.3/31.0 MB 11.9 MB/s eta 0:00:01\n",
      "     ----------------------------------- --- 28.0/31.0 MB 11.9 MB/s eta 0:00:01\n",
      "     ----------------------------------- --- 28.6/31.0 MB 11.9 MB/s eta 0:00:01\n",
      "     ------------------------------------ -- 29.1/31.0 MB 11.9 MB/s eta 0:00:01\n",
      "     ------------------------------------- - 29.6/31.0 MB 11.9 MB/s eta 0:00:01\n",
      "     ------------------------------------- - 30.2/31.0 MB 11.9 MB/s eta 0:00:01\n",
      "     --------------------------------------  30.7/31.0 MB 11.9 MB/s eta 0:00:01\n",
      "     --------------------------------------  31.0/31.0 MB 11.9 MB/s eta 0:00:01\n",
      "     --------------------------------------  31.0/31.0 MB 11.9 MB/s eta 0:00:01\n",
      "     --------------------------------------  31.0/31.0 MB 11.9 MB/s eta 0:00:01\n",
      "     --------------------------------------- 31.0/31.0 MB 10.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: grpcio>=1.8.6 in c:\\users\\knuyh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow-gpu==2.3.0) (1.56.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\knuyh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (2.22.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in c:\\users\\knuyh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\knuyh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (3.4.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\knuyh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (2.31.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\knuyh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (68.0.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\knuyh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (0.7.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\knuyh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (2.3.6)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\knuyh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\knuyh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\knuyh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (4.9)\n",
      "Requirement already satisfied: urllib3<2.0 in c:\\users\\knuyh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (1.26.16)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\knuyh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\knuyh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (6.8.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\knuyh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\knuyh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\knuyh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (2023.5.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\knuyh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (2.1.3)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\knuyh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (3.16.0)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in c:\\users\\knuyh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\knuyh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (3.2.2)\n",
      "Installing collected packages: tensorflow-gpu-estimator, numpy, gast, scipy, keras-preprocessing, h5py, tensorflow-gpu\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.24.3\n",
      "    Uninstalling numpy-1.24.3:\n",
      "      Successfully uninstalled numpy-1.24.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [WinError 5] 액세스가 거부되었습니다: 'C:\\\\Users\\\\knuyh\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python38\\\\Lib\\\\site-packages\\\\~-mpy\\\\.libs\\\\libopenblas64__v0.3.21-gcc_10_3_0.dll'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow-gpu==2.3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "c11f659c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 15575414697542718054\n",
       " xla_global_id: -1]"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "fda06678",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6670dc1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36386c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "48b75dd8",
   "metadata": {},
   "source": [
    "# 연습문제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "3156aea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3082, 0.3742, 0.4297],\n",
      "        [0.9729, 0.9739, 0.4533],\n",
      "        [0.3499, 0.7428, 0.4601]])\n",
      "torch.Size([3, 3])\n",
      "tensor([[[0.3082, 0.3742, 0.4297],\n",
      "         [0.9729, 0.9739, 0.4533],\n",
      "         [0.3499, 0.7428, 0.4601]]])\n",
      "torch.Size([1, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "# 1) 2D 텐서를 만들고 차원 0 위치에 크기가 1인 차원을 추가\n",
    "a = torch.rand(3, 3)\n",
    "print(a)\n",
    "print(a.shape)\n",
    "\n",
    "a = a.unsqueeze(dim = 0)\n",
    "print(a)\n",
    "print(a.shape)\n",
    "\n",
    "# squeeze : (A * B * 1 * C * 1)텐서 -> 차원1 제거 (A * B * C)텐서\n",
    "# unsqueeze : 지정한 차원에 size가 1인 공간 채움"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "1964e5c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 3])\n"
     ]
    }
   ],
   "source": [
    "# 2) 이전 텐서에 추가한 차원을 삭제\n",
    "a = a.squeeze(dim = 0)\n",
    "print(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "1708c991",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4.6973, 4.0894, 5.9158],\n",
       "        [3.8147, 4.9657, 3.4822],\n",
       "        [4.3225, 4.1021, 5.1472],\n",
       "        [5.5478, 4.8648, 4.3638],\n",
       "        [4.1159, 5.6760, 4.1456]])"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3) 범위가 [3, 7)이고 크기가 5 * 3인 랜덤한 텐서\n",
    "3 + torch.rand(5, 3) * (7 - 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "acd113dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1914, -0.9557,  0.1861],\n",
      "        [-1.8754, -0.1489,  0.5779],\n",
      "        [-0.7427, -0.0917,  0.8737]])\n",
      "\n",
      "tensor([[ 1.2546, -0.7061,  1.9140],\n",
      "        [-0.7122,  1.2873,  1.0257],\n",
      "        [ 0.8553,  0.8914,  0.8476]])\n",
      "\n",
      "tensor([[0.6497, 0.9484, 0.1678],\n",
      "        [0.0592, 0.7710, 0.8062],\n",
      "        [0.7092, 0.8940, 0.8161]])\n"
     ]
    }
   ],
   "source": [
    "# 4) 표준정규분포를 사용해 텐서 만들기\n",
    "print(torch.rand(3, 3).normal_(mean=0, std=1))\n",
    "print()\n",
    "print(torch.randn(3, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "797a94bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0],\n",
       "        [1],\n",
       "        [2],\n",
       "        [4]])"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5) 텐서 torch.Tensor([1, 1, 1, 0, 1])에서 0이 아닌 원소의 인덱스 추출\n",
    "a = torch.Tensor([1, 1, 1, 0, 1])\n",
    "torch.nonzero(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "f1916136",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1498, 0.1498, 0.1498, 0.1498],\n",
       "        [0.0933, 0.0933, 0.0933, 0.0933],\n",
       "        [0.6621, 0.6621, 0.6621, 0.6621]])"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6) 크기가 (3, 1)인 랜덤한 텐서를 만들고 네 벌을 복사해 쌓기\n",
    "a = torch.rand(3, 1)\n",
    "a.expand(3, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "85565a31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.6863, 1.0293, 1.0478, 1.0594],\n",
       "         [0.9419, 1.4537, 0.9492, 1.1504],\n",
       "         [0.7627, 1.1510, 0.9687, 1.1690],\n",
       "         [1.2054, 1.6729, 1.5440, 1.5168]],\n",
       "\n",
       "        [[1.2460, 1.2716, 1.2640, 0.9110],\n",
       "         [0.9292, 0.9143, 0.7946, 0.3787],\n",
       "         [1.6836, 1.7209, 1.5028, 1.0755],\n",
       "         [1.3620, 1.1290, 1.1289, 0.7804]],\n",
       "\n",
       "        [[1.4704, 0.8107, 1.5941, 1.5876],\n",
       "         [1.1916, 0.8711, 1.7155, 1.2294],\n",
       "         [1.2244, 0.5177, 1.1844, 1.3758],\n",
       "         [1.7513, 1.4848, 2.2572, 1.7295]]])"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 7) 3차원 행렬 두개의 배치 행렬 곱셈 계산\n",
    "a = torch.rand(3, 4, 5)\n",
    "b = torch.rand(3, 5, 4)\n",
    "torch.bmm(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "0684e9e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.9211, 1.0260, 1.1571, 0.6107],\n",
       "         [1.4150, 1.3554, 1.1342, 0.8690],\n",
       "         [2.2614, 1.9752, 1.9251, 1.2487],\n",
       "         [1.2627, 1.6914, 0.7091, 0.9530]],\n",
       "\n",
       "        [[1.4862, 1.2423, 1.1480, 0.6953],\n",
       "         [1.5345, 1.3368, 1.4592, 0.9156],\n",
       "         [1.2149, 1.1443, 0.6697, 0.7501],\n",
       "         [1.2979, 1.5386, 1.3208, 0.8696]],\n",
       "\n",
       "        [[1.0805, 1.1173, 1.2084, 0.6284],\n",
       "         [1.5268, 1.3741, 1.5223, 0.9872],\n",
       "         [1.9167, 1.3081, 1.3359, 0.6612],\n",
       "         [2.1798, 1.6470, 2.0117, 0.9501]]])"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 8) 3차원 행렬과 2차원 행렬의 배치 행렬 곱셈 계산\n",
    "a = torch.rand(3, 4, 5)\n",
    "b = torch.rand(5, 4)\n",
    "torch.bmm(a, b.unsqueeze(0).expand(a.size(0), *b.size()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197a9851",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8df97f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
