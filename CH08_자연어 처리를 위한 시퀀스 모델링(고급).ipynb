{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "380f8f42",
   "metadata": {},
   "source": [
    "### 8.1 시퀀스-투-시퀀스 모델, 인코더-디코더 모델, 조건부 생성\n",
    "* 인코더 : 입력에서 현재 문제와 관련된 중요한 성질 감지\n",
    "* 디코더 : 인코딩된 입력을 받아 원하는 출력 만듦\n",
    "* 입력과 출력 사이의 매핑 : 정렬\n",
    "\n",
    "[S2S 모델의 핵심 구성 요소]\n",
    "* 양방향 순환 모델\n",
    "* 어텐션\n",
    "\n",
    "### 8.2 강력한 시퀀스 모델링 : 양방향 순환 모델\n",
    "* 과거와 미래의 정보를 합침\n",
    "\n",
    "### 8.3 강력한 시퀀스 모델링 : 어텐션\n",
    "* 인코딩에 최종 은닉 상태만 사용하는 제약이 있기에, 긴 문장에서 전체 입력 정보 감지 어려움\n",
    "* 출력을 생성할 때 관련된 입력 부분에 초점을 맞추는 어텐션\n",
    "\n",
    "\n",
    "1. 심층 신경망의 어텐션\n",
    "* 각 타임 스텝은 은닉 상태 생성\n",
    "* 어텐션을 사용할 때는 인코더의 최종 은닉 상태뿐만 아니라 중간 타임 스텝의 은닉 상태도 고려\n",
    "\n",
    "\n",
    "[용어정리]\n",
    "* 인코더의 은닉 상태 = 값 = 키\n",
    "* 디코더의 이전 은닉 상태 = 쿼리\n",
    "* 어텐션은 주의를 기울이려는 값의 개수와 차원이 같은 벡터 하나로 표현되는데, 이를 어텐션 벡터 = 어텐션 가중치 = 정렬 이라 한다.\n",
    "* 어텐션 가중치 + 인코더 상태(값) = 문맥 벡터 = 글림스 -> 디코더의 입력\n",
    "* 다음 타임 스텝의 어텐션 벡터는 호환성 함수를 사용해 업데이트\n",
    "\n",
    "--------------\n",
    "* 콘텐츠 인식 어텐션  \n",
    "* 위치 인식 어텐션 : 쿼리 벡터 + 키만 사용  \n",
    "* 소프트 어텐션 : 어텐션 가중치는 일반적으로 0 ~ 1 사이 실수  \n",
    "* 하드 어텐션 : 0 or 1인 이진 벡터 학습  \n",
    "* 전역 어텐션 : 입력의 모든 타임 스텝에 대해 인코더의 상태 사용  \n",
    "* 지역 어텐션 : 현재 타임 스텝 주위에 있는 입력에만 의존  \n",
    "* 지도 어텐션 : 동시에 훈련도는 별도의 신경망 사용해 어텐션 함수 학습  \n",
    "* 멀티헤드 어텐션 : 트랜스포머 네트워크, 여러 어텐션 벡터 사용해 입력의 다양한 영역 추적  \n",
    "* 셀프 어텐션 : 입력의 어떤 영역이 다른 영역에 영향을 미치는지 학습  \n",
    "* 멀티모달 어텐션 : 이미지와 음성처럼 입력의 형태 다양할 때  \n",
    "\n",
    "\n",
    "### 8.4 시퀀스 생성 모델 평가\n",
    "* 참조 출력이라는 기대 출력으로 평가\n",
    "* 모델의 출력이 얼마나 참조 출력에 가까운지 점수로 매김\n",
    "1. 사람평가  \n",
    "*  좋음 / 나쁨 을 표시하거나 번역 고치는 방법\n",
    "* 에러율, 평가자 간의 일치율\n",
    "* HTER\n",
    "2. 자동 평가\n",
    "* n-그램 중복 기반 지표\n",
    "    * 참조와 출력이 얼마나 가까운지 n-그램 중복 통계로 점수 계산\n",
    "    * BLEU, ROUGE, METEOR\n",
    "* 혼란도\n",
    "    * 출력 시퀀스의 확률을 측정할 수 있다면 적용 가능\n",
    "    * 과장된 지표, 모델의 오차율에 직접 반영되지 않음\n",
    "    \n",
    "### 8.5 예제 : 신경망 기계 번역"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39666371",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e63b5c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75cc6261",
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe(x):\n",
    "    print(\"Type: {}\".format(x.type()))\n",
    "    print(\"Shape/size: {}\".format(x.shape))\n",
    "    print(\"Values: \\n{}\".format(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0174b751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: torch.FloatTensor\n",
      "Shape/size: torch.Size([3, 4])\n",
      "Values: \n",
      "tensor([[1., 2., 3., 4.],\n",
      "        [5., 6., 7., 0.],\n",
      "        [8., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "abcd_padded = torch.tensor([1, 2, 3, 4], dtype=torch.float32)\n",
    "efg_padded = torch.tensor([5, 6, 7, 0], dtype=torch.float32)\n",
    "h_padded = torch.tensor([8, 0, 0, 0], dtype=torch.float32)\n",
    "\n",
    "padded_tensor = torch.stack([abcd_padded, efg_padded, h_padded])\n",
    "\n",
    "describe(padded_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a0449e",
   "metadata": {},
   "source": [
    "* pack_padded_sequence : 패딩된 시퀀스 압축\n",
    "1. 0으로 패딩이 많이 된 것은 밑으로  \n",
    "1 2 3 4  - 4  \n",
    "5 6 7 0  - 3  \n",
    "8 0 0 0  - 1  \n",
    "2. batch_first = True -> 첫 번째 차원이 배치 차원인지\n",
    "* 세로로 읽기\n",
    "1 5 8 2 6 3 7 4\n",
    "3. batch_size는 세로로 읽기  \n",
    "**3**(158) **2**(26) **2**(37) **1**(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0bf378fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PackedSequence(data=tensor([1., 5., 8., 2., 6., 3., 7., 4.]), batch_sizes=tensor([3, 2, 2, 1]), sorted_indices=None, unsorted_indices=None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lengths = [4, 3, 1]\n",
    "packed_tensor = pack_padded_sequence(padded_tensor, lengths, \n",
    "                                     batch_first=True)\n",
    "packed_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de67f75",
   "metadata": {},
   "source": [
    "* pad_packed_sequence : 압축된 시퀀스 패딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed3a3e48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: torch.FloatTensor\n",
      "Shape/size: torch.Size([3, 4])\n",
      "Values: \n",
      "tensor([[1., 2., 3., 4.],\n",
      "        [5., 6., 7., 0.],\n",
      "        [8., 0., 0., 0.]])\n",
      "Type: torch.LongTensor\n",
      "Shape/size: torch.Size([3])\n",
      "Values: \n",
      "tensor([4, 3, 1])\n"
     ]
    }
   ],
   "source": [
    "unpacked_tensor, unpacked_lengths = pad_packed_sequence(packed_tensor, batch_first=True)\n",
    "describe(unpacked_tensor)\n",
    "describe(unpacked_lengths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48b522b",
   "metadata": {},
   "source": [
    "------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bfaeb97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "from nltk.tokenize import word_tokenize\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "139c6dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Namespace(\n",
    "    source_data_path=\"./Data/eng-fra.txt\",\n",
    "    output_data_path=\"./Data/simplest_eng_fra.csv\",\n",
    "    perc_train=0.7,\n",
    "    perc_val=0.15,\n",
    "    perc_test=0.15,\n",
    "    seed=1337\n",
    ")\n",
    "\n",
    "assert args.perc_test > 0 and (args.perc_test + args.perc_val + args.perc_train == 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5b9d14e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(args.source_data_path, 'r', encoding='UTF8') as fp:\n",
    "    lines = fp.readlines()\n",
    "    \n",
    "lines = [line.replace(\"\\n\", \"\").lower().split(\"\\t\") for line in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3913556b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for english_sentence, french_sentence in lines:\n",
    "    data.append({\"english_tokens\": word_tokenize(english_sentence, language=\"english\"),\n",
    "                 \"french_tokens\": word_tokenize(french_sentence, language=\"french\")})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9c1265ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'english_tokens': ['go', '.'], 'french_tokens': ['va', '!']},\n",
       " {'english_tokens': ['run', '!'], 'french_tokens': ['cours', '!']},\n",
       " {'english_tokens': ['run', '!'], 'french_tokens': ['courez', '!']},\n",
       " {'english_tokens': ['wow', '!'], 'french_tokens': ['ça', 'alors', '!']},\n",
       " {'english_tokens': ['fire', '!'], 'french_tokens': ['au', 'feu', '!']}]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "44fdba08",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_phrases = (\n",
    "    (\"i\", \"am\"), (\"i\", \"'m\"), \n",
    "    (\"he\", \"is\"), (\"he\", \"'s\"),\n",
    "    (\"she\", \"is\"), (\"she\", \"'s\"),\n",
    "    (\"you\", \"are\"), (\"you\", \"'re\"),\n",
    "    (\"we\", \"are\"), (\"we\", \"'re\"),\n",
    "    (\"they\", \"are\"), (\"they\", \"'re\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ddc6741e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_subset = {phrase: [] for phrase in filter_phrases}\n",
    "for datum in data:\n",
    "    key = tuple(datum['english_tokens'][:2]) # ('go', '.')\n",
    "    if key in data_subset:\n",
    "        data_subset[key].append(datum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2a2da4f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({('i', 'am'): 805,\n",
       "  ('i', \"'m\"): 4760,\n",
       "  ('he', 'is'): 1069,\n",
       "  ('he', \"'s\"): 787,\n",
       "  ('she', 'is'): 504,\n",
       "  ('she', \"'s\"): 316,\n",
       "  ('you', 'are'): 449,\n",
       "  ('you', \"'re\"): 2474,\n",
       "  ('we', 'are'): 181,\n",
       "  ('we', \"'re\"): 1053,\n",
       "  ('they', 'are'): 194,\n",
       "  ('they', \"'re\"): 470},\n",
       " 13062)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = {k: len(v) for k,v in data_subset.items()}\n",
    "counts, sum(counts.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b1867879",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(args.seed)\n",
    "\n",
    "dataset_stage3 = []\n",
    "for phrase, datum_list in sorted(data_subset.items()):\n",
    "    np.random.shuffle(datum_list)\n",
    "    n_train = int(len(datum_list) * args.perc_train)\n",
    "    n_val = int(len(datum_list) * args.perc_val)\n",
    "\n",
    "    for datum in datum_list[:n_train]:\n",
    "        datum['split'] = 'train'\n",
    "        \n",
    "    for datum in datum_list[n_train:n_train+n_val]:\n",
    "        datum['split'] = 'val'\n",
    "        \n",
    "    for datum in datum_list[n_train+n_val:]:\n",
    "        datum['split'] = 'test'\n",
    "    \n",
    "    dataset_stage3.extend(datum_list)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ea1e9db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for datum in dataset_stage3:\n",
    "    datum['source_language'] = \" \".join(datum.pop('english_tokens'))\n",
    "    datum['target_language'] = \" \".join(datum.pop('french_tokens'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a1ac1d71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'split': 'train',\n",
       "  'source_language': \"he 's the cutest boy in town .\",\n",
       "  'target_language': \"c'est le garçon le plus mignon en ville .\"},\n",
       " {'split': 'train',\n",
       "  'source_language': \"he 's a nonsmoker .\",\n",
       "  'target_language': 'il est non-fumeur .'},\n",
       " {'split': 'train',\n",
       "  'source_language': \"he 's smarter than me .\",\n",
       "  'target_language': 'il est plus intelligent que moi .'}]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_stage3[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a711b3b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>split</th>\n",
       "      <th>source_language</th>\n",
       "      <th>target_language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train</td>\n",
       "      <td>he 's the cutest boy in town .</td>\n",
       "      <td>c'est le garçon le plus mignon en ville .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train</td>\n",
       "      <td>he 's a nonsmoker .</td>\n",
       "      <td>il est non-fumeur .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train</td>\n",
       "      <td>he 's smarter than me .</td>\n",
       "      <td>il est plus intelligent que moi .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train</td>\n",
       "      <td>he 's a lovely young man .</td>\n",
       "      <td>c'est un adorable jeune homme .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train</td>\n",
       "      <td>he 's three years older than me .</td>\n",
       "      <td>il a trois ans de plus que moi .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13057</th>\n",
       "      <td>test</td>\n",
       "      <td>you are n't invited .</td>\n",
       "      <td>vous n'êtes pas invités .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13058</th>\n",
       "      <td>test</td>\n",
       "      <td>you are always watching tv .</td>\n",
       "      <td>tu regardes tout le temps la télé .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13059</th>\n",
       "      <td>test</td>\n",
       "      <td>you are trusted by every one of us .</td>\n",
       "      <td>chacun de nous te fait confiance .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13060</th>\n",
       "      <td>test</td>\n",
       "      <td>you are blinded by love .</td>\n",
       "      <td>vous êtes aveuglé par l'amour .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13061</th>\n",
       "      <td>test</td>\n",
       "      <td>you are a good person .</td>\n",
       "      <td>tu es une chouette gonzesse .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13062 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       split                       source_language  \\\n",
       "0      train        he 's the cutest boy in town .   \n",
       "1      train                   he 's a nonsmoker .   \n",
       "2      train               he 's smarter than me .   \n",
       "3      train            he 's a lovely young man .   \n",
       "4      train     he 's three years older than me .   \n",
       "...      ...                                   ...   \n",
       "13057   test                 you are n't invited .   \n",
       "13058   test          you are always watching tv .   \n",
       "13059   test  you are trusted by every one of us .   \n",
       "13060   test             you are blinded by love .   \n",
       "13061   test               you are a good person .   \n",
       "\n",
       "                                 target_language  \n",
       "0      c'est le garçon le plus mignon en ville .  \n",
       "1                            il est non-fumeur .  \n",
       "2              il est plus intelligent que moi .  \n",
       "3                c'est un adorable jeune homme .  \n",
       "4               il a trois ans de plus que moi .  \n",
       "...                                          ...  \n",
       "13057                  vous n'êtes pas invités .  \n",
       "13058        tu regardes tout le temps la télé .  \n",
       "13059         chacun de nous te fait confiance .  \n",
       "13060            vous êtes aveuglé par l'amour .  \n",
       "13061              tu es une chouette gonzesse .  \n",
       "\n",
       "[13062 rows x 3 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nmt_df = pd.DataFrame(dataset_stage3)\n",
    "nmt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670225dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nmt_df.to_csv(args.output_data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8956d769",
   "metadata": {},
   "source": [
    "---------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4d1a8ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from argparse import Namespace\n",
    "from collections import Counter\n",
    "import json\n",
    "import re\n",
    "import string\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7657fae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocabulary(object) :\n",
    "\n",
    "    def __init__(self, token_to_idx=None, mask_token=\"<MASK>\", add_unk=True, unk_token=\"<UNK>\"):\n",
    "        if token_to_idx is None:\n",
    "            token_to_idx = {}\n",
    "        self._token_to_idx = token_to_idx\n",
    "\n",
    "        self._idx_to_token = {idx: token \n",
    "                              for token, idx in self._token_to_idx.items()}\n",
    "        \n",
    "        self._add_unk = add_unk\n",
    "        self._unk_token = unk_token\n",
    "        self._mask_token = mask_token  # 모델 파라미터 업데이트하는데 사용하지 않는 위치\n",
    "        \n",
    "        self.mask_index = self.add_token(self._mask_token)\n",
    "        self.unk_index = -1\n",
    "        if add_unk:\n",
    "            self.unk_index = self.add_token(unk_token) \n",
    "        \n",
    "    def to_serializable(self):\n",
    "        return {'token_to_idx': self._token_to_idx, \n",
    "                'add_unk': self._add_unk, \n",
    "                'unk_token': self._unk_token, \n",
    "                'mask_token': self._mask_token}\n",
    "\n",
    "    \n",
    "    @classmethod\n",
    "    def from_serializable(cls, contents):\n",
    "        return cls(**contents)\n",
    "\n",
    "    \n",
    "    def add_token(self, token):        \n",
    "        if token in self._token_to_idx:\n",
    "            index = self._token_to_idx[token]\n",
    "        else:\n",
    "            index = len(self._token_to_idx)\n",
    "            self._token_to_idx[token] = index\n",
    "            self._idx_to_token[index] = token\n",
    "        return index\n",
    "            \n",
    "    \n",
    "    def add_many(self, tokens):\n",
    "        return [self.add_token(token) for token in tokens]\n",
    "\n",
    "    def lookup_token(self, token):\n",
    "        if self.unk_index >= 0:\n",
    "            return self._token_to_idx.get(token, self.unk_index)\n",
    "        else:\n",
    "            return self._token_to_idx[token]\n",
    "\n",
    "    def lookup_index(self, index):\n",
    "        if index not in self._idx_to_token:\n",
    "            raise KeyError(\"the index (%d) is not in the Vocabulary\" % index)\n",
    "        return self._idx_to_token[index]\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"<Vocabulary(size=%d)>\" % len(self)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._token_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "30c278ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequenceVocabulary(Vocabulary) :\n",
    "    def __init__(self, token_to_idx=None, unk_token=\"<UNK>\",\n",
    "                 mask_token=\"<MASK>\", begin_seq_token=\"<BEGIN>\",\n",
    "                 end_seq_token=\"<END>\"):\n",
    "\n",
    "        super(SequenceVocabulary, self).__init__(token_to_idx)\n",
    "\n",
    "        self._mask_token = mask_token  # 임베딩층의 마스킹 역할, 가변 길이의 시퀀스의 손실 계산\n",
    "        self._unk_token = unk_token  # 드물게 등장하는 단어 학습\n",
    "        self._begin_seq_token = begin_seq_token  # 시퀀스 경계에 관한 힌트\n",
    "        self._end_seq_token = end_seq_token\n",
    "\n",
    "        self.mask_index = self.add_token(self._mask_token)\n",
    "        self.unk_index = self.add_token(self._unk_token)\n",
    "        self.begin_seq_index = self.add_token(self._begin_seq_token)\n",
    "        self.end_seq_index = self.add_token(self._end_seq_token)\n",
    "\n",
    "    def to_serializable(self):\n",
    "        contents = super(SequenceVocabulary, self).to_serializable()\n",
    "        contents.update({'unk_token': self._unk_token,\n",
    "                         'mask_token': self._mask_token,\n",
    "                         'begin_seq_token': self._begin_seq_token,\n",
    "                         'end_seq_token': self._end_seq_token})\n",
    "        return contents\n",
    "\n",
    "    def lookup_token(self, token):\n",
    "        if self.unk_index >= 0:\n",
    "            return self._token_to_idx.get(token, self.unk_index)\n",
    "        else:\n",
    "            return self._token_to_idx[token]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4282232c",
   "metadata": {},
   "source": [
    "[소스 영어와 타깃 프랑스어를 벡터로 벼환하려면 복잡도가 증가한다.]\n",
    "* 소스와 타깃 시퀀스는 모델에서 다른 역할을 하고, 언어가 다르며, 다른 두 방식으로 벡터화된다.\n",
    "* 소스 시퀀스의 길이에 따라 각 미니배치 소팅해야 한다.  \n",
    "=> 두 문제에 대비하려고 객체 두 개를 만들고, 최대 시퀀스 길이를 따로 측정해야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2b82786a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorizer\n",
    "class NMTVectorizer(object) :\n",
    "    def __init__(self, source_vocab, target_vocab, max_source_length, max_target_length) :\n",
    "        self.source_vocab = source_vocab\n",
    "        self.target_vocab = target_vocab\n",
    "        \n",
    "        self.max_source_length = max_source_length\n",
    "        self.max_target_length = max_target_length\n",
    "        \n",
    "    # 인덱스 -> 벡터\n",
    "    # 고정크기 벡터로 변환하고, 필요시 mask_index로 패딩\n",
    "    # S2S 모델의 디코더가 예측 작업에 타임 스텝마다 입력/출력 토큰 필요함의 작업을 수행하지만, 인코더 문맥이 추가된다.\n",
    "    # 이런 작업 단순화하고자, 소스와 타깃 인덱스에 상관없이 벡터화를 수행\n",
    "    def _vectorize(self, indices, vector_length=-1, mask_index=0):\n",
    "        if vector_length < 0:\n",
    "            vector_length = len(indices)\n",
    "        \n",
    "        vector = np.zeros(vector_length, dtype=np.int64)\n",
    "        vector[:len(indices)] = indices\n",
    "        vector[len(indices):] = mask_index\n",
    "\n",
    "        return vector\n",
    "    \n",
    "    # 벡터로 변환된 소스 텍스트 반환\n",
    "    def _get_source_indices(self, text):\n",
    "        indices = [self.source_vocab.begin_seq_index]\n",
    "        indices.extend(self.source_vocab.lookup_token(token) for token in text.split(\" \"))\n",
    "        indices.append(self.source_vocab.end_seq_index)\n",
    "        return indices\n",
    "        \n",
    "    # 벡터로 변환된 타깃 텍스트 반환\n",
    "    def _get_target_indices(self, text):\n",
    "        indices = [self.target_vocab.lookup_token(token) for token in text.split(\" \")]\n",
    "        x_indices = [self.target_vocab.begin_seq_index] + indices\n",
    "        y_indices = indices + [self.target_vocab.end_seq_index]\n",
    "        return x_indices, y_indices # 디코더에서 샘플/예측을 나타내는 정수 리스트\n",
    "    \n",
    "    # 벡터화된 소스 텍스트와 타깃 텍스트 반환\n",
    "    # 벡터화된 소스 텍스트는 하나의 벡터, 타깃 텍스트는 2개의 벡터(샘플, 타깃)\n",
    "    def vectorize(self, source_text, target_text, use_dataset_max_lengths=True): # 최대 벡터 길이 사용할지 여부\n",
    "        source_vector_length = -1\n",
    "        target_vector_length = -1\n",
    "        \n",
    "        if use_dataset_max_lengths:\n",
    "            source_vector_length = self.max_source_length + 2 # begin / end index\n",
    "            target_vector_length = self.max_target_length + 1 # 토큰 하나가 밀린 복사본 두 개로 벡터화(첫번째 복사본-begin_of_seq, 두번째 복사본-end)\n",
    "            \n",
    "        source_indices = self._get_source_indices(source_text)\n",
    "        source_vector = self._vectorize(source_indices, \n",
    "                                        vector_length=source_vector_length, \n",
    "                                        mask_index=self.source_vocab.mask_index)\n",
    "        \n",
    "        target_x_indices, target_y_indices = self._get_target_indices(target_text)\n",
    "        target_x_vector = self._vectorize(target_x_indices,\n",
    "                                        vector_length=target_vector_length,\n",
    "                                        mask_index=self.target_vocab.mask_index)\n",
    "        target_y_vector = self._vectorize(target_y_indices,\n",
    "                                        vector_length=target_vector_length,\n",
    "                                        mask_index=self.target_vocab.mask_index)\n",
    "        return {\"source_vector\": source_vector, \n",
    "                \"target_x_vector\": target_x_vector, \n",
    "                \"target_y_vector\": target_y_vector, \n",
    "                \"source_length\": len(source_indices)}\n",
    "    \n",
    "    @classmethod\n",
    "    def from_dataframe(cls, bitext_df):\n",
    "        source_vocab = SequenceVocabulary()\n",
    "        target_vocab = SequenceVocabulary()\n",
    "        \n",
    "        max_source_length = 0\n",
    "        max_target_length = 0\n",
    "\n",
    "        for _, row in bitext_df.iterrows():\n",
    "            source_tokens = row[\"source_language\"].split(\" \")\n",
    "            if len(source_tokens) > max_source_length:\n",
    "                max_source_length = len(source_tokens)\n",
    "            for token in source_tokens:\n",
    "                source_vocab.add_token(token)\n",
    "            \n",
    "            target_tokens = row[\"target_language\"].split(\" \")\n",
    "            if len(target_tokens) > max_target_length:\n",
    "                max_target_length = len(target_tokens)\n",
    "            for token in target_tokens:\n",
    "                target_vocab.add_token(token)\n",
    "            \n",
    "        return cls(source_vocab, target_vocab, max_source_length, max_target_length)\n",
    "\n",
    "    @classmethod\n",
    "    def from_serializable(cls, contents):\n",
    "        source_vocab = SequenceVocabulary.from_serializable(contents[\"source_vocab\"])\n",
    "        target_vocab = SequenceVocabulary.from_serializable(contents[\"target_vocab\"])\n",
    "        \n",
    "        return cls(source_vocab=source_vocab, \n",
    "                   target_vocab=target_vocab, \n",
    "                   max_source_length=contents[\"max_source_length\"], \n",
    "                   max_target_length=contents[\"max_target_length\"])\n",
    "\n",
    "    def to_serializable(self):\n",
    "        return {\"source_vocab\": self.source_vocab.to_serializable(), \n",
    "                \"target_vocab\": self.target_vocab.to_serializable(), \n",
    "                \"max_source_length\": self.max_source_length,\n",
    "                \"max_target_length\": self.max_target_length}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "4e73c933",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NMTDataset(Dataset):\n",
    "    def __init__(self, text_df, vectorizer):\n",
    "        self.text_df = text_df\n",
    "        self._vectorizer = vectorizer\n",
    "\n",
    "        self.train_df = self.text_df[self.text_df.split=='train']\n",
    "        self.train_size = len(self.train_df)\n",
    "\n",
    "        self.val_df = self.text_df[self.text_df.split=='val']\n",
    "        self.validation_size = len(self.val_df)\n",
    "\n",
    "        self.test_df = self.text_df[self.text_df.split=='test']\n",
    "        self.test_size = len(self.test_df)\n",
    "\n",
    "        self._lookup_dict = {'train': (self.train_df, self.train_size),\n",
    "                             'val': (self.val_df, self.validation_size),\n",
    "                             'test': (self.test_df, self.test_size)}\n",
    "\n",
    "\n",
    "        self.set_split('train')\n",
    "        \n",
    "        \n",
    "    @classmethod\n",
    "    def load_dataset_and_make_vectorizer(cls, dataset_csv):\n",
    "        text_df = pd.read_csv(dataset_csv)\n",
    "        train_subset = text_df[text_df.split=='train']\n",
    "        return cls(text_df, NMTVectorizer.from_dataframe(train_subset))\n",
    "\n",
    "    @classmethod\n",
    "    def load_dataset_and_load_vectorizer(cls, dataset_csv, vectorizer_filepath):\n",
    "        text_df = pd.read_csv(dataset_csv)\n",
    "        vectorizer = cls.load_vectorizer_only(vectorizer_filepath)\n",
    "        return cls(text_df, vectorizer)\n",
    "\n",
    "    @staticmethod\n",
    "    def load_vectorizer_only(vectorizer_filepath):\n",
    "        with open(vectorizer_filepath) as fp:\n",
    "            return NMTVectorizer.from_serializable(json.load(fp))\n",
    "\n",
    "    def save_vectorizer(self, vectorizer_filepath):\n",
    "        with open(vectorizer_filepath, \"w\") as fp:\n",
    "            json.dump(self._vectorizer.to_serializable(), fp)\n",
    "\n",
    "    def get_vectorizer(self):\n",
    "        return self._vectorizer\n",
    "\n",
    "    def set_split(self, split=\"train\"):\n",
    "        self._target_split = split\n",
    "        self._target_df, self._target_size = self._lookup_dict[split]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self._target_size\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self._target_df.iloc[index]\n",
    "\n",
    "        vector_dict = self._vectorizer.vectorize(row.source_language, row.target_language)\n",
    "\n",
    "        return {\"x_source\": vector_dict[\"source_vector\"], \n",
    "                \"x_target\": vector_dict[\"target_x_vector\"],\n",
    "                \"y_target\": vector_dict[\"target_y_vector\"], \n",
    "                \"x_source_length\": vector_dict[\"source_length\"]}\n",
    "        \n",
    "    def get_num_batches(self, batch_size):\n",
    "        return len(self) // batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3b2412d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_nmt_batches(dataset, batch_size, shuffle=True,\n",
    "                        drop_last = True, device='cpu') :\n",
    "    dataloader = DataLoader(dataset=dataset, batch_size=batch_size,\n",
    "                            shuffle=shuffle, drop_last=drop_last)\n",
    "\n",
    "    for data_dict in dataloader:\n",
    "        lengths = data_dict['x_source_length'].numpy()\n",
    "        sorted_length_indices = lengths.argsort()[::-1].tolist()\n",
    "        \n",
    "        out_data_dict = {}\n",
    "        for name, tensor in data_dict.items():\n",
    "            out_data_dict[name] = data_dict[name][sorted_length_indices].to(device)\n",
    "        yield out_data_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd04422",
   "metadata": {},
   "source": [
    "------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb39200a",
   "metadata": {},
   "source": [
    "1. NMTEncoder : 소스 시퀀스를 입력으로 받아 임베딩하여 양방향 GRU에 주입\n",
    "2. NMTDecoder\n",
    "* 인코더 상태와 어텐션을 사용해 디코더가 새로운 시퀀스 생성\n",
    "* 타임 스텝마다 정답 타깃 시퀀스를 입력으로 사용\n",
    "* 또는 디코더가 선택한 시퀀스를 입력으로 사용\n",
    "* 이를 커리큘럼 학습, 탐색 학습이라 함\n",
    "3. NMTModel : 인코더와 디코더를 하나의 클래스로 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "3abb132f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NMTEncoder(nn.Module) :\n",
    "    def __init__(self, num_embeddings, embedding_size, rnn_hidden_size):\n",
    "        super(NMTEncoder, self).__init__()\n",
    "        \n",
    "        self.source_embedding = nn.Embedding(num_embeddings, embedding_size, padding_idx=0)\n",
    "        self.birnn = nn.GRU(embedding_size, rnn_hidden_size, bidirectional=True, batch_first=True)\n",
    "    \n",
    "    def forward(self, x_source, x_lengths):\n",
    "        x_embedded = self.source_embedding(x_source)\n",
    "        \n",
    "        # PackedSequence 생성; x_packed.data.shape=(number_items, embedding_size)\n",
    "        x_packed = pack_padded_sequence(x_embedded, x_lengths.detach().cpu().numpy(), \n",
    "                                        batch_first=True)\n",
    "        \n",
    "        # x_birnn_h.shape = (num_rnn, batch_size, feature_size)\n",
    "        x_birnn_out, x_birnn_h  = self.birnn(x_packed)\n",
    "        \n",
    "        # (batch_size, num_rnn, feature_size)로 변환\n",
    "        x_birnn_h = x_birnn_h.permute(1, 0, 2)\n",
    "        \n",
    "        # 특성 펼침; (batch_size, num_rnn * feature_size)로 바꾸기\n",
    "        # (참고: -1은 남은 차원에 해당합니다, \n",
    "        #       두 개의 RNN 은닉 벡터를 1로 펼칩니다)\n",
    "        x_birnn_h = x_birnn_h.contiguous().view(x_birnn_h.size(0), -1)\n",
    "        \n",
    "        x_unpacked, _ = pad_packed_sequence(x_birnn_out, batch_first=True)\n",
    "        \n",
    "        return x_unpacked, x_birnn_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "93f5554f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원소별 연산을 사용하는 어텐션 매커니즘 버전\n",
    "# 텐서가 다른 텐서에 브로드캐스팅될 수 있도록 view() 연산을 사용해 크기가 1인 차원 추가\n",
    "def verbose_attention(encoder_state_vectors, query_vector):\n",
    "    batch_size, num_vectors, vector_size = encoder_state_vectors.size()\n",
    "    vector_scores = torch.sum(encoder_state_vectors * query_vector.view(batch_size, 1, vector_size), \n",
    "                              dim=2)  # (batch_size, num_vectors)\n",
    "    vector_probabilities = F.softmax(vector_scores, dim=1)\n",
    "    weighted_vectors = encoder_state_vectors * vector_probabilities.view(batch_size, num_vectors, 1)\n",
    "    context_vectors = torch.sum(weighted_vectors, dim=1)\n",
    "    return context_vectors, vector_probabilities, vector_scores\n",
    "\n",
    "\n",
    "# 점곱을 사용하는 어텐션 매커니즘 버전\n",
    "# view()연산을 unsqueeze()로 변환\n",
    "# 원소별 곱셈과 덧셈 대신 matmul()연산 사용\n",
    "def terse_attention(encoder_state_vectors, query_vector):\n",
    "    vector_scores = torch.matmul(encoder_state_vectors, query_vector.unsqueeze(dim=2)).squeeze()\n",
    "    vector_probabilities = F.softmax(vector_scores, dim=-1) # (batch_size, num_vectors)\n",
    "    context_vectors = torch.matmul(encoder_state_vectors.transpose(-2, -1), \n",
    "                                   vector_probabilities.unsqueeze(dim=2)).squeeze() # (batch_size, vector_size)\n",
    "    return context_vectors, vector_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "aa805544",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NMTDecoder(nn.Module):\n",
    "    def __init__(self, num_embeddings, embedding_size, rnn_hidden_size, bos_index):\n",
    "        super(NMTDecoder, self).__init__()\n",
    "        self._rnn_hidden_size = rnn_hidden_size\n",
    "        self.target_embedding = nn.Embedding(num_embeddings=num_embeddings, \n",
    "                                             embedding_dim=embedding_size, \n",
    "                                             padding_idx=0)\n",
    "        self.gru_cell = nn.GRUCell(embedding_size + rnn_hidden_size, \n",
    "                                   rnn_hidden_size)\n",
    "        self.hidden_map = nn.Linear(rnn_hidden_size, rnn_hidden_size)\n",
    "        self.classifier = nn.Linear(rnn_hidden_size * 2, num_embeddings)\n",
    "        self.bos_index = bos_index # begin of sequence 인덱스\n",
    "    \n",
    "    # Begin_of_sequence 인덱스 벡터 반환\n",
    "    def _init_indices(self, batch_size) :\n",
    "        return torch.ones(batch_size, dtype=torch.int64) * self.bos_index\n",
    "    \n",
    "    # 문맥 벡터 초기화하기 위한 0벡터 반환\n",
    "    def _init_context_vectors(self, batch_size):\n",
    "        return torch.zeros(batch_size, self._rnn_hidden_size)\n",
    "    \n",
    "    \n",
    "    def forward(self, encoder_state, initial_hidden_state, target_sequence):\n",
    "        # 가정: 첫 번째 차원은 배치 차원입니다\n",
    "        # 즉 입력은 (Batch, Seq)\n",
    "        # 시퀀스에 대해 반복해야 하므로 (Seq, Batch)로 차원을 바꿉니다\n",
    "        target_sequence = target_sequence.permute(1, 0)\n",
    "        output_sequence_size = target_sequence.size(0)\n",
    "\n",
    "        # 주어진 인코더의 은닉 상태를 초기 은닉 상태로 사용합니다\n",
    "        h_t = self.hidden_map(initial_hidden_state)\n",
    "\n",
    "        batch_size = encoder_state.size(0)\n",
    "        # 문맥 벡터를 0으로 초기화합니다\n",
    "        context_vectors = self._init_context_vectors(batch_size)\n",
    "        # 첫 단어 y_t를 BOS로 초기화합니다\n",
    "        y_t_index = self._init_indices(batch_size)\n",
    "        \n",
    "        h_t = h_t.to(encoder_state.device)\n",
    "        y_t_index = y_t_index.to(encoder_state.device)\n",
    "        context_vectors = context_vectors.to(encoder_state.device)\n",
    "\n",
    "        output_vectors = []\n",
    "        self._cached_p_attn = []\n",
    "        self._cached_ht = []\n",
    "        self._cached_decoder_state = encoder_state.cpu().detach().numpy()\n",
    "        \n",
    "        for i in range(output_sequence_size):\n",
    "            y_t_index = target_sequence[i]\n",
    "                \n",
    "            # 단계 1: 단어를 임베딩하고 이전 문맥과 연결합니다\n",
    "            y_input_vector = self.target_embedding(y_t_index)\n",
    "            rnn_input = torch.cat([y_input_vector, context_vectors], dim=1)\n",
    "            \n",
    "            # 단계 2: GRU를 적용하고 새로운 은닉 벡터를 얻습니다\n",
    "            h_t = self.gru_cell(rnn_input, h_t)\n",
    "            self._cached_ht.append(h_t.cpu().detach().numpy())\n",
    "            \n",
    "            # 단계 3: 현재 은닉 상태를 사용해 인코더의 상태를 주목합니다\n",
    "            context_vectors, p_attn, _ = verbose_attention(encoder_state_vectors=encoder_state, \n",
    "                                                           query_vector=h_t)\n",
    "            \n",
    "            # 부가 작업: 시각화를 위해 어텐션 확률을 저장합니다\n",
    "            self._cached_p_attn.append(p_attn.cpu().detach().numpy())\n",
    "            \n",
    "            # 단게 4: 현재 은닉 상태와 문맥 벡터를 사용해 다음 단어를 예측합니다\n",
    "            prediction_vector = torch.cat((context_vectors, h_t), dim=1)\n",
    "            score_for_y_t_index = self.classifier(F.dropout(prediction_vector, 0.3))\n",
    "            \n",
    "            # 부가 작업: 예측 성능 점수를 기록합니다\n",
    "            output_vectors.append(score_for_y_t_index)\n",
    "            \n",
    "        output_vectors = torch.stack(output_vectors).permute(1, 0, 2)\n",
    "        \n",
    "        return output_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "9431a621",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NMTModel(nn.Module) :\n",
    "    def __init__(self, source_vocab_size, source_embedding_size, \n",
    "                 target_vocab_size, target_embedding_size, encoding_size, \n",
    "                 target_bos_index):\n",
    "        super(NMTModel, self).__init__()\n",
    "        self.encoder = NMTEncoder(num_embeddings=source_vocab_size, \n",
    "                                  embedding_size=source_embedding_size,\n",
    "                                  rnn_hidden_size=encoding_size)\n",
    "        decoding_size = encoding_size * 2\n",
    "        self.decoder = NMTDecoder(num_embeddings=target_vocab_size, \n",
    "                                  embedding_size=target_embedding_size, \n",
    "                                  rnn_hidden_size=decoding_size,\n",
    "                                  bos_index=target_bos_index)\n",
    "    \n",
    "    \n",
    "    def forward(self, x_source, x_source_lengths, target_sequence):\n",
    "        encoder_state, final_hidden_states = self.encoder(x_source, x_source_lengths)\n",
    "        decoded_states = self.decoder(encoder_state=encoder_state, \n",
    "                                      initial_hidden_state=final_hidden_states, \n",
    "                                      target_sequence=target_sequence)\n",
    "        return decoded_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "bffd8414",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_train_state(args):\n",
    "    return {'stop_early': False,\n",
    "            'early_stopping_step': 0,\n",
    "            'early_stopping_best_val': 1e8,\n",
    "            'learning_rate': args.learning_rate,\n",
    "            'epoch_index': 0,\n",
    "            'train_loss': [],\n",
    "            'train_acc': [],\n",
    "            'val_loss': [],\n",
    "            'val_acc': [],\n",
    "            'test_loss': -1,\n",
    "            'test_acc': -1,\n",
    "            'model_filename': args.model_state_file}\n",
    "\n",
    "def update_train_state(args, model, train_state):\n",
    "    # 적어도 한 번 모델을 저장합니다\n",
    "    if train_state['epoch_index'] == 0:\n",
    "        torch.save(model.state_dict(), train_state['model_filename'])\n",
    "        train_state['stop_early'] = False\n",
    "\n",
    "    # 성능이 향상되면 모델을 저장합니다\n",
    "    elif train_state['epoch_index'] >= 1:\n",
    "        loss_tm1, loss_t = train_state['val_loss'][-2:]\n",
    "         \n",
    "        # 손실이 나빠지면\n",
    "        if loss_t >= loss_tm1:\n",
    "            # 조기 종료 단계 업데이트\n",
    "            train_state['early_stopping_step'] += 1\n",
    "        # 손실이 감소하면\n",
    "        else:\n",
    "            # 최상의 모델 저장\n",
    "            if loss_t < train_state['early_stopping_best_val']:\n",
    "                torch.save(model.state_dict(), train_state['model_filename'])\n",
    "                train_state['early_stopping_best_val'] = loss_t\n",
    "\n",
    "            # 조기 종료 단계 재설정\n",
    "            train_state['early_stopping_step'] = 0\n",
    "\n",
    "        # 조기 종료 여부 확인\n",
    "        train_state['stop_early'] = \\\n",
    "            train_state['early_stopping_step'] >= args.early_stopping_criteria\n",
    "\n",
    "    return train_state\n",
    "\n",
    "def normalize_sizes(y_pred, y_true):\n",
    "    if len(y_pred.size()) == 3:\n",
    "        y_pred = y_pred.contiguous().view(-1, y_pred.size(2))\n",
    "    if len(y_true.size()) == 2:\n",
    "        y_true = y_true.contiguous().view(-1)\n",
    "    return y_pred, y_true\n",
    "\n",
    "def compute_accuracy(y_pred, y_true, mask_index):\n",
    "    y_pred, y_true = normalize_sizes(y_pred, y_true)\n",
    "\n",
    "    _, y_pred_indices = y_pred.max(dim=1)\n",
    "    \n",
    "    correct_indices = torch.eq(y_pred_indices, y_true).float()\n",
    "    valid_indices = torch.ne(y_true, mask_index).float()\n",
    "    \n",
    "    n_correct = (correct_indices * valid_indices).sum().item()\n",
    "    n_valid = valid_indices.sum().item()\n",
    "\n",
    "    return n_correct / n_valid * 100\n",
    "\n",
    "def sequence_loss(y_pred, y_true, mask_index):\n",
    "    y_pred, y_true = normalize_sizes(y_pred, y_true)\n",
    "    return F.cross_entropy(y_pred, y_true, ignore_index=mask_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "dc9e0608",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Namespace(dataset_csv=\"./Data/simplest_eng_fra.csv\",\n",
    "                 vectorizer_file=\"vectorizer.json\",\n",
    "                 model_state_file=\"model7.pth\",\n",
    "                 save_dir=\"./\",\n",
    "                 reload_from_files=True,\n",
    "                 expand_filepaths_to_save_dir=True,\n",
    "                 cuda=False,\n",
    "                 seed=1337,\n",
    "                 learning_rate=5e-4,\n",
    "                 batch_size=64,\n",
    "                 num_epochs=100,\n",
    "                 early_stopping_criteria=5,              \n",
    "                 source_embedding_size=64, \n",
    "                 target_embedding_size=64,\n",
    "                 encoding_size=64,\n",
    "                 catch_keyboard_interrupt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "13015ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = NMTDataset.load_dataset_and_make_vectorizer(args.dataset_csv)\n",
    "vectorizer = dataset.get_vectorizer()\n",
    "\n",
    "model = NMTModel(source_vocab_size=len(vectorizer.source_vocab), \n",
    "                 source_embedding_size=args.source_embedding_size, \n",
    "                 target_vocab_size=len(vectorizer.target_vocab),\n",
    "                 target_embedding_size=args.target_embedding_size, \n",
    "                 encoding_size=args.encoding_size,\n",
    "                 target_bos_index=vectorizer.target_vocab.begin_seq_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "5858487b",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=args.learning_rate)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer,\n",
    "                                           mode='min', factor=0.5,\n",
    "                                           patience=1)\n",
    "mask_index = vectorizer.target_vocab.mask_index\n",
    "train_state = make_train_state(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "d24308c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch_index in range(args.num_epochs):\n",
    "    train_state['epoch_index'] = epoch_index\n",
    "    \n",
    "    dataset.set_split('train')\n",
    "    batch_generator = generate_nmt_batches(dataset, \n",
    "                                           batch_size=args.batch_size, \n",
    "                                           #device=args.device\n",
    "                                          )\n",
    "    running_loss = 0.0\n",
    "    running_acc = 0.0\n",
    "    model.train()\n",
    "        \n",
    "    for batch_index, batch_dict in enumerate(batch_generator) :\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(batch_dict['x_source'],\n",
    "                      batch_dict['x_source_length'],\n",
    "                      batch_dict['x_target'])\n",
    "        loss = sequence_loss(y_pred, batch_dict['y_target'], mask_index)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += (loss.item() - running_loss) / (batch_index + 1)\n",
    "\n",
    "        acc_t = compute_accuracy(y_pred, batch_dict['y_target'], mask_index)\n",
    "        running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
    "        \n",
    "    train_state['train_loss'].append(running_loss)\n",
    "    train_state['train_acc'].append(running_acc)\n",
    "    \n",
    "    dataset.set_split('val')\n",
    "    batch_generator = generate_nmt_batches(dataset, \n",
    "                                           batch_size=args.batch_size, \n",
    "                                           #device=args.device\n",
    "                                          )\n",
    "    running_loss = 0.\n",
    "    running_acc = 0.\n",
    "    model.eval()\n",
    "\n",
    "    for batch_index, batch_dict in enumerate(batch_generator):\n",
    "        y_pred = model(batch_dict['x_source'], \n",
    "                       batch_dict['x_source_length'], \n",
    "                       batch_dict['x_target'])\n",
    "\n",
    "        loss = sequence_loss(y_pred, batch_dict['y_target'], mask_index)\n",
    "        \n",
    "        running_loss += (loss.item() - running_loss) / (batch_index + 1)\n",
    "        acc_t = compute_accuracy(y_pred, batch_dict['y_target'], mask_index)\n",
    "        running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
    "        \n",
    "    train_state['val_loss'].append(running_loss)\n",
    "    train_state['val_acc'].append(running_acc)\n",
    "\n",
    "    train_state = update_train_state(args=args, model=model, \n",
    "                                     train_state=train_state)\n",
    "\n",
    "    scheduler.step(train_state['val_loss'][-1])\n",
    "\n",
    "    if train_state['stop_early']:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "56876c83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NMTModel(\n",
       "  (encoder): NMTEncoder(\n",
       "    (source_embedding): Embedding(3025, 64, padding_idx=0)\n",
       "    (birnn): GRU(64, 64, batch_first=True, bidirectional=True)\n",
       "  )\n",
       "  (decoder): NMTDecoder(\n",
       "    (target_embedding): Embedding(4902, 64, padding_idx=0)\n",
       "    (gru_cell): GRUCell(192, 128)\n",
       "    (hidden_map): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (classifier): Linear(in_features=256, out_features=4902, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "81fd3067",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate import bleu_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "chencherry = bleu_score.SmoothingFunction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "7867ca17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_from_indices(indices, vocab, strict=True, return_string=True):\n",
    "    ignore_indices = set([vocab.mask_index, vocab.begin_seq_index, vocab.end_seq_index])\n",
    "    out = []\n",
    "    for index in indices:\n",
    "        if index == vocab.begin_seq_index and strict:\n",
    "            continue\n",
    "        elif index == vocab.end_seq_index and strict:\n",
    "            break\n",
    "        else:\n",
    "            out.append(vocab.lookup_index(index))\n",
    "    if return_string:\n",
    "        return \" \".join(out)\n",
    "    else:\n",
    "        return out\n",
    "    \n",
    "class NMTSampler:\n",
    "    def __init__(self, vectorizer, model):\n",
    "        self.vectorizer = vectorizer\n",
    "        self.model = model\n",
    "    \n",
    "    def apply_to_batch(self, batch_dict):\n",
    "        self._last_batch = batch_dict\n",
    "        y_pred = self.model(x_source=batch_dict['x_source'], \n",
    "                            x_source_lengths=batch_dict['x_source_length'], \n",
    "                            target_sequence=batch_dict['x_target'])\n",
    "        self._last_batch['y_pred'] = y_pred\n",
    "        \n",
    "        attention_batched = np.stack(self.model.decoder._cached_p_attn).transpose(1, 0, 2)\n",
    "        self._last_batch['attention'] = attention_batched\n",
    "        \n",
    "    def _get_source_sentence(self, index, return_string=True):\n",
    "        indices = self._last_batch['x_source'][index].cpu().detach().numpy()\n",
    "        vocab = self.vectorizer.source_vocab\n",
    "        return sentence_from_indices(indices, vocab, return_string=return_string)\n",
    "    \n",
    "    def _get_reference_sentence(self, index, return_string=True):\n",
    "        indices = self._last_batch['y_target'][index].cpu().detach().numpy()\n",
    "        vocab = self.vectorizer.target_vocab\n",
    "        return sentence_from_indices(indices, vocab, return_string=return_string)\n",
    "    \n",
    "    def _get_sampled_sentence(self, index, return_string=True):\n",
    "        _, all_indices = torch.max(self._last_batch['y_pred'], dim=2)\n",
    "        sentence_indices = all_indices[index].cpu().detach().numpy()\n",
    "        vocab = self.vectorizer.target_vocab\n",
    "        return sentence_from_indices(sentence_indices, vocab, return_string=return_string)\n",
    "\n",
    "    def get_ith_item(self, index, return_string=True):\n",
    "        output = {\"source\": self._get_source_sentence(index, return_string=return_string), \n",
    "                  \"reference\": self._get_reference_sentence(index, return_string=return_string), \n",
    "                  \"sampled\": self._get_sampled_sentence(index, return_string=return_string),\n",
    "                  \"attention\": self._last_batch['attention'][index]}\n",
    "        \n",
    "        reference = output['reference']\n",
    "        hypothesis = output['sampled']\n",
    "        \n",
    "        if not return_string:\n",
    "            reference = \" \".join(reference)\n",
    "            hypothesis = \" \".join(hypothesis)\n",
    "        \n",
    "        output['bleu-4'] = bleu_score.sentence_bleu(references=[reference],\n",
    "                                                    hypothesis=hypothesis,\n",
    "                                                    smoothing_function=chencherry.method1)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "4f8eb758",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = NMTSampler(vectorizer, model)\n",
    "\n",
    "dataset.set_split('test')\n",
    "batch_generator = generate_nmt_batches(dataset, \n",
    "                                       batch_size=args.batch_size, \n",
    "                                       #device=args.device\n",
    "                                      )\n",
    "\n",
    "test_results = []\n",
    "for batch_dict in batch_generator:\n",
    "    sampler.apply_to_batch(batch_dict)\n",
    "    for i in range(args.batch_size):\n",
    "        test_results.append(sampler.get_ith_item(i, False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "0763ee9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.459742734195706, 0.4568723121499908)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist([r['bleu-4'] for r in test_results], bins=100);\n",
    "np.mean([r['bleu-4'] for r in test_results]), np.median([r['bleu-4'] for r in test_results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "69b8422c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.set_split('val')\n",
    "batch_generator = generate_nmt_batches(dataset, \n",
    "                                       batch_size=args.batch_size, \n",
    "                                       #device=args.device\n",
    "                                      )\n",
    "batch_dict = next(batch_generator)\n",
    "\n",
    "#model = model.eval().to(args.device)\n",
    "sampler = NMTSampler(vectorizer, model)\n",
    "sampler.apply_to_batch(batch_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "5fa2935d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = []\n",
    "for i in range(args.batch_size):\n",
    "    all_results.append(sampler.get_ith_item(i, False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "83baf0d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_results = [x for x in all_results if x['bleu-4']>0.1]\n",
    "len(top_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "c6f00e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_source_sentence(vectorizer, batch_dict, index):\n",
    "    indices = batch_dict['x_source'][index].cpu().data.numpy()\n",
    "    vocab = vectorizer.source_vocab\n",
    "    return sentence_from_indices(indices, vocab)\n",
    "\n",
    "def get_true_sentence(vectorizer, batch_dict, index):\n",
    "    return sentence_from_indices(batch_dict['y_target'].cpu().data.numpy()[index], vectorizer.target_vocab)\n",
    "    \n",
    "def get_sampled_sentence(vectorizer, batch_dict, index):\n",
    "    y_pred = model(x_source=batch_dict['x_source'], \n",
    "                   x_source_lengths=batch_dict['x_source_length'], \n",
    "                   target_sequence=batch_dict['x_target'])\n",
    "    return sentence_from_indices(torch.max(y_pred, dim=2)[1].cpu().data.numpy()[index], vectorizer.target_vocab)\n",
    "\n",
    "def get_all_sentences(vectorizer, batch_dict, index):\n",
    "    return {\"source\": get_source_sentence(vectorizer, batch_dict, index), \n",
    "            \"truth\": get_true_sentence(vectorizer, batch_dict, index), \n",
    "            \"sampled\": get_sampled_sentence(vectorizer, batch_dict, index)}\n",
    "    \n",
    "def sentence_from_indices(indices, vocab, strict=True):\n",
    "    ignore_indices = set([vocab.mask_index, vocab.begin_seq_index, vocab.end_seq_index])\n",
    "    out = []\n",
    "    for index in indices:\n",
    "        if index == vocab.begin_seq_index and strict:\n",
    "            continue\n",
    "        elif index == vocab.end_seq_index and strict:\n",
    "            return \" \".join(out)\n",
    "        else:\n",
    "            out.append(vocab.lookup_index(index))\n",
    "    return \" \".join(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "8b4c23ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': \"you 're the only person i know who ca n't swim .\",\n",
       " 'truth': 'tu es la seule personne que je connaisse qui ne sache pas nager .',\n",
       " 'sampled': 'vous es la seule personne que je connaisse qui vous sache pas la .'}"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = get_all_sentences(vectorizer, batch_dict, 1)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9d9863",
   "metadata": {},
   "source": [
    "----------------------------------\n",
    "#### 샘플링 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "6fb0de46",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NMTDecoder(nn.Module):\n",
    "    def __init__(self, num_embeddings, embedding_size, rnn_hidden_size, bos_index):\n",
    "        \"\"\"\n",
    "        매개변수:\n",
    "            num_embeddings (int): 임베딩 개수는 타깃 어휘 사전에 있는 고유한 단어의 개수이다\n",
    "            embedding_size (int): 임베딩 벡터 크기\n",
    "            rnn_hidden_size (int): RNN 은닉 상태 크기\n",
    "            bos_index(int): begin-of-sequence 인덱스\n",
    "        \"\"\"\n",
    "        super(NMTDecoder, self).__init__()\n",
    "        self._rnn_hidden_size = rnn_hidden_size\n",
    "        self.target_embedding = nn.Embedding(num_embeddings=num_embeddings, \n",
    "                                             embedding_dim=embedding_size, \n",
    "                                             padding_idx=0)\n",
    "        self.gru_cell = nn.GRUCell(embedding_size + rnn_hidden_size, \n",
    "                                   rnn_hidden_size)\n",
    "        self.hidden_map = nn.Linear(rnn_hidden_size, rnn_hidden_size)\n",
    "        self.classifier = nn.Linear(rnn_hidden_size * 2, num_embeddings)\n",
    "        self.bos_index = bos_index\n",
    "        self._sampling_temperature = 3\n",
    "        \n",
    "    # Begin_of_sequence 인덱스 벡터 반환\n",
    "    def _init_indices(self, batch_size) :\n",
    "        return torch.ones(batch_size, dtype=torch.int64) * self.bos_index\n",
    "    \n",
    "    # 문맥 벡터 초기화하기 위한 0벡터 반환\n",
    "    def _init_context_vectors(self, batch_size):\n",
    "        return torch.zeros(batch_size, self._rnn_hidden_size)\n",
    "    \n",
    "    def forward(self, encoder_state, initial_hidden_state, target_sequence, sample_probability=0.0):\n",
    "        if target_sequence is None:\n",
    "            sample_probability = 1.0\n",
    "        else:\n",
    "            # 가정: 첫 번째 차원은 배치 차원입니다\n",
    "            # 즉 입력은 (Batch, Seq)\n",
    "            # 시퀀스에 대해 반복해야 하므로 (Seq, Batch)로 차원을 바꿉니다\n",
    "            target_sequence = target_sequence.permute(1, 0)\n",
    "            output_sequence_size = target_sequence.size(0)\n",
    "        \n",
    "        # 주어진 인코더의 은닉 상태를 초기 은닉 상태로 사용합니다\n",
    "        h_t = self.hidden_map(initial_hidden_state)\n",
    "        \n",
    "        batch_size = encoder_state.size(0)\n",
    "        # 문맥 벡터를 0으로 초기화합니다\n",
    "        context_vectors = self._init_context_vectors(batch_size)\n",
    "        # 첫 단어 y_t를 BOS로 초기화합니다\n",
    "        y_t_index = self._init_indices(batch_size)\n",
    "        \n",
    "        h_t = h_t.to(encoder_state.device)\n",
    "        y_t_index = y_t_index.to(encoder_state.device)\n",
    "        context_vectors = context_vectors.to(encoder_state.device)\n",
    "\n",
    "        output_vectors = []\n",
    "        self._cached_p_attn = []\n",
    "        self._cached_ht = []\n",
    "        self._cached_decoder_state = encoder_state.cpu().detach().numpy()\n",
    "        \n",
    "        for i in range(output_sequence_size):\n",
    "            # 스케줄링된 샘플링 사용 여부\n",
    "            use_sample = np.random.random() < sample_probability\n",
    "            if not use_sample:\n",
    "                y_t_index = target_sequence[i]\n",
    "                \n",
    "            # 단계 1: 단어를 임베딩하고 이전 문맥과 연결합니다\n",
    "            y_input_vector = self.target_embedding(y_t_index)\n",
    "            rnn_input = torch.cat([y_input_vector, context_vectors], dim=1)\n",
    "            \n",
    "            # 단계 2: GRU를 적용하고 새로운 은닉 벡터를 얻습니다\n",
    "            h_t = self.gru_cell(rnn_input, h_t)\n",
    "            self._cached_ht.append(h_t.cpu().detach().numpy())\n",
    "            \n",
    "            # 단계 3: 현재 은닉 상태를 사용해 인코더의 상태를 주목합니다\n",
    "            context_vectors, p_attn, _ = verbose_attention(encoder_state_vectors=encoder_state, \n",
    "                                                           query_vector=h_t)\n",
    "            \n",
    "            # 부가 작업: 시각화를 위해 어텐션 확률을 저장합니다\n",
    "            self._cached_p_attn.append(p_attn.cpu().detach().numpy())\n",
    "            \n",
    "            # 단계 4: 현재 은닉 상태와 문맥 벡터를 사용해 다음 단어를 예측합니다\n",
    "            prediction_vector = torch.cat((context_vectors, h_t), dim=1)\n",
    "            score_for_y_t_index = self.classifier(F.dropout(prediction_vector, 0.3))\n",
    "            \n",
    "            \n",
    "            # 샘플링 수행\n",
    "            if use_sample:\n",
    "                p_y_t_index = F.softmax(score_for_y_t_index * self._sampling_temperature, dim=1) # 뾰족 분포 생성\n",
    "                # _, y_t_index = torch.max(p_y_t_index, 1) # 최댓값 예측, 확률이 가장 높은 단어\n",
    "                y_t_index = torch.multinomial(p_y_t_index, 1).squeeze() # 확률에 비례하여 다항분포에서 인덱스 샘플링\n",
    "            \n",
    "            # 부가 작업: 예측 성능 점수를 기록\n",
    "            output_vectors.append(score_for_y_t_index)\n",
    "            \n",
    "        output_vectors = torch.stack(output_vectors).permute(1, 0, 2)\n",
    "        \n",
    "        return output_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "b2f5bfcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NMTModel(nn.Module):\n",
    "    def __init__(self, source_vocab_size, source_embedding_size, \n",
    "                 target_vocab_size, target_embedding_size, encoding_size, \n",
    "                 target_bos_index):\n",
    "        super(NMTModel, self).__init__()\n",
    "        self.encoder = NMTEncoder(num_embeddings=source_vocab_size, \n",
    "                                  embedding_size=source_embedding_size,\n",
    "                                  rnn_hidden_size=encoding_size)\n",
    "        decoding_size = encoding_size * 2\n",
    "        self.decoder = NMTDecoder(num_embeddings=target_vocab_size, \n",
    "                                  embedding_size=target_embedding_size, \n",
    "                                  rnn_hidden_size=decoding_size,\n",
    "                                  bos_index=target_bos_index)\n",
    "    \n",
    "    \n",
    "    def forward(self, x_source, x_source_lengths, target_sequence, sample_probability=0.0):\n",
    "        encoder_state, final_hidden_states = self.encoder(x_source, x_source_lengths)\n",
    "        decoded_states = self.decoder(encoder_state=encoder_state, \n",
    "                                      initial_hidden_state=final_hidden_states, \n",
    "                                      target_sequence=target_sequence, \n",
    "                                      sample_probability=sample_probability)\n",
    "        return decoded_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "fc64edb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Namespace(dataset_csv=\"./Data/simplest_eng_fra.csv\",\n",
    "                 vectorizer_file=\"vectorizer.json\",\n",
    "                 model_state_file=\"model8.pth\",\n",
    "                 save_dir=\"./\",\n",
    "                 reload_from_files=False,\n",
    "                 expand_filepaths_to_save_dir=True,\n",
    "                 cuda=True,\n",
    "                 seed=1337,\n",
    "                 learning_rate=5e-4,\n",
    "                 batch_size=32,\n",
    "                 num_epochs=100,\n",
    "                 early_stopping_criteria=5,              \n",
    "                 source_embedding_size=24, \n",
    "                 target_embedding_size=24,\n",
    "                 encoding_size=32,\n",
    "                 catch_keyboard_interrupt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "c73e389d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = NMTDataset.load_dataset_and_make_vectorizer(args.dataset_csv)\n",
    "vectorizer = dataset.get_vectorizer()\n",
    "\n",
    "model = NMTModel(source_vocab_size=len(vectorizer.source_vocab), \n",
    "                 source_embedding_size=args.source_embedding_size, \n",
    "                 target_vocab_size=len(vectorizer.target_vocab),\n",
    "                 target_embedding_size=args.target_embedding_size, \n",
    "                 encoding_size=args.encoding_size,\n",
    "                 target_bos_index=vectorizer.target_vocab.begin_seq_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "304ae8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=args.learning_rate)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer,\n",
    "                                           mode='min', factor=0.5,\n",
    "                                           patience=1)\n",
    "mask_index = vectorizer.target_vocab.mask_index\n",
    "train_state = make_train_state(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "ef5ba82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch_index in range(args.num_epochs):\n",
    "    sample_probability = (20 + epoch_index) / args.num_epochs\n",
    "\n",
    "    train_state['epoch_index'] = epoch_index\n",
    "\n",
    "    dataset.set_split('train')\n",
    "    batch_generator = generate_nmt_batches(dataset, \n",
    "                                           batch_size=args.batch_size, \n",
    "                                           #device=args.device\n",
    "                                          )\n",
    "    running_loss = 0.0\n",
    "    running_acc = 0.0\n",
    "    model.train()\n",
    "\n",
    "    for batch_index, batch_dict in enumerate(batch_generator):\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(batch_dict['x_source'],\n",
    "                      batch_dict['x_source_length'],\n",
    "                      batch_dict['x_target'],\n",
    "                      sample_probability = sample_probability)\n",
    "        loss = sequence_loss(y_pred, batch_dict['y_target'], mask_index)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += (loss.item() - running_loss) / (batch_index + 1)\n",
    "\n",
    "        acc_t = compute_accuracy(y_pred, batch_dict['y_target'], mask_index)\n",
    "        running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
    "        \n",
    "    train_state['train_loss'].append(running_loss)\n",
    "    train_state['train_acc'].append(running_acc)\n",
    "    \n",
    "    \n",
    "    dataset.set_split('val')\n",
    "    batch_generator = generate_nmt_batches(dataset, \n",
    "                                           batch_size=args.batch_size, \n",
    "                                           #device=args.device\n",
    "                                          )\n",
    "    running_loss = 0.\n",
    "    running_acc = 0.\n",
    "    model.eval()\n",
    "\n",
    "    for batch_index, batch_dict in enumerate(batch_generator):\n",
    "        y_pred = model(batch_dict['x_source'], \n",
    "                       batch_dict['x_source_length'], \n",
    "                       batch_dict['x_target'],\n",
    "                       sample_probability=sample_probability)\n",
    "\n",
    "        loss = sequence_loss(y_pred, batch_dict['y_target'], mask_index)\n",
    "\n",
    "        running_loss += (loss.item() - running_loss) / (batch_index + 1)\n",
    "\n",
    "        acc_t = compute_accuracy(y_pred, batch_dict['y_target'], mask_index)\n",
    "        running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
    "        \n",
    "    train_state['val_loss'].append(running_loss)\n",
    "    train_state['val_acc'].append(running_acc)\n",
    "\n",
    "    train_state = update_train_state(args=args, model=model, \n",
    "                                     train_state=train_state)\n",
    "\n",
    "    scheduler.step(train_state['val_loss'][-1])\n",
    "\n",
    "    if train_state['stop_early']:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "63228b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.set_split('val')\n",
    "batch_generator = generate_nmt_batches(dataset, \n",
    "                                       batch_size=args.batch_size, \n",
    "                                       #device=args.device\n",
    "                                      )\n",
    "batch_dict = next(batch_generator)\n",
    "\n",
    "model = model.eval()#.to(args.device)\n",
    "sampler = NMTSampler(vectorizer, model)\n",
    "sampler.apply_to_batch(batch_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "6080cb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = []\n",
    "for i in range(args.batch_size):\n",
    "    all_results.append(sampler.get_ith_item(i, False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "9b1810b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_results = [x for x in all_results if x['bleu-4']>0.5]\n",
    "len(top_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "3011e1f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': \"i 'm willing to help you if you want me to .\",\n",
       " 'truth': \"je suis disposé à t'aider , si tu veux que je le fasse .\",\n",
       " 'sampled': 'je suis prêt de vous vous vous vous avais vous vous vous fasse .'}"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = get_all_sentences(vectorizer, batch_dict, 1)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd6c0cd",
   "metadata": {},
   "source": [
    "* 샘플링된 것의 각 미니배치는 텐서 4개로 구성\n",
    "    - 소스 시퀀스의 정수 행렬 1 / 타깃 시퀀스의 정수 행렬 2 (하나는 어긋난 시퀀스) / 소스 시퀀스 길이의 정수 벡터 1\n",
    "    \n",
    "* 두 버전의 모델이 타깃 시퀀스를 다루는 방법이 다르다.\n",
    "    - 샘플링 X : 제공된 타깃 시퀀스를 타임 스텝마다 디코더의 입력으로 사용\n",
    "    - 샘플링 O : 스케줄링된 샘플링 사용해 모델이 자체 예측을 만들어 디코더의 입력으로 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15152b99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
